module @compiled_vae {
  util.global private @__auto.vae.post_quant_conv.weight = #stream.parameter.named<"model"::"vae.post_quant_conv.weight"> : tensor<4x4x1x1xf16>
  util.global private @__auto.vae.post_quant_conv.bias = #stream.parameter.named<"model"::"vae.post_quant_conv.bias"> : tensor<4xf16>
  util.global private @__auto.vae.decoder.conv_in.weight = #stream.parameter.named<"model"::"vae.decoder.conv_in.weight"> : tensor<512x4x3x3xf16>
  util.global private @__auto.vae.decoder.conv_in.bias = #stream.parameter.named<"model"::"vae.decoder.conv_in.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.group_norm.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.group_norm.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_q.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_q.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_k.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_k.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_v.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_v.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.weight"> : tensor<256x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<256x512x1x1xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.weight"> : tensor<128x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight"> : tensor<128x256x1x1xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_norm_out.bias = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_norm_out.weight = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_out.weight = #stream.parameter.named<"model"::"vae.decoder.conv_out.weight"> : tensor<3x128x3x3xf16>
  util.global private @__auto.vae.decoder.conv_out.bias = #stream.parameter.named<"model"::"vae.decoder.conv_out.bias"> : tensor<3xf16>
  util.global private @__auto.vae.encoder.conv_in.weight = #stream.parameter.named<"model"::"vae.encoder.conv_in.weight"> : tensor<128x3x3x3xf16>
  util.global private @__auto.vae.encoder.conv_in.bias = #stream.parameter.named<"model"::"vae.encoder.conv_in.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.downsamplers.0.conv.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.downsamplers.0.conv.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv1.weight"> : tensor<256x128x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight"> : tensor<256x128x1x1xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.downsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.downsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv1.weight"> : tensor<512x256x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<512x256x1x1xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.downsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.downsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.down_blocks.3.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.group_norm.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.group_norm.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_q.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_q.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_k.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_k.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_v.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_v.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_out.0.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.encoder.mid_block.attentions.0.to_out.0.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.encoder.mid_block.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.conv_norm_out.bias = #stream.parameter.named<"model"::"vae.encoder.conv_norm_out.bias"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.conv_norm_out.weight = #stream.parameter.named<"model"::"vae.encoder.conv_norm_out.weight"> : tensor<512xf16>
  util.global private @__auto.vae.encoder.conv_out.weight = #stream.parameter.named<"model"::"vae.encoder.conv_out.weight"> : tensor<8x512x3x3xf16>
  util.global private @__auto.vae.encoder.conv_out.bias = #stream.parameter.named<"model"::"vae.encoder.conv_out.bias"> : tensor<8xf16>
  util.global private @__auto.vae.quant_conv.weight = #stream.parameter.named<"model"::"vae.quant_conv.weight"> : tensor<8x8x1x1xf16>
  util.global private @__auto.vae.quant_conv.bias = #stream.parameter.named<"model"::"vae.quant_conv.bias"> : tensor<8xf16>
  func.func @decode(%arg0: !torch.vtensor<[8,4,128,128],f16>) -> !torch.vtensor<[8,3,1024,1024],f16> attributes {iree.reflection = {input_dtypes = "['float16']", input_shapes = "[(8, 4, 128, 128)]", model_name = "vae_decode", output_dtypes = "['float32']", output_shapes = "[(3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024)]"}, torch.assume_strict_symbolic_shapes} {
    %float7.677540e00 = torch.constant.float 7.6775431861804221
    %0 = torch.aten.mul.Scalar %arg0, %float7.677540e00 : !torch.vtensor<[8,4,128,128],f16>, !torch.float -> !torch.vtensor<[8,4,128,128],f16>
    %__auto.vae.post_quant_conv.weight = util.global.load @__auto.vae.post_quant_conv.weight : tensor<4x4x1x1xf16>
    %1 = torch_c.from_builtin_tensor %__auto.vae.post_quant_conv.weight : tensor<4x4x1x1xf16> -> !torch.vtensor<[4,4,1,1],f16>
    %__auto.vae.post_quant_conv.bias = util.global.load @__auto.vae.post_quant_conv.bias : tensor<4xf16>
    %2 = torch_c.from_builtin_tensor %__auto.vae.post_quant_conv.bias : tensor<4xf16> -> !torch.vtensor<[4],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %int0_1 = torch.constant.int 0
    %4 = torch.prim.ListConstruct %int0, %int0_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_2 = torch.constant.int 1
    %int1_3 = torch.constant.int 1
    %5 = torch.prim.ListConstruct %int1_2, %int1_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0_4 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %6 = torch.prim.ListConstruct %int0_4, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %7 = torch.aten.convolution %0, %1, %2, %3, %4, %5, %false, %6, %int1_6 : !torch.vtensor<[8,4,128,128],f16>, !torch.vtensor<[4,4,1,1],f16>, !torch.vtensor<[4],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,4,128,128],f16>
    %__auto.vae.decoder.conv_in.weight = util.global.load @__auto.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16>
    %8 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16> -> !torch.vtensor<[512,4,3,3],f16>
    %__auto.vae.decoder.conv_in.bias = util.global.load @__auto.vae.decoder.conv_in.bias : tensor<512xf16>
    %9 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_in.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_7 = torch.constant.int 1
    %int1_8 = torch.constant.int 1
    %10 = torch.prim.ListConstruct %int1_7, %int1_8 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_9 = torch.constant.int 1
    %int1_10 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int1_9, %int1_10 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_11 = torch.constant.int 1
    %int1_12 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_11, %int1_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_13 = torch.constant.bool false
    %int0_14 = torch.constant.int 0
    %int0_15 = torch.constant.int 0
    %13 = torch.prim.ListConstruct %int0_14, %int0_15 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_16 = torch.constant.int 1
    %14 = torch.aten.convolution %7, %8, %9, %10, %11, %12, %false_13, %13, %int1_16 : !torch.vtensor<[8,4,128,128],f16>, !torch.vtensor<[512,4,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8 = torch.constant.int 8
    %int32 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %15 = torch.prim.ListConstruct %int8, %int32, %int16, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6 = torch.constant.int 6
    %17 = torch.prims.convert_element_type %16, %int6 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %18 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_17 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %17, %18, %int0_17, %true : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_18 = torch.constant.int 1
    %19 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_18 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %20 = torch.aten.rsqrt %19 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_19 = torch.constant.int 1
    %21 = torch.aten.sub.Tensor %16, %result1, %int1_19 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %22 = torch.aten.mul.Tensor %21, %20 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_20 = torch.constant.int 8
    %int512 = torch.constant.int 512
    %int128 = torch.constant.int 128
    %int128_21 = torch.constant.int 128
    %23 = torch.prim.ListConstruct %int8_20, %int512, %int128, %int128_21 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %24 = torch.aten.view %22, %23 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %25 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_22 = torch.constant.int 0
    %26 = torch.aten.unsqueeze %25, %int0_22 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_23 = torch.constant.int 2
    %27 = torch.aten.unsqueeze %26, %int2_23 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_24 = torch.constant.int 3
    %28 = torch.aten.unsqueeze %27, %int3_24 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %29 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_25 = torch.constant.int 0
    %30 = torch.aten.unsqueeze %29, %int0_25 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_26 = torch.constant.int 2
    %31 = torch.aten.unsqueeze %30, %int2_26 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_27 = torch.constant.int 3
    %32 = torch.aten.unsqueeze %31, %int3_27 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %33 = torch.aten.mul.Tensor %24, %32 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_28 = torch.constant.int 1
    %34 = torch.aten.add.Tensor %33, %28, %int1_28 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5 = torch.constant.int 5
    %35 = torch.prims.convert_element_type %34, %int5 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %36 = torch.aten.silu %35 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %37 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %38 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_29 = torch.constant.int 1
    %int1_30 = torch.constant.int 1
    %39 = torch.prim.ListConstruct %int1_29, %int1_30 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_31 = torch.constant.int 1
    %int1_32 = torch.constant.int 1
    %40 = torch.prim.ListConstruct %int1_31, %int1_32 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_33 = torch.constant.int 1
    %int1_34 = torch.constant.int 1
    %41 = torch.prim.ListConstruct %int1_33, %int1_34 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_35 = torch.constant.bool false
    %int0_36 = torch.constant.int 0
    %int0_37 = torch.constant.int 0
    %42 = torch.prim.ListConstruct %int0_36, %int0_37 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_38 = torch.constant.int 1
    %43 = torch.aten.convolution %36, %37, %38, %39, %40, %41, %false_35, %42, %int1_38 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_39 = torch.constant.int 8
    %int32_40 = torch.constant.int 32
    %int16_41 = torch.constant.int 16
    %int16384_42 = torch.constant.int 16384
    %44 = torch.prim.ListConstruct %int8_39, %int32_40, %int16_41, %int16384_42 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %45 = torch.aten.view %43, %44 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_43 = torch.constant.int 6
    %46 = torch.prims.convert_element_type %45, %int6_43 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_44 = torch.constant.int 2
    %int3_45 = torch.constant.int 3
    %47 = torch.prim.ListConstruct %int2_44, %int3_45 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_46 = torch.constant.int 0
    %true_47 = torch.constant.bool true
    %result0_48, %result1_49 = torch.aten.var_mean.correction %46, %47, %int0_46, %true_47 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_50 = torch.constant.float 9.9999999999999995E-7
    %int1_51 = torch.constant.int 1
    %48 = torch.aten.add.Scalar %result0_48, %float9.999990e-07_50, %int1_51 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %49 = torch.aten.rsqrt %48 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_52 = torch.constant.int 1
    %50 = torch.aten.sub.Tensor %45, %result1_49, %int1_52 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %51 = torch.aten.mul.Tensor %50, %49 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_53 = torch.constant.int 8
    %int512_54 = torch.constant.int 512
    %int128_55 = torch.constant.int 128
    %int128_56 = torch.constant.int 128
    %52 = torch.prim.ListConstruct %int8_53, %int512_54, %int128_55, %int128_56 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %53 = torch.aten.view %51, %52 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %54 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_57 = torch.constant.int 0
    %55 = torch.aten.unsqueeze %54, %int0_57 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_58 = torch.constant.int 2
    %56 = torch.aten.unsqueeze %55, %int2_58 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_59 = torch.constant.int 3
    %57 = torch.aten.unsqueeze %56, %int3_59 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %58 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_60 = torch.constant.int 0
    %59 = torch.aten.unsqueeze %58, %int0_60 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_61 = torch.constant.int 2
    %60 = torch.aten.unsqueeze %59, %int2_61 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_62 = torch.constant.int 3
    %61 = torch.aten.unsqueeze %60, %int3_62 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %62 = torch.aten.mul.Tensor %53, %61 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_63 = torch.constant.int 1
    %63 = torch.aten.add.Tensor %62, %57, %int1_63 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_64 = torch.constant.int 5
    %64 = torch.prims.convert_element_type %63, %int5_64 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %65 = torch.aten.silu %64 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none = torch.constant.none
    %66 = torch.aten.clone %65, %none : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %67 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %68 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_65 = torch.constant.int 1
    %int1_66 = torch.constant.int 1
    %69 = torch.prim.ListConstruct %int1_65, %int1_66 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_67 = torch.constant.int 1
    %int1_68 = torch.constant.int 1
    %70 = torch.prim.ListConstruct %int1_67, %int1_68 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_69 = torch.constant.int 1
    %int1_70 = torch.constant.int 1
    %71 = torch.prim.ListConstruct %int1_69, %int1_70 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_71 = torch.constant.bool false
    %int0_72 = torch.constant.int 0
    %int0_73 = torch.constant.int 0
    %72 = torch.prim.ListConstruct %int0_72, %int0_73 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_74 = torch.constant.int 1
    %73 = torch.aten.convolution %66, %67, %68, %69, %70, %71, %false_71, %72, %int1_74 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_75 = torch.constant.int 1
    %74 = torch.aten.add.Tensor %14, %73, %int1_75 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_76 = torch.constant.int 1
    %75 = torch.aten.div.Scalar %74, %int1_76 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_77 = torch.constant.int 8
    %int512_78 = torch.constant.int 512
    %int16384_79 = torch.constant.int 16384
    %76 = torch.prim.ListConstruct %int8_77, %int512_78, %int16384_79 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %75, %76 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f16>
    %int1_80 = torch.constant.int 1
    %int2_81 = torch.constant.int 2
    %78 = torch.aten.transpose.int %77, %int1_80, %int2_81 : !torch.vtensor<[8,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int1_82 = torch.constant.int 1
    %int2_83 = torch.constant.int 2
    %79 = torch.aten.transpose.int %78, %int1_82, %int2_83 : !torch.vtensor<[8,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int8_84 = torch.constant.int 8
    %int32_85 = torch.constant.int 32
    %int16_86 = torch.constant.int 16
    %int16384_87 = torch.constant.int 16384
    %80 = torch.prim.ListConstruct %int8_84, %int32_85, %int16_86, %int16384_87 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %81 = torch.aten.view %79, %80 : !torch.vtensor<[8,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_88 = torch.constant.int 6
    %82 = torch.prims.convert_element_type %81, %int6_88 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_89 = torch.constant.int 2
    %int3_90 = torch.constant.int 3
    %83 = torch.prim.ListConstruct %int2_89, %int3_90 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_91 = torch.constant.int 0
    %true_92 = torch.constant.bool true
    %result0_93, %result1_94 = torch.aten.var_mean.correction %82, %83, %int0_91, %true_92 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_95 = torch.constant.float 9.9999999999999995E-7
    %int1_96 = torch.constant.int 1
    %84 = torch.aten.add.Scalar %result0_93, %float9.999990e-07_95, %int1_96 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %85 = torch.aten.rsqrt %84 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_97 = torch.constant.int 1
    %86 = torch.aten.sub.Tensor %81, %result1_94, %int1_97 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %87 = torch.aten.mul.Tensor %86, %85 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_98 = torch.constant.int 8
    %int512_99 = torch.constant.int 512
    %int16384_100 = torch.constant.int 16384
    %88 = torch.prim.ListConstruct %int8_98, %int512_99, %int16384_100 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %89 = torch.aten.view %87, %88 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f32>
    %__auto.vae.decoder.mid_block.attentions.0.group_norm.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %90 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_101 = torch.constant.int 0
    %91 = torch.aten.unsqueeze %90, %int0_101 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_102 = torch.constant.int 2
    %92 = torch.aten.unsqueeze %91, %int2_102 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %__auto.vae.decoder.mid_block.attentions.0.group_norm.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %93 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_103 = torch.constant.int 0
    %94 = torch.aten.unsqueeze %93, %int0_103 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_104 = torch.constant.int 2
    %95 = torch.aten.unsqueeze %94, %int2_104 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %96 = torch.aten.mul.Tensor %89, %95 : !torch.vtensor<[8,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[8,512,16384],f32>
    %int1_105 = torch.constant.int 1
    %97 = torch.aten.add.Tensor %96, %92, %int1_105 : !torch.vtensor<[8,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[8,512,16384],f32>
    %int5_106 = torch.constant.int 5
    %98 = torch.prims.convert_element_type %97, %int5_106 : !torch.vtensor<[8,512,16384],f32>, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int1_107 = torch.constant.int 1
    %int2_108 = torch.constant.int 2
    %99 = torch.aten.transpose.int %98, %int1_107, %int2_108 : !torch.vtensor<[8,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_q.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %100 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_109 = torch.constant.int 0
    %int1_110 = torch.constant.int 1
    %101 = torch.aten.transpose.int %100, %int0_109, %int1_110 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_111 = torch.constant.int 0
    %102 = torch.aten.clone %99, %int0_111 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072 = torch.constant.int 131072
    %int512_112 = torch.constant.int 512
    %103 = torch.prim.ListConstruct %int131072, %int512_112 : (!torch.int, !torch.int) -> !torch.list<int>
    %104 = torch.aten._unsafe_view %102, %103 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %105 = torch.aten.mm %104, %101 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_113 = torch.constant.int 8
    %int16384_114 = torch.constant.int 16384
    %int512_115 = torch.constant.int 512
    %106 = torch.prim.ListConstruct %int8_113, %int16384_114, %int512_115 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %107 = torch.aten.view %105, %106 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_q.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %108 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_116 = torch.constant.int 1
    %109 = torch.aten.add.Tensor %107, %108, %int1_116 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_k.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %110 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_117 = torch.constant.int 0
    %int1_118 = torch.constant.int 1
    %111 = torch.aten.transpose.int %110, %int0_117, %int1_118 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_119 = torch.constant.int 0
    %112 = torch.aten.clone %99, %int0_119 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_120 = torch.constant.int 131072
    %int512_121 = torch.constant.int 512
    %113 = torch.prim.ListConstruct %int131072_120, %int512_121 : (!torch.int, !torch.int) -> !torch.list<int>
    %114 = torch.aten._unsafe_view %112, %113 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %115 = torch.aten.mm %114, %111 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_122 = torch.constant.int 8
    %int16384_123 = torch.constant.int 16384
    %int512_124 = torch.constant.int 512
    %116 = torch.prim.ListConstruct %int8_122, %int16384_123, %int512_124 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %117 = torch.aten.view %115, %116 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_k.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %118 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_125 = torch.constant.int 1
    %119 = torch.aten.add.Tensor %117, %118, %int1_125 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_v.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %120 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_126 = torch.constant.int 0
    %int1_127 = torch.constant.int 1
    %121 = torch.aten.transpose.int %120, %int0_126, %int1_127 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_128 = torch.constant.int 0
    %122 = torch.aten.clone %99, %int0_128 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_129 = torch.constant.int 131072
    %int512_130 = torch.constant.int 512
    %123 = torch.prim.ListConstruct %int131072_129, %int512_130 : (!torch.int, !torch.int) -> !torch.list<int>
    %124 = torch.aten._unsafe_view %122, %123 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %125 = torch.aten.mm %124, %121 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_131 = torch.constant.int 8
    %int16384_132 = torch.constant.int 16384
    %int512_133 = torch.constant.int 512
    %126 = torch.prim.ListConstruct %int8_131, %int16384_132, %int512_133 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %127 = torch.aten.view %125, %126 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_v.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %128 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_134 = torch.constant.int 1
    %129 = torch.aten.add.Tensor %127, %128, %int1_134 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int8_135 = torch.constant.int 8
    %int-1 = torch.constant.int -1
    %int1_136 = torch.constant.int 1
    %int512_137 = torch.constant.int 512
    %130 = torch.prim.ListConstruct %int8_135, %int-1, %int1_136, %int512_137 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %131 = torch.aten.view %109, %130 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_138 = torch.constant.int 1
    %int2_139 = torch.constant.int 2
    %132 = torch.aten.transpose.int %131, %int1_138, %int2_139 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_140 = torch.constant.int 8
    %int-1_141 = torch.constant.int -1
    %int1_142 = torch.constant.int 1
    %int512_143 = torch.constant.int 512
    %133 = torch.prim.ListConstruct %int8_140, %int-1_141, %int1_142, %int512_143 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %134 = torch.aten.view %119, %133 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_144 = torch.constant.int 1
    %int2_145 = torch.constant.int 2
    %135 = torch.aten.transpose.int %134, %int1_144, %int2_145 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_146 = torch.constant.int 8
    %int-1_147 = torch.constant.int -1
    %int1_148 = torch.constant.int 1
    %int512_149 = torch.constant.int 512
    %136 = torch.prim.ListConstruct %int8_146, %int-1_147, %int1_148, %int512_149 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %137 = torch.aten.view %129, %136 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_150 = torch.constant.int 1
    %int2_151 = torch.constant.int 2
    %138 = torch.aten.transpose.int %137, %int1_150, %int2_151 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %139 = torch.aten.mul.Scalar %132, %float2.102240e-01 : !torch.vtensor<[8,1,16384,512],f16>, !torch.float -> !torch.vtensor<[8,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_152 = torch.constant.int -1
    %140 = torch.aten.transpose.int %135, %int-2, %int-1_152 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,512,16384],f16>
    %float2.102240e-01_153 = torch.constant.float 0.21022410381342863
    %141 = torch.aten.mul.Scalar %140, %float2.102240e-01_153 : !torch.vtensor<[8,1,512,16384],f16>, !torch.float -> !torch.vtensor<[8,1,512,16384],f16>
    %int8_154 = torch.constant.int 8
    %int1_155 = torch.constant.int 1
    %int16384_156 = torch.constant.int 16384
    %int512_157 = torch.constant.int 512
    %142 = torch.prim.ListConstruct %int8_154, %int1_155, %int16384_156, %int512_157 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_158 = torch.constant.bool false
    %143 = torch.aten.expand %139, %142, %false_158 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_159 = torch.constant.int 8
    %int16384_160 = torch.constant.int 16384
    %int512_161 = torch.constant.int 512
    %144 = torch.prim.ListConstruct %int8_159, %int16384_160, %int512_161 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %145 = torch.aten.view %143, %144 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %int8_162 = torch.constant.int 8
    %int1_163 = torch.constant.int 1
    %int512_164 = torch.constant.int 512
    %int16384_165 = torch.constant.int 16384
    %146 = torch.prim.ListConstruct %int8_162, %int1_163, %int512_164, %int16384_165 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_166 = torch.constant.bool false
    %147 = torch.aten.expand %141, %146, %false_166 : !torch.vtensor<[8,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,512,16384],f16>
    %int8_167 = torch.constant.int 8
    %int512_168 = torch.constant.int 512
    %int16384_169 = torch.constant.int 16384
    %148 = torch.prim.ListConstruct %int8_167, %int512_168, %int16384_169 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %149 = torch.aten.view %147, %148 : !torch.vtensor<[8,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f16>
    %150 = torch.aten.bmm %145, %149 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[8,512,16384],f16> -> !torch.vtensor<[8,16384,16384],f16>
    %int8_170 = torch.constant.int 8
    %int1_171 = torch.constant.int 1
    %int16384_172 = torch.constant.int 16384
    %int16384_173 = torch.constant.int 16384
    %151 = torch.prim.ListConstruct %int8_170, %int1_171, %int16384_172, %int16384_173 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %152 = torch.aten.view %150, %151 : !torch.vtensor<[8,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,1,16384,16384],f16>
    %int-1_174 = torch.constant.int -1
    %false_175 = torch.constant.bool false
    %153 = torch.aten._softmax %152, %int-1_174, %false_175 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[8,1,16384,16384],f16>
    %int8_176 = torch.constant.int 8
    %int1_177 = torch.constant.int 1
    %int16384_178 = torch.constant.int 16384
    %int16384_179 = torch.constant.int 16384
    %154 = torch.prim.ListConstruct %int8_176, %int1_177, %int16384_178, %int16384_179 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_180 = torch.constant.bool false
    %155 = torch.aten.expand %153, %154, %false_180 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,16384],f16>
    %int8_181 = torch.constant.int 8
    %int16384_182 = torch.constant.int 16384
    %int16384_183 = torch.constant.int 16384
    %156 = torch.prim.ListConstruct %int8_181, %int16384_182, %int16384_183 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %157 = torch.aten.view %155, %156 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,16384],f16>
    %int8_184 = torch.constant.int 8
    %int1_185 = torch.constant.int 1
    %int16384_186 = torch.constant.int 16384
    %int512_187 = torch.constant.int 512
    %158 = torch.prim.ListConstruct %int8_184, %int1_185, %int16384_186, %int512_187 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_188 = torch.constant.bool false
    %159 = torch.aten.expand %138, %158, %false_188 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_189 = torch.constant.int 8
    %int16384_190 = torch.constant.int 16384
    %int512_191 = torch.constant.int 512
    %160 = torch.prim.ListConstruct %int8_189, %int16384_190, %int512_191 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %161 = torch.aten.view %159, %160 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %162 = torch.aten.bmm %157, %161 : !torch.vtensor<[8,16384,16384],f16>, !torch.vtensor<[8,16384,512],f16> -> !torch.vtensor<[8,16384,512],f16>
    %int8_192 = torch.constant.int 8
    %int1_193 = torch.constant.int 1
    %int16384_194 = torch.constant.int 16384
    %int512_195 = torch.constant.int 512
    %163 = torch.prim.ListConstruct %int8_192, %int1_193, %int16384_194, %int512_195 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %164 = torch.aten.view %162, %163 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,1,16384,512],f16>
    %int1_196 = torch.constant.int 1
    %int2_197 = torch.constant.int 2
    %165 = torch.aten.transpose.int %164, %int1_196, %int2_197 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_198 = torch.constant.int 1
    %int2_199 = torch.constant.int 2
    %166 = torch.aten.transpose.int %165, %int1_198, %int2_199 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int1_200 = torch.constant.int 1
    %int2_201 = torch.constant.int 2
    %167 = torch.aten.transpose.int %166, %int1_200, %int2_201 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,1,512],f16>
    %int8_202 = torch.constant.int 8
    %int-1_203 = torch.constant.int -1
    %int512_204 = torch.constant.int 512
    %168 = torch.prim.ListConstruct %int8_202, %int-1_203, %int512_204 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %169 = torch.aten.view %167, %168 : !torch.vtensor<[8,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %int5_205 = torch.constant.int 5
    %170 = torch.prims.convert_element_type %169, %int5_205 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_206 = torch.constant.int 131072
    %int512_207 = torch.constant.int 512
    %171 = torch.prim.ListConstruct %int131072_206, %int512_207 : (!torch.int, !torch.int) -> !torch.list<int>
    %172 = torch.aten.view %170, %171 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %173 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_208 = torch.constant.int 0
    %int1_209 = torch.constant.int 1
    %174 = torch.aten.transpose.int %173, %int0_208, %int1_209 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %175 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_210 = torch.constant.int 6
    %176 = torch.prims.convert_element_type %175, %int6_210 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_211 = torch.constant.int 6
    %177 = torch.prims.convert_element_type %172, %int6_211 : !torch.vtensor<[131072,512],f16>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int6_212 = torch.constant.int 6
    %178 = torch.prims.convert_element_type %174, %int6_212 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %179 = torch.aten.mm %177, %178 : !torch.vtensor<[131072,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[131072,512],f32>
    %int1_213 = torch.constant.int 1
    %180 = torch.aten.mul.Scalar %179, %int1_213 : !torch.vtensor<[131072,512],f32>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int1_214 = torch.constant.int 1
    %181 = torch.aten.mul.Scalar %176, %int1_214 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_215 = torch.constant.int 1
    %182 = torch.aten.add.Tensor %180, %181, %int1_215 : !torch.vtensor<[131072,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int5_216 = torch.constant.int 5
    %183 = torch.prims.convert_element_type %182, %int5_216 : !torch.vtensor<[131072,512],f32>, !torch.int -> !torch.vtensor<[131072,512],f16>
    %int8_217 = torch.constant.int 8
    %int16384_218 = torch.constant.int 16384
    %int512_219 = torch.constant.int 512
    %184 = torch.prim.ListConstruct %int8_217, %int16384_218, %int512_219 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %185 = torch.aten.view %183, %184 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %none_220 = torch.constant.none
    %186 = torch.aten.clone %185, %none_220 : !torch.vtensor<[8,16384,512],f16>, !torch.none -> !torch.vtensor<[8,16384,512],f16>
    %int-1_221 = torch.constant.int -1
    %int-2_222 = torch.constant.int -2
    %187 = torch.aten.transpose.int %186, %int-1_221, %int-2_222 : !torch.vtensor<[8,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int8_223 = torch.constant.int 8
    %int512_224 = torch.constant.int 512
    %int128_225 = torch.constant.int 128
    %int128_226 = torch.constant.int 128
    %188 = torch.prim.ListConstruct %int8_223, %int512_224, %int128_225, %int128_226 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %189 = torch.aten.view %187, %188 : !torch.vtensor<[8,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f16>
    %int1_227 = torch.constant.int 1
    %190 = torch.aten.add.Tensor %189, %75, %int1_227 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_228 = torch.constant.int 1
    %191 = torch.aten.div.Scalar %190, %int1_228 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_229 = torch.constant.int 8
    %int32_230 = torch.constant.int 32
    %int16_231 = torch.constant.int 16
    %int16384_232 = torch.constant.int 16384
    %192 = torch.prim.ListConstruct %int8_229, %int32_230, %int16_231, %int16384_232 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %193 = torch.aten.view %191, %192 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_233 = torch.constant.int 6
    %194 = torch.prims.convert_element_type %193, %int6_233 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_234 = torch.constant.int 2
    %int3_235 = torch.constant.int 3
    %195 = torch.prim.ListConstruct %int2_234, %int3_235 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_236 = torch.constant.int 0
    %true_237 = torch.constant.bool true
    %result0_238, %result1_239 = torch.aten.var_mean.correction %194, %195, %int0_236, %true_237 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_240 = torch.constant.float 9.9999999999999995E-7
    %int1_241 = torch.constant.int 1
    %196 = torch.aten.add.Scalar %result0_238, %float9.999990e-07_240, %int1_241 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %197 = torch.aten.rsqrt %196 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_242 = torch.constant.int 1
    %198 = torch.aten.sub.Tensor %193, %result1_239, %int1_242 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %199 = torch.aten.mul.Tensor %198, %197 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_243 = torch.constant.int 8
    %int512_244 = torch.constant.int 512
    %int128_245 = torch.constant.int 128
    %int128_246 = torch.constant.int 128
    %200 = torch.prim.ListConstruct %int8_243, %int512_244, %int128_245, %int128_246 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %201 = torch.aten.view %199, %200 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %202 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_247 = torch.constant.int 0
    %203 = torch.aten.unsqueeze %202, %int0_247 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_248 = torch.constant.int 2
    %204 = torch.aten.unsqueeze %203, %int2_248 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_249 = torch.constant.int 3
    %205 = torch.aten.unsqueeze %204, %int3_249 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %206 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_250 = torch.constant.int 0
    %207 = torch.aten.unsqueeze %206, %int0_250 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_251 = torch.constant.int 2
    %208 = torch.aten.unsqueeze %207, %int2_251 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_252 = torch.constant.int 3
    %209 = torch.aten.unsqueeze %208, %int3_252 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %210 = torch.aten.mul.Tensor %201, %209 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_253 = torch.constant.int 1
    %211 = torch.aten.add.Tensor %210, %205, %int1_253 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_254 = torch.constant.int 5
    %212 = torch.prims.convert_element_type %211, %int5_254 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %213 = torch.aten.silu %212 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %214 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %215 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_255 = torch.constant.int 1
    %int1_256 = torch.constant.int 1
    %216 = torch.prim.ListConstruct %int1_255, %int1_256 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_257 = torch.constant.int 1
    %int1_258 = torch.constant.int 1
    %217 = torch.prim.ListConstruct %int1_257, %int1_258 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_259 = torch.constant.int 1
    %int1_260 = torch.constant.int 1
    %218 = torch.prim.ListConstruct %int1_259, %int1_260 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_261 = torch.constant.bool false
    %int0_262 = torch.constant.int 0
    %int0_263 = torch.constant.int 0
    %219 = torch.prim.ListConstruct %int0_262, %int0_263 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_264 = torch.constant.int 1
    %220 = torch.aten.convolution %213, %214, %215, %216, %217, %218, %false_261, %219, %int1_264 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_265 = torch.constant.int 8
    %int32_266 = torch.constant.int 32
    %int16_267 = torch.constant.int 16
    %int16384_268 = torch.constant.int 16384
    %221 = torch.prim.ListConstruct %int8_265, %int32_266, %int16_267, %int16384_268 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %222 = torch.aten.view %220, %221 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_269 = torch.constant.int 6
    %223 = torch.prims.convert_element_type %222, %int6_269 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_270 = torch.constant.int 2
    %int3_271 = torch.constant.int 3
    %224 = torch.prim.ListConstruct %int2_270, %int3_271 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_272 = torch.constant.int 0
    %true_273 = torch.constant.bool true
    %result0_274, %result1_275 = torch.aten.var_mean.correction %223, %224, %int0_272, %true_273 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_276 = torch.constant.float 9.9999999999999995E-7
    %int1_277 = torch.constant.int 1
    %225 = torch.aten.add.Scalar %result0_274, %float9.999990e-07_276, %int1_277 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %226 = torch.aten.rsqrt %225 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_278 = torch.constant.int 1
    %227 = torch.aten.sub.Tensor %222, %result1_275, %int1_278 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %228 = torch.aten.mul.Tensor %227, %226 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_279 = torch.constant.int 8
    %int512_280 = torch.constant.int 512
    %int128_281 = torch.constant.int 128
    %int128_282 = torch.constant.int 128
    %229 = torch.prim.ListConstruct %int8_279, %int512_280, %int128_281, %int128_282 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %230 = torch.aten.view %228, %229 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %231 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_283 = torch.constant.int 0
    %232 = torch.aten.unsqueeze %231, %int0_283 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_284 = torch.constant.int 2
    %233 = torch.aten.unsqueeze %232, %int2_284 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_285 = torch.constant.int 3
    %234 = torch.aten.unsqueeze %233, %int3_285 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %235 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_286 = torch.constant.int 0
    %236 = torch.aten.unsqueeze %235, %int0_286 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_287 = torch.constant.int 2
    %237 = torch.aten.unsqueeze %236, %int2_287 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_288 = torch.constant.int 3
    %238 = torch.aten.unsqueeze %237, %int3_288 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %239 = torch.aten.mul.Tensor %230, %238 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_289 = torch.constant.int 1
    %240 = torch.aten.add.Tensor %239, %234, %int1_289 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_290 = torch.constant.int 5
    %241 = torch.prims.convert_element_type %240, %int5_290 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %242 = torch.aten.silu %241 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_291 = torch.constant.none
    %243 = torch.aten.clone %242, %none_291 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %244 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %245 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_292 = torch.constant.int 1
    %int1_293 = torch.constant.int 1
    %246 = torch.prim.ListConstruct %int1_292, %int1_293 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_294 = torch.constant.int 1
    %int1_295 = torch.constant.int 1
    %247 = torch.prim.ListConstruct %int1_294, %int1_295 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_296 = torch.constant.int 1
    %int1_297 = torch.constant.int 1
    %248 = torch.prim.ListConstruct %int1_296, %int1_297 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_298 = torch.constant.bool false
    %int0_299 = torch.constant.int 0
    %int0_300 = torch.constant.int 0
    %249 = torch.prim.ListConstruct %int0_299, %int0_300 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_301 = torch.constant.int 1
    %250 = torch.aten.convolution %243, %244, %245, %246, %247, %248, %false_298, %249, %int1_301 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_302 = torch.constant.int 1
    %251 = torch.aten.add.Tensor %191, %250, %int1_302 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_303 = torch.constant.int 1
    %252 = torch.aten.div.Scalar %251, %int1_303 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int5_304 = torch.constant.int 5
    %253 = torch.prims.convert_element_type %252, %int5_304 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_305 = torch.constant.int 8
    %int32_306 = torch.constant.int 32
    %int16_307 = torch.constant.int 16
    %int16384_308 = torch.constant.int 16384
    %254 = torch.prim.ListConstruct %int8_305, %int32_306, %int16_307, %int16384_308 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %255 = torch.aten.view %253, %254 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_309 = torch.constant.int 6
    %256 = torch.prims.convert_element_type %255, %int6_309 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_310 = torch.constant.int 2
    %int3_311 = torch.constant.int 3
    %257 = torch.prim.ListConstruct %int2_310, %int3_311 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_312 = torch.constant.int 0
    %true_313 = torch.constant.bool true
    %result0_314, %result1_315 = torch.aten.var_mean.correction %256, %257, %int0_312, %true_313 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_316 = torch.constant.float 9.9999999999999995E-7
    %int1_317 = torch.constant.int 1
    %258 = torch.aten.add.Scalar %result0_314, %float9.999990e-07_316, %int1_317 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %259 = torch.aten.rsqrt %258 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_318 = torch.constant.int 1
    %260 = torch.aten.sub.Tensor %255, %result1_315, %int1_318 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %261 = torch.aten.mul.Tensor %260, %259 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_319 = torch.constant.int 8
    %int512_320 = torch.constant.int 512
    %int128_321 = torch.constant.int 128
    %int128_322 = torch.constant.int 128
    %262 = torch.prim.ListConstruct %int8_319, %int512_320, %int128_321, %int128_322 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %263 = torch.aten.view %261, %262 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16>
    %264 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_323 = torch.constant.int 0
    %265 = torch.aten.unsqueeze %264, %int0_323 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_324 = torch.constant.int 2
    %266 = torch.aten.unsqueeze %265, %int2_324 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_325 = torch.constant.int 3
    %267 = torch.aten.unsqueeze %266, %int3_325 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16>
    %268 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_326 = torch.constant.int 0
    %269 = torch.aten.unsqueeze %268, %int0_326 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_327 = torch.constant.int 2
    %270 = torch.aten.unsqueeze %269, %int2_327 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_328 = torch.constant.int 3
    %271 = torch.aten.unsqueeze %270, %int3_328 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %272 = torch.aten.mul.Tensor %263, %271 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_329 = torch.constant.int 1
    %273 = torch.aten.add.Tensor %272, %267, %int1_329 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_330 = torch.constant.int 5
    %274 = torch.prims.convert_element_type %273, %int5_330 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %275 = torch.aten.silu %274 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %276 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16>
    %277 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_331 = torch.constant.int 1
    %int1_332 = torch.constant.int 1
    %278 = torch.prim.ListConstruct %int1_331, %int1_332 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_333 = torch.constant.int 1
    %int1_334 = torch.constant.int 1
    %279 = torch.prim.ListConstruct %int1_333, %int1_334 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_335 = torch.constant.int 1
    %int1_336 = torch.constant.int 1
    %280 = torch.prim.ListConstruct %int1_335, %int1_336 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_337 = torch.constant.bool false
    %int0_338 = torch.constant.int 0
    %int0_339 = torch.constant.int 0
    %281 = torch.prim.ListConstruct %int0_338, %int0_339 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_340 = torch.constant.int 1
    %282 = torch.aten.convolution %275, %276, %277, %278, %279, %280, %false_337, %281, %int1_340 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_341 = torch.constant.int 8
    %int32_342 = torch.constant.int 32
    %int16_343 = torch.constant.int 16
    %int16384_344 = torch.constant.int 16384
    %283 = torch.prim.ListConstruct %int8_341, %int32_342, %int16_343, %int16384_344 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %284 = torch.aten.view %282, %283 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_345 = torch.constant.int 6
    %285 = torch.prims.convert_element_type %284, %int6_345 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_346 = torch.constant.int 2
    %int3_347 = torch.constant.int 3
    %286 = torch.prim.ListConstruct %int2_346, %int3_347 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_348 = torch.constant.int 0
    %true_349 = torch.constant.bool true
    %result0_350, %result1_351 = torch.aten.var_mean.correction %285, %286, %int0_348, %true_349 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_352 = torch.constant.float 9.9999999999999995E-7
    %int1_353 = torch.constant.int 1
    %287 = torch.aten.add.Scalar %result0_350, %float9.999990e-07_352, %int1_353 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %288 = torch.aten.rsqrt %287 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_354 = torch.constant.int 1
    %289 = torch.aten.sub.Tensor %284, %result1_351, %int1_354 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %290 = torch.aten.mul.Tensor %289, %288 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_355 = torch.constant.int 8
    %int512_356 = torch.constant.int 512
    %int128_357 = torch.constant.int 128
    %int128_358 = torch.constant.int 128
    %291 = torch.prim.ListConstruct %int8_355, %int512_356, %int128_357, %int128_358 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %292 = torch.aten.view %290, %291 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16>
    %293 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_359 = torch.constant.int 0
    %294 = torch.aten.unsqueeze %293, %int0_359 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_360 = torch.constant.int 2
    %295 = torch.aten.unsqueeze %294, %int2_360 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_361 = torch.constant.int 3
    %296 = torch.aten.unsqueeze %295, %int3_361 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16>
    %297 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_362 = torch.constant.int 0
    %298 = torch.aten.unsqueeze %297, %int0_362 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_363 = torch.constant.int 2
    %299 = torch.aten.unsqueeze %298, %int2_363 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_364 = torch.constant.int 3
    %300 = torch.aten.unsqueeze %299, %int3_364 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %301 = torch.aten.mul.Tensor %292, %300 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_365 = torch.constant.int 1
    %302 = torch.aten.add.Tensor %301, %296, %int1_365 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_366 = torch.constant.int 5
    %303 = torch.prims.convert_element_type %302, %int5_366 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %304 = torch.aten.silu %303 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_367 = torch.constant.none
    %305 = torch.aten.clone %304, %none_367 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %306 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16>
    %307 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_368 = torch.constant.int 1
    %int1_369 = torch.constant.int 1
    %308 = torch.prim.ListConstruct %int1_368, %int1_369 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_370 = torch.constant.int 1
    %int1_371 = torch.constant.int 1
    %309 = torch.prim.ListConstruct %int1_370, %int1_371 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_372 = torch.constant.int 1
    %int1_373 = torch.constant.int 1
    %310 = torch.prim.ListConstruct %int1_372, %int1_373 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_374 = torch.constant.bool false
    %int0_375 = torch.constant.int 0
    %int0_376 = torch.constant.int 0
    %311 = torch.prim.ListConstruct %int0_375, %int0_376 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_377 = torch.constant.int 1
    %312 = torch.aten.convolution %305, %306, %307, %308, %309, %310, %false_374, %311, %int1_377 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_378 = torch.constant.int 1
    %313 = torch.aten.add.Tensor %253, %312, %int1_378 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %314 = torch.aten.div.Scalar %313, %float1.000000e00 : !torch.vtensor<[8,512,128,128],f16>, !torch.float -> !torch.vtensor<[8,512,128,128],f16>
    %int8_379 = torch.constant.int 8
    %int32_380 = torch.constant.int 32
    %int16_381 = torch.constant.int 16
    %int16384_382 = torch.constant.int 16384
    %315 = torch.prim.ListConstruct %int8_379, %int32_380, %int16_381, %int16384_382 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %316 = torch.aten.view %314, %315 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_383 = torch.constant.int 6
    %317 = torch.prims.convert_element_type %316, %int6_383 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_384 = torch.constant.int 2
    %int3_385 = torch.constant.int 3
    %318 = torch.prim.ListConstruct %int2_384, %int3_385 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_386 = torch.constant.int 0
    %true_387 = torch.constant.bool true
    %result0_388, %result1_389 = torch.aten.var_mean.correction %317, %318, %int0_386, %true_387 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_390 = torch.constant.float 9.9999999999999995E-7
    %int1_391 = torch.constant.int 1
    %319 = torch.aten.add.Scalar %result0_388, %float9.999990e-07_390, %int1_391 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %320 = torch.aten.rsqrt %319 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_392 = torch.constant.int 1
    %321 = torch.aten.sub.Tensor %316, %result1_389, %int1_392 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %322 = torch.aten.mul.Tensor %321, %320 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_393 = torch.constant.int 8
    %int512_394 = torch.constant.int 512
    %int128_395 = torch.constant.int 128
    %int128_396 = torch.constant.int 128
    %323 = torch.prim.ListConstruct %int8_393, %int512_394, %int128_395, %int128_396 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %324 = torch.aten.view %322, %323 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16>
    %325 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_397 = torch.constant.int 0
    %326 = torch.aten.unsqueeze %325, %int0_397 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_398 = torch.constant.int 2
    %327 = torch.aten.unsqueeze %326, %int2_398 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_399 = torch.constant.int 3
    %328 = torch.aten.unsqueeze %327, %int3_399 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16>
    %329 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_400 = torch.constant.int 0
    %330 = torch.aten.unsqueeze %329, %int0_400 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_401 = torch.constant.int 2
    %331 = torch.aten.unsqueeze %330, %int2_401 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_402 = torch.constant.int 3
    %332 = torch.aten.unsqueeze %331, %int3_402 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %333 = torch.aten.mul.Tensor %324, %332 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_403 = torch.constant.int 1
    %334 = torch.aten.add.Tensor %333, %328, %int1_403 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_404 = torch.constant.int 5
    %335 = torch.prims.convert_element_type %334, %int5_404 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %336 = torch.aten.silu %335 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %337 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16>
    %338 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_405 = torch.constant.int 1
    %int1_406 = torch.constant.int 1
    %339 = torch.prim.ListConstruct %int1_405, %int1_406 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_407 = torch.constant.int 1
    %int1_408 = torch.constant.int 1
    %340 = torch.prim.ListConstruct %int1_407, %int1_408 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_409 = torch.constant.int 1
    %int1_410 = torch.constant.int 1
    %341 = torch.prim.ListConstruct %int1_409, %int1_410 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_411 = torch.constant.bool false
    %int0_412 = torch.constant.int 0
    %int0_413 = torch.constant.int 0
    %342 = torch.prim.ListConstruct %int0_412, %int0_413 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_414 = torch.constant.int 1
    %343 = torch.aten.convolution %336, %337, %338, %339, %340, %341, %false_411, %342, %int1_414 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_415 = torch.constant.int 8
    %int32_416 = torch.constant.int 32
    %int16_417 = torch.constant.int 16
    %int16384_418 = torch.constant.int 16384
    %344 = torch.prim.ListConstruct %int8_415, %int32_416, %int16_417, %int16384_418 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %345 = torch.aten.view %343, %344 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_419 = torch.constant.int 6
    %346 = torch.prims.convert_element_type %345, %int6_419 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_420 = torch.constant.int 2
    %int3_421 = torch.constant.int 3
    %347 = torch.prim.ListConstruct %int2_420, %int3_421 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_422 = torch.constant.int 0
    %true_423 = torch.constant.bool true
    %result0_424, %result1_425 = torch.aten.var_mean.correction %346, %347, %int0_422, %true_423 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_426 = torch.constant.float 9.9999999999999995E-7
    %int1_427 = torch.constant.int 1
    %348 = torch.aten.add.Scalar %result0_424, %float9.999990e-07_426, %int1_427 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %349 = torch.aten.rsqrt %348 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_428 = torch.constant.int 1
    %350 = torch.aten.sub.Tensor %345, %result1_425, %int1_428 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %351 = torch.aten.mul.Tensor %350, %349 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_429 = torch.constant.int 8
    %int512_430 = torch.constant.int 512
    %int128_431 = torch.constant.int 128
    %int128_432 = torch.constant.int 128
    %352 = torch.prim.ListConstruct %int8_429, %int512_430, %int128_431, %int128_432 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %353 = torch.aten.view %351, %352 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16>
    %354 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_433 = torch.constant.int 0
    %355 = torch.aten.unsqueeze %354, %int0_433 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_434 = torch.constant.int 2
    %356 = torch.aten.unsqueeze %355, %int2_434 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_435 = torch.constant.int 3
    %357 = torch.aten.unsqueeze %356, %int3_435 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16>
    %358 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_436 = torch.constant.int 0
    %359 = torch.aten.unsqueeze %358, %int0_436 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_437 = torch.constant.int 2
    %360 = torch.aten.unsqueeze %359, %int2_437 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_438 = torch.constant.int 3
    %361 = torch.aten.unsqueeze %360, %int3_438 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %362 = torch.aten.mul.Tensor %353, %361 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_439 = torch.constant.int 1
    %363 = torch.aten.add.Tensor %362, %357, %int1_439 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_440 = torch.constant.int 5
    %364 = torch.prims.convert_element_type %363, %int5_440 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %365 = torch.aten.silu %364 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_441 = torch.constant.none
    %366 = torch.aten.clone %365, %none_441 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %367 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16>
    %368 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_442 = torch.constant.int 1
    %int1_443 = torch.constant.int 1
    %369 = torch.prim.ListConstruct %int1_442, %int1_443 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_444 = torch.constant.int 1
    %int1_445 = torch.constant.int 1
    %370 = torch.prim.ListConstruct %int1_444, %int1_445 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_446 = torch.constant.int 1
    %int1_447 = torch.constant.int 1
    %371 = torch.prim.ListConstruct %int1_446, %int1_447 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_448 = torch.constant.bool false
    %int0_449 = torch.constant.int 0
    %int0_450 = torch.constant.int 0
    %372 = torch.prim.ListConstruct %int0_449, %int0_450 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_451 = torch.constant.int 1
    %373 = torch.aten.convolution %366, %367, %368, %369, %370, %371, %false_448, %372, %int1_451 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_452 = torch.constant.int 1
    %374 = torch.aten.add.Tensor %314, %373, %int1_452 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %float1.000000e00_453 = torch.constant.float 1.000000e+00
    %375 = torch.aten.div.Scalar %374, %float1.000000e00_453 : !torch.vtensor<[8,512,128,128],f16>, !torch.float -> !torch.vtensor<[8,512,128,128],f16>
    %int8_454 = torch.constant.int 8
    %int32_455 = torch.constant.int 32
    %int16_456 = torch.constant.int 16
    %int16384_457 = torch.constant.int 16384
    %376 = torch.prim.ListConstruct %int8_454, %int32_455, %int16_456, %int16384_457 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %377 = torch.aten.view %375, %376 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_458 = torch.constant.int 6
    %378 = torch.prims.convert_element_type %377, %int6_458 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_459 = torch.constant.int 2
    %int3_460 = torch.constant.int 3
    %379 = torch.prim.ListConstruct %int2_459, %int3_460 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_461 = torch.constant.int 0
    %true_462 = torch.constant.bool true
    %result0_463, %result1_464 = torch.aten.var_mean.correction %378, %379, %int0_461, %true_462 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_465 = torch.constant.float 9.9999999999999995E-7
    %int1_466 = torch.constant.int 1
    %380 = torch.aten.add.Scalar %result0_463, %float9.999990e-07_465, %int1_466 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %381 = torch.aten.rsqrt %380 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_467 = torch.constant.int 1
    %382 = torch.aten.sub.Tensor %377, %result1_464, %int1_467 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %383 = torch.aten.mul.Tensor %382, %381 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_468 = torch.constant.int 8
    %int512_469 = torch.constant.int 512
    %int128_470 = torch.constant.int 128
    %int128_471 = torch.constant.int 128
    %384 = torch.prim.ListConstruct %int8_468, %int512_469, %int128_470, %int128_471 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %385 = torch.aten.view %383, %384 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16>
    %386 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_472 = torch.constant.int 0
    %387 = torch.aten.unsqueeze %386, %int0_472 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_473 = torch.constant.int 2
    %388 = torch.aten.unsqueeze %387, %int2_473 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_474 = torch.constant.int 3
    %389 = torch.aten.unsqueeze %388, %int3_474 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16>
    %390 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_475 = torch.constant.int 0
    %391 = torch.aten.unsqueeze %390, %int0_475 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_476 = torch.constant.int 2
    %392 = torch.aten.unsqueeze %391, %int2_476 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_477 = torch.constant.int 3
    %393 = torch.aten.unsqueeze %392, %int3_477 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %394 = torch.aten.mul.Tensor %385, %393 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_478 = torch.constant.int 1
    %395 = torch.aten.add.Tensor %394, %389, %int1_478 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_479 = torch.constant.int 5
    %396 = torch.prims.convert_element_type %395, %int5_479 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %397 = torch.aten.silu %396 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %398 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16>
    %399 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_480 = torch.constant.int 1
    %int1_481 = torch.constant.int 1
    %400 = torch.prim.ListConstruct %int1_480, %int1_481 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_482 = torch.constant.int 1
    %int1_483 = torch.constant.int 1
    %401 = torch.prim.ListConstruct %int1_482, %int1_483 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_484 = torch.constant.int 1
    %int1_485 = torch.constant.int 1
    %402 = torch.prim.ListConstruct %int1_484, %int1_485 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_486 = torch.constant.bool false
    %int0_487 = torch.constant.int 0
    %int0_488 = torch.constant.int 0
    %403 = torch.prim.ListConstruct %int0_487, %int0_488 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_489 = torch.constant.int 1
    %404 = torch.aten.convolution %397, %398, %399, %400, %401, %402, %false_486, %403, %int1_489 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_490 = torch.constant.int 8
    %int32_491 = torch.constant.int 32
    %int16_492 = torch.constant.int 16
    %int16384_493 = torch.constant.int 16384
    %405 = torch.prim.ListConstruct %int8_490, %int32_491, %int16_492, %int16384_493 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %406 = torch.aten.view %404, %405 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_494 = torch.constant.int 6
    %407 = torch.prims.convert_element_type %406, %int6_494 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_495 = torch.constant.int 2
    %int3_496 = torch.constant.int 3
    %408 = torch.prim.ListConstruct %int2_495, %int3_496 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_497 = torch.constant.int 0
    %true_498 = torch.constant.bool true
    %result0_499, %result1_500 = torch.aten.var_mean.correction %407, %408, %int0_497, %true_498 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_501 = torch.constant.float 9.9999999999999995E-7
    %int1_502 = torch.constant.int 1
    %409 = torch.aten.add.Scalar %result0_499, %float9.999990e-07_501, %int1_502 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %410 = torch.aten.rsqrt %409 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_503 = torch.constant.int 1
    %411 = torch.aten.sub.Tensor %406, %result1_500, %int1_503 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %412 = torch.aten.mul.Tensor %411, %410 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_504 = torch.constant.int 8
    %int512_505 = torch.constant.int 512
    %int128_506 = torch.constant.int 128
    %int128_507 = torch.constant.int 128
    %413 = torch.prim.ListConstruct %int8_504, %int512_505, %int128_506, %int128_507 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %414 = torch.aten.view %412, %413 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16>
    %415 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_508 = torch.constant.int 0
    %416 = torch.aten.unsqueeze %415, %int0_508 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_509 = torch.constant.int 2
    %417 = torch.aten.unsqueeze %416, %int2_509 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_510 = torch.constant.int 3
    %418 = torch.aten.unsqueeze %417, %int3_510 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16>
    %419 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_511 = torch.constant.int 0
    %420 = torch.aten.unsqueeze %419, %int0_511 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_512 = torch.constant.int 2
    %421 = torch.aten.unsqueeze %420, %int2_512 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_513 = torch.constant.int 3
    %422 = torch.aten.unsqueeze %421, %int3_513 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %423 = torch.aten.mul.Tensor %414, %422 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_514 = torch.constant.int 1
    %424 = torch.aten.add.Tensor %423, %418, %int1_514 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_515 = torch.constant.int 5
    %425 = torch.prims.convert_element_type %424, %int5_515 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %426 = torch.aten.silu %425 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_516 = torch.constant.none
    %427 = torch.aten.clone %426, %none_516 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %428 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16>
    %429 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_517 = torch.constant.int 1
    %int1_518 = torch.constant.int 1
    %430 = torch.prim.ListConstruct %int1_517, %int1_518 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_519 = torch.constant.int 1
    %int1_520 = torch.constant.int 1
    %431 = torch.prim.ListConstruct %int1_519, %int1_520 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_521 = torch.constant.int 1
    %int1_522 = torch.constant.int 1
    %432 = torch.prim.ListConstruct %int1_521, %int1_522 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_523 = torch.constant.bool false
    %int0_524 = torch.constant.int 0
    %int0_525 = torch.constant.int 0
    %433 = torch.prim.ListConstruct %int0_524, %int0_525 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_526 = torch.constant.int 1
    %434 = torch.aten.convolution %427, %428, %429, %430, %431, %432, %false_523, %433, %int1_526 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_527 = torch.constant.int 1
    %435 = torch.aten.add.Tensor %375, %434, %int1_527 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %float1.000000e00_528 = torch.constant.float 1.000000e+00
    %436 = torch.aten.div.Scalar %435, %float1.000000e00_528 : !torch.vtensor<[8,512,128,128],f16>, !torch.float -> !torch.vtensor<[8,512,128,128],f16>
    %int6_529 = torch.constant.int 6
    %437 = torch.prims.convert_element_type %436, %int6_529 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int256 = torch.constant.int 256
    %int6_530 = torch.constant.int 6
    %none_531 = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_532 = torch.constant.bool false
    %438 = torch.aten.arange %int256, %int6_530, %none_531, %cpu, %false_532 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int1_533 = torch.constant.int 1
    %439 = torch.aten.add.Scalar %438, %float0.000000e00, %int1_533 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %440 = torch.aten.mul.Scalar %439, %float5.000000e-01 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4 = torch.constant.int 4
    %441 = torch.prims.convert_element_type %440, %int4 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %int-1_534 = torch.constant.int -1
    %442 = torch.aten.unsqueeze %441, %int-1_534 : !torch.vtensor<[256],si64>, !torch.int -> !torch.vtensor<[256,1],si64>
    %int256_535 = torch.constant.int 256
    %int6_536 = torch.constant.int 6
    %none_537 = torch.constant.none
    %cpu_538 = torch.constant.device "cpu"
    %false_539 = torch.constant.bool false
    %443 = torch.aten.arange %int256_535, %int6_536, %none_537, %cpu_538, %false_539 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00_540 = torch.constant.float 0.000000e+00
    %int1_541 = torch.constant.int 1
    %444 = torch.aten.add.Scalar %443, %float0.000000e00_540, %int1_541 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01_542 = torch.constant.float 5.000000e-01
    %445 = torch.aten.mul.Scalar %444, %float5.000000e-01_542 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4_543 = torch.constant.int 4
    %446 = torch.prims.convert_element_type %445, %int4_543 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %none_544 = torch.constant.none
    %none_545 = torch.constant.none
    %447 = torch.prim.ListConstruct %none_544, %none_545, %442, %446 : (!torch.none, !torch.none, !torch.vtensor<[256,1],si64>, !torch.vtensor<[256],si64>) -> !torch.list<optional<vtensor>>
    %448 = torch.aten.index.Tensor %437, %447 : !torch.vtensor<[8,512,128,128],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[8,512,256,256],f32>
    %int2_546 = torch.constant.int 2
    %449 = torch.aten.clone %448, %int2_546 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_547 = torch.constant.int 5
    %450 = torch.prims.convert_element_type %449, %int5_547 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %451 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16>
    %452 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_548 = torch.constant.int 1
    %int1_549 = torch.constant.int 1
    %453 = torch.prim.ListConstruct %int1_548, %int1_549 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_550 = torch.constant.int 1
    %int1_551 = torch.constant.int 1
    %454 = torch.prim.ListConstruct %int1_550, %int1_551 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_552 = torch.constant.int 1
    %int1_553 = torch.constant.int 1
    %455 = torch.prim.ListConstruct %int1_552, %int1_553 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_554 = torch.constant.bool false
    %int0_555 = torch.constant.int 0
    %int0_556 = torch.constant.int 0
    %456 = torch.prim.ListConstruct %int0_555, %int0_556 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_557 = torch.constant.int 1
    %457 = torch.aten.convolution %450, %451, %452, %453, %454, %455, %false_554, %456, %int1_557 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_558 = torch.constant.int 8
    %int32_559 = torch.constant.int 32
    %int16_560 = torch.constant.int 16
    %int65536 = torch.constant.int 65536
    %458 = torch.prim.ListConstruct %int8_558, %int32_559, %int16_560, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %459 = torch.aten.view %457, %458 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_561 = torch.constant.int 6
    %460 = torch.prims.convert_element_type %459, %int6_561 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_562 = torch.constant.int 2
    %int3_563 = torch.constant.int 3
    %461 = torch.prim.ListConstruct %int2_562, %int3_563 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_564 = torch.constant.int 0
    %true_565 = torch.constant.bool true
    %result0_566, %result1_567 = torch.aten.var_mean.correction %460, %461, %int0_564, %true_565 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_568 = torch.constant.float 9.9999999999999995E-7
    %int1_569 = torch.constant.int 1
    %462 = torch.aten.add.Scalar %result0_566, %float9.999990e-07_568, %int1_569 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %463 = torch.aten.rsqrt %462 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_570 = torch.constant.int 1
    %464 = torch.aten.sub.Tensor %459, %result1_567, %int1_570 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %465 = torch.aten.mul.Tensor %464, %463 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_571 = torch.constant.int 8
    %int512_572 = torch.constant.int 512
    %int256_573 = torch.constant.int 256
    %int256_574 = torch.constant.int 256
    %466 = torch.prim.ListConstruct %int8_571, %int512_572, %int256_573, %int256_574 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %467 = torch.aten.view %465, %466 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16>
    %468 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_575 = torch.constant.int 0
    %469 = torch.aten.unsqueeze %468, %int0_575 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_576 = torch.constant.int 2
    %470 = torch.aten.unsqueeze %469, %int2_576 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_577 = torch.constant.int 3
    %471 = torch.aten.unsqueeze %470, %int3_577 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16>
    %472 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_578 = torch.constant.int 0
    %473 = torch.aten.unsqueeze %472, %int0_578 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_579 = torch.constant.int 2
    %474 = torch.aten.unsqueeze %473, %int2_579 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_580 = torch.constant.int 3
    %475 = torch.aten.unsqueeze %474, %int3_580 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %476 = torch.aten.mul.Tensor %467, %475 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_581 = torch.constant.int 1
    %477 = torch.aten.add.Tensor %476, %471, %int1_581 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_582 = torch.constant.int 5
    %478 = torch.prims.convert_element_type %477, %int5_582 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %479 = torch.aten.silu %478 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %480 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16>
    %481 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_583 = torch.constant.int 1
    %int1_584 = torch.constant.int 1
    %482 = torch.prim.ListConstruct %int1_583, %int1_584 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_585 = torch.constant.int 1
    %int1_586 = torch.constant.int 1
    %483 = torch.prim.ListConstruct %int1_585, %int1_586 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_587 = torch.constant.int 1
    %int1_588 = torch.constant.int 1
    %484 = torch.prim.ListConstruct %int1_587, %int1_588 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_589 = torch.constant.bool false
    %int0_590 = torch.constant.int 0
    %int0_591 = torch.constant.int 0
    %485 = torch.prim.ListConstruct %int0_590, %int0_591 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_592 = torch.constant.int 1
    %486 = torch.aten.convolution %479, %480, %481, %482, %483, %484, %false_589, %485, %int1_592 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_593 = torch.constant.int 8
    %int32_594 = torch.constant.int 32
    %int16_595 = torch.constant.int 16
    %int65536_596 = torch.constant.int 65536
    %487 = torch.prim.ListConstruct %int8_593, %int32_594, %int16_595, %int65536_596 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %488 = torch.aten.view %486, %487 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_597 = torch.constant.int 6
    %489 = torch.prims.convert_element_type %488, %int6_597 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_598 = torch.constant.int 2
    %int3_599 = torch.constant.int 3
    %490 = torch.prim.ListConstruct %int2_598, %int3_599 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_600 = torch.constant.int 0
    %true_601 = torch.constant.bool true
    %result0_602, %result1_603 = torch.aten.var_mean.correction %489, %490, %int0_600, %true_601 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_604 = torch.constant.float 9.9999999999999995E-7
    %int1_605 = torch.constant.int 1
    %491 = torch.aten.add.Scalar %result0_602, %float9.999990e-07_604, %int1_605 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %492 = torch.aten.rsqrt %491 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_606 = torch.constant.int 1
    %493 = torch.aten.sub.Tensor %488, %result1_603, %int1_606 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %494 = torch.aten.mul.Tensor %493, %492 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_607 = torch.constant.int 8
    %int512_608 = torch.constant.int 512
    %int256_609 = torch.constant.int 256
    %int256_610 = torch.constant.int 256
    %495 = torch.prim.ListConstruct %int8_607, %int512_608, %int256_609, %int256_610 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %496 = torch.aten.view %494, %495 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16>
    %497 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_611 = torch.constant.int 0
    %498 = torch.aten.unsqueeze %497, %int0_611 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_612 = torch.constant.int 2
    %499 = torch.aten.unsqueeze %498, %int2_612 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_613 = torch.constant.int 3
    %500 = torch.aten.unsqueeze %499, %int3_613 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16>
    %501 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_614 = torch.constant.int 0
    %502 = torch.aten.unsqueeze %501, %int0_614 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_615 = torch.constant.int 2
    %503 = torch.aten.unsqueeze %502, %int2_615 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_616 = torch.constant.int 3
    %504 = torch.aten.unsqueeze %503, %int3_616 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %505 = torch.aten.mul.Tensor %496, %504 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_617 = torch.constant.int 1
    %506 = torch.aten.add.Tensor %505, %500, %int1_617 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_618 = torch.constant.int 5
    %507 = torch.prims.convert_element_type %506, %int5_618 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %508 = torch.aten.silu %507 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %none_619 = torch.constant.none
    %509 = torch.aten.clone %508, %none_619 : !torch.vtensor<[8,512,256,256],f16>, !torch.none -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %510 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16>
    %511 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_620 = torch.constant.int 1
    %int1_621 = torch.constant.int 1
    %512 = torch.prim.ListConstruct %int1_620, %int1_621 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_622 = torch.constant.int 1
    %int1_623 = torch.constant.int 1
    %513 = torch.prim.ListConstruct %int1_622, %int1_623 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_624 = torch.constant.int 1
    %int1_625 = torch.constant.int 1
    %514 = torch.prim.ListConstruct %int1_624, %int1_625 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_626 = torch.constant.bool false
    %int0_627 = torch.constant.int 0
    %int0_628 = torch.constant.int 0
    %515 = torch.prim.ListConstruct %int0_627, %int0_628 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_629 = torch.constant.int 1
    %516 = torch.aten.convolution %509, %510, %511, %512, %513, %514, %false_626, %515, %int1_629 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int1_630 = torch.constant.int 1
    %517 = torch.aten.add.Tensor %457, %516, %int1_630 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %float1.000000e00_631 = torch.constant.float 1.000000e+00
    %518 = torch.aten.div.Scalar %517, %float1.000000e00_631 : !torch.vtensor<[8,512,256,256],f16>, !torch.float -> !torch.vtensor<[8,512,256,256],f16>
    %int8_632 = torch.constant.int 8
    %int32_633 = torch.constant.int 32
    %int16_634 = torch.constant.int 16
    %int65536_635 = torch.constant.int 65536
    %519 = torch.prim.ListConstruct %int8_632, %int32_633, %int16_634, %int65536_635 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %520 = torch.aten.view %518, %519 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_636 = torch.constant.int 6
    %521 = torch.prims.convert_element_type %520, %int6_636 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_637 = torch.constant.int 2
    %int3_638 = torch.constant.int 3
    %522 = torch.prim.ListConstruct %int2_637, %int3_638 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_639 = torch.constant.int 0
    %true_640 = torch.constant.bool true
    %result0_641, %result1_642 = torch.aten.var_mean.correction %521, %522, %int0_639, %true_640 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_643 = torch.constant.float 9.9999999999999995E-7
    %int1_644 = torch.constant.int 1
    %523 = torch.aten.add.Scalar %result0_641, %float9.999990e-07_643, %int1_644 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %524 = torch.aten.rsqrt %523 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_645 = torch.constant.int 1
    %525 = torch.aten.sub.Tensor %520, %result1_642, %int1_645 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %526 = torch.aten.mul.Tensor %525, %524 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_646 = torch.constant.int 8
    %int512_647 = torch.constant.int 512
    %int256_648 = torch.constant.int 256
    %int256_649 = torch.constant.int 256
    %527 = torch.prim.ListConstruct %int8_646, %int512_647, %int256_648, %int256_649 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %528 = torch.aten.view %526, %527 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16>
    %529 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_650 = torch.constant.int 0
    %530 = torch.aten.unsqueeze %529, %int0_650 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_651 = torch.constant.int 2
    %531 = torch.aten.unsqueeze %530, %int2_651 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_652 = torch.constant.int 3
    %532 = torch.aten.unsqueeze %531, %int3_652 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16>
    %533 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_653 = torch.constant.int 0
    %534 = torch.aten.unsqueeze %533, %int0_653 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_654 = torch.constant.int 2
    %535 = torch.aten.unsqueeze %534, %int2_654 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_655 = torch.constant.int 3
    %536 = torch.aten.unsqueeze %535, %int3_655 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %537 = torch.aten.mul.Tensor %528, %536 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_656 = torch.constant.int 1
    %538 = torch.aten.add.Tensor %537, %532, %int1_656 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_657 = torch.constant.int 5
    %539 = torch.prims.convert_element_type %538, %int5_657 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %540 = torch.aten.silu %539 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %541 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16>
    %542 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_658 = torch.constant.int 1
    %int1_659 = torch.constant.int 1
    %543 = torch.prim.ListConstruct %int1_658, %int1_659 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_660 = torch.constant.int 1
    %int1_661 = torch.constant.int 1
    %544 = torch.prim.ListConstruct %int1_660, %int1_661 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_662 = torch.constant.int 1
    %int1_663 = torch.constant.int 1
    %545 = torch.prim.ListConstruct %int1_662, %int1_663 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_664 = torch.constant.bool false
    %int0_665 = torch.constant.int 0
    %int0_666 = torch.constant.int 0
    %546 = torch.prim.ListConstruct %int0_665, %int0_666 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_667 = torch.constant.int 1
    %547 = torch.aten.convolution %540, %541, %542, %543, %544, %545, %false_664, %546, %int1_667 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_668 = torch.constant.int 8
    %int32_669 = torch.constant.int 32
    %int16_670 = torch.constant.int 16
    %int65536_671 = torch.constant.int 65536
    %548 = torch.prim.ListConstruct %int8_668, %int32_669, %int16_670, %int65536_671 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %549 = torch.aten.view %547, %548 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_672 = torch.constant.int 6
    %550 = torch.prims.convert_element_type %549, %int6_672 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_673 = torch.constant.int 2
    %int3_674 = torch.constant.int 3
    %551 = torch.prim.ListConstruct %int2_673, %int3_674 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_675 = torch.constant.int 0
    %true_676 = torch.constant.bool true
    %result0_677, %result1_678 = torch.aten.var_mean.correction %550, %551, %int0_675, %true_676 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_679 = torch.constant.float 9.9999999999999995E-7
    %int1_680 = torch.constant.int 1
    %552 = torch.aten.add.Scalar %result0_677, %float9.999990e-07_679, %int1_680 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %553 = torch.aten.rsqrt %552 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_681 = torch.constant.int 1
    %554 = torch.aten.sub.Tensor %549, %result1_678, %int1_681 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %555 = torch.aten.mul.Tensor %554, %553 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_682 = torch.constant.int 8
    %int512_683 = torch.constant.int 512
    %int256_684 = torch.constant.int 256
    %int256_685 = torch.constant.int 256
    %556 = torch.prim.ListConstruct %int8_682, %int512_683, %int256_684, %int256_685 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %557 = torch.aten.view %555, %556 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16>
    %558 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_686 = torch.constant.int 0
    %559 = torch.aten.unsqueeze %558, %int0_686 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_687 = torch.constant.int 2
    %560 = torch.aten.unsqueeze %559, %int2_687 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_688 = torch.constant.int 3
    %561 = torch.aten.unsqueeze %560, %int3_688 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16>
    %562 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_689 = torch.constant.int 0
    %563 = torch.aten.unsqueeze %562, %int0_689 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_690 = torch.constant.int 2
    %564 = torch.aten.unsqueeze %563, %int2_690 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_691 = torch.constant.int 3
    %565 = torch.aten.unsqueeze %564, %int3_691 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %566 = torch.aten.mul.Tensor %557, %565 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_692 = torch.constant.int 1
    %567 = torch.aten.add.Tensor %566, %561, %int1_692 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_693 = torch.constant.int 5
    %568 = torch.prims.convert_element_type %567, %int5_693 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %569 = torch.aten.silu %568 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %none_694 = torch.constant.none
    %570 = torch.aten.clone %569, %none_694 : !torch.vtensor<[8,512,256,256],f16>, !torch.none -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %571 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16>
    %572 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_695 = torch.constant.int 1
    %int1_696 = torch.constant.int 1
    %573 = torch.prim.ListConstruct %int1_695, %int1_696 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_697 = torch.constant.int 1
    %int1_698 = torch.constant.int 1
    %574 = torch.prim.ListConstruct %int1_697, %int1_698 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_699 = torch.constant.int 1
    %int1_700 = torch.constant.int 1
    %575 = torch.prim.ListConstruct %int1_699, %int1_700 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_701 = torch.constant.bool false
    %int0_702 = torch.constant.int 0
    %int0_703 = torch.constant.int 0
    %576 = torch.prim.ListConstruct %int0_702, %int0_703 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_704 = torch.constant.int 1
    %577 = torch.aten.convolution %570, %571, %572, %573, %574, %575, %false_701, %576, %int1_704 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int1_705 = torch.constant.int 1
    %578 = torch.aten.add.Tensor %518, %577, %int1_705 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %float1.000000e00_706 = torch.constant.float 1.000000e+00
    %579 = torch.aten.div.Scalar %578, %float1.000000e00_706 : !torch.vtensor<[8,512,256,256],f16>, !torch.float -> !torch.vtensor<[8,512,256,256],f16>
    %int8_707 = torch.constant.int 8
    %int32_708 = torch.constant.int 32
    %int16_709 = torch.constant.int 16
    %int65536_710 = torch.constant.int 65536
    %580 = torch.prim.ListConstruct %int8_707, %int32_708, %int16_709, %int65536_710 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %581 = torch.aten.view %579, %580 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_711 = torch.constant.int 6
    %582 = torch.prims.convert_element_type %581, %int6_711 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_712 = torch.constant.int 2
    %int3_713 = torch.constant.int 3
    %583 = torch.prim.ListConstruct %int2_712, %int3_713 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_714 = torch.constant.int 0
    %true_715 = torch.constant.bool true
    %result0_716, %result1_717 = torch.aten.var_mean.correction %582, %583, %int0_714, %true_715 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_718 = torch.constant.float 9.9999999999999995E-7
    %int1_719 = torch.constant.int 1
    %584 = torch.aten.add.Scalar %result0_716, %float9.999990e-07_718, %int1_719 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %585 = torch.aten.rsqrt %584 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_720 = torch.constant.int 1
    %586 = torch.aten.sub.Tensor %581, %result1_717, %int1_720 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %587 = torch.aten.mul.Tensor %586, %585 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_721 = torch.constant.int 8
    %int512_722 = torch.constant.int 512
    %int256_723 = torch.constant.int 256
    %int256_724 = torch.constant.int 256
    %588 = torch.prim.ListConstruct %int8_721, %int512_722, %int256_723, %int256_724 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %589 = torch.aten.view %587, %588 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16>
    %590 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_725 = torch.constant.int 0
    %591 = torch.aten.unsqueeze %590, %int0_725 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_726 = torch.constant.int 2
    %592 = torch.aten.unsqueeze %591, %int2_726 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_727 = torch.constant.int 3
    %593 = torch.aten.unsqueeze %592, %int3_727 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16>
    %594 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_728 = torch.constant.int 0
    %595 = torch.aten.unsqueeze %594, %int0_728 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_729 = torch.constant.int 2
    %596 = torch.aten.unsqueeze %595, %int2_729 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_730 = torch.constant.int 3
    %597 = torch.aten.unsqueeze %596, %int3_730 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %598 = torch.aten.mul.Tensor %589, %597 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_731 = torch.constant.int 1
    %599 = torch.aten.add.Tensor %598, %593, %int1_731 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_732 = torch.constant.int 5
    %600 = torch.prims.convert_element_type %599, %int5_732 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %601 = torch.aten.silu %600 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %602 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16>
    %603 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_733 = torch.constant.int 1
    %int1_734 = torch.constant.int 1
    %604 = torch.prim.ListConstruct %int1_733, %int1_734 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_735 = torch.constant.int 1
    %int1_736 = torch.constant.int 1
    %605 = torch.prim.ListConstruct %int1_735, %int1_736 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_737 = torch.constant.int 1
    %int1_738 = torch.constant.int 1
    %606 = torch.prim.ListConstruct %int1_737, %int1_738 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_739 = torch.constant.bool false
    %int0_740 = torch.constant.int 0
    %int0_741 = torch.constant.int 0
    %607 = torch.prim.ListConstruct %int0_740, %int0_741 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_742 = torch.constant.int 1
    %608 = torch.aten.convolution %601, %602, %603, %604, %605, %606, %false_739, %607, %int1_742 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_743 = torch.constant.int 8
    %int32_744 = torch.constant.int 32
    %int16_745 = torch.constant.int 16
    %int65536_746 = torch.constant.int 65536
    %609 = torch.prim.ListConstruct %int8_743, %int32_744, %int16_745, %int65536_746 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %610 = torch.aten.view %608, %609 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_747 = torch.constant.int 6
    %611 = torch.prims.convert_element_type %610, %int6_747 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_748 = torch.constant.int 2
    %int3_749 = torch.constant.int 3
    %612 = torch.prim.ListConstruct %int2_748, %int3_749 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_750 = torch.constant.int 0
    %true_751 = torch.constant.bool true
    %result0_752, %result1_753 = torch.aten.var_mean.correction %611, %612, %int0_750, %true_751 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_754 = torch.constant.float 9.9999999999999995E-7
    %int1_755 = torch.constant.int 1
    %613 = torch.aten.add.Scalar %result0_752, %float9.999990e-07_754, %int1_755 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %614 = torch.aten.rsqrt %613 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_756 = torch.constant.int 1
    %615 = torch.aten.sub.Tensor %610, %result1_753, %int1_756 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %616 = torch.aten.mul.Tensor %615, %614 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_757 = torch.constant.int 8
    %int512_758 = torch.constant.int 512
    %int256_759 = torch.constant.int 256
    %int256_760 = torch.constant.int 256
    %617 = torch.prim.ListConstruct %int8_757, %int512_758, %int256_759, %int256_760 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %618 = torch.aten.view %616, %617 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16>
    %619 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_761 = torch.constant.int 0
    %620 = torch.aten.unsqueeze %619, %int0_761 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_762 = torch.constant.int 2
    %621 = torch.aten.unsqueeze %620, %int2_762 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_763 = torch.constant.int 3
    %622 = torch.aten.unsqueeze %621, %int3_763 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16>
    %623 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_764 = torch.constant.int 0
    %624 = torch.aten.unsqueeze %623, %int0_764 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_765 = torch.constant.int 2
    %625 = torch.aten.unsqueeze %624, %int2_765 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_766 = torch.constant.int 3
    %626 = torch.aten.unsqueeze %625, %int3_766 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %627 = torch.aten.mul.Tensor %618, %626 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_767 = torch.constant.int 1
    %628 = torch.aten.add.Tensor %627, %622, %int1_767 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_768 = torch.constant.int 5
    %629 = torch.prims.convert_element_type %628, %int5_768 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %630 = torch.aten.silu %629 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %none_769 = torch.constant.none
    %631 = torch.aten.clone %630, %none_769 : !torch.vtensor<[8,512,256,256],f16>, !torch.none -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %632 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16>
    %633 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_770 = torch.constant.int 1
    %int1_771 = torch.constant.int 1
    %634 = torch.prim.ListConstruct %int1_770, %int1_771 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_772 = torch.constant.int 1
    %int1_773 = torch.constant.int 1
    %635 = torch.prim.ListConstruct %int1_772, %int1_773 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_774 = torch.constant.int 1
    %int1_775 = torch.constant.int 1
    %636 = torch.prim.ListConstruct %int1_774, %int1_775 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_776 = torch.constant.bool false
    %int0_777 = torch.constant.int 0
    %int0_778 = torch.constant.int 0
    %637 = torch.prim.ListConstruct %int0_777, %int0_778 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_779 = torch.constant.int 1
    %638 = torch.aten.convolution %631, %632, %633, %634, %635, %636, %false_776, %637, %int1_779 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int1_780 = torch.constant.int 1
    %639 = torch.aten.add.Tensor %579, %638, %int1_780 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %float1.000000e00_781 = torch.constant.float 1.000000e+00
    %640 = torch.aten.div.Scalar %639, %float1.000000e00_781 : !torch.vtensor<[8,512,256,256],f16>, !torch.float -> !torch.vtensor<[8,512,256,256],f16>
    %int6_782 = torch.constant.int 6
    %641 = torch.prims.convert_element_type %640, %int6_782 : !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int512_783 = torch.constant.int 512
    %int6_784 = torch.constant.int 6
    %none_785 = torch.constant.none
    %cpu_786 = torch.constant.device "cpu"
    %false_787 = torch.constant.bool false
    %642 = torch.aten.arange %int512_783, %int6_784, %none_785, %cpu_786, %false_787 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_788 = torch.constant.float 0.000000e+00
    %int1_789 = torch.constant.int 1
    %643 = torch.aten.add.Scalar %642, %float0.000000e00_788, %int1_789 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_790 = torch.constant.float 5.000000e-01
    %644 = torch.aten.mul.Scalar %643, %float5.000000e-01_790 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_791 = torch.constant.int 4
    %645 = torch.prims.convert_element_type %644, %int4_791 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %int-1_792 = torch.constant.int -1
    %646 = torch.aten.unsqueeze %645, %int-1_792 : !torch.vtensor<[512],si64>, !torch.int -> !torch.vtensor<[512,1],si64>
    %int512_793 = torch.constant.int 512
    %int6_794 = torch.constant.int 6
    %none_795 = torch.constant.none
    %cpu_796 = torch.constant.device "cpu"
    %false_797 = torch.constant.bool false
    %647 = torch.aten.arange %int512_793, %int6_794, %none_795, %cpu_796, %false_797 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_798 = torch.constant.float 0.000000e+00
    %int1_799 = torch.constant.int 1
    %648 = torch.aten.add.Scalar %647, %float0.000000e00_798, %int1_799 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_800 = torch.constant.float 5.000000e-01
    %649 = torch.aten.mul.Scalar %648, %float5.000000e-01_800 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_801 = torch.constant.int 4
    %650 = torch.prims.convert_element_type %649, %int4_801 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %none_802 = torch.constant.none
    %none_803 = torch.constant.none
    %651 = torch.prim.ListConstruct %none_802, %none_803, %646, %650 : (!torch.none, !torch.none, !torch.vtensor<[512,1],si64>, !torch.vtensor<[512],si64>) -> !torch.list<optional<vtensor>>
    %652 = torch.aten.index.Tensor %641, %651 : !torch.vtensor<[8,512,256,256],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[8,512,512,512],f32>
    %int2_804 = torch.constant.int 2
    %653 = torch.aten.clone %652, %int2_804 : !torch.vtensor<[8,512,512,512],f32>, !torch.int -> !torch.vtensor<[8,512,512,512],f32>
    %int5_805 = torch.constant.int 5
    %654 = torch.prims.convert_element_type %653, %int5_805 : !torch.vtensor<[8,512,512,512],f32>, !torch.int -> !torch.vtensor<[8,512,512,512],f16>
    %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %655 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16>
    %656 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_806 = torch.constant.int 1
    %int1_807 = torch.constant.int 1
    %657 = torch.prim.ListConstruct %int1_806, %int1_807 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_808 = torch.constant.int 1
    %int1_809 = torch.constant.int 1
    %658 = torch.prim.ListConstruct %int1_808, %int1_809 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_810 = torch.constant.int 1
    %int1_811 = torch.constant.int 1
    %659 = torch.prim.ListConstruct %int1_810, %int1_811 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_812 = torch.constant.bool false
    %int0_813 = torch.constant.int 0
    %int0_814 = torch.constant.int 0
    %660 = torch.prim.ListConstruct %int0_813, %int0_814 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_815 = torch.constant.int 1
    %661 = torch.aten.convolution %654, %655, %656, %657, %658, %659, %false_812, %660, %int1_815 : !torch.vtensor<[8,512,512,512],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,512,512],f16>
    %int8_816 = torch.constant.int 8
    %int32_817 = torch.constant.int 32
    %int16_818 = torch.constant.int 16
    %int262144 = torch.constant.int 262144
    %662 = torch.prim.ListConstruct %int8_816, %int32_817, %int16_818, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %663 = torch.aten.view %661, %662 : !torch.vtensor<[8,512,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,262144],f16>
    %int6_819 = torch.constant.int 6
    %664 = torch.prims.convert_element_type %663, %int6_819 : !torch.vtensor<[8,32,16,262144],f16>, !torch.int -> !torch.vtensor<[8,32,16,262144],f32>
    %int2_820 = torch.constant.int 2
    %int3_821 = torch.constant.int 3
    %665 = torch.prim.ListConstruct %int2_820, %int3_821 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_822 = torch.constant.int 0
    %true_823 = torch.constant.bool true
    %result0_824, %result1_825 = torch.aten.var_mean.correction %664, %665, %int0_822, %true_823 : !torch.vtensor<[8,32,16,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_826 = torch.constant.float 9.9999999999999995E-7
    %int1_827 = torch.constant.int 1
    %666 = torch.aten.add.Scalar %result0_824, %float9.999990e-07_826, %int1_827 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %667 = torch.aten.rsqrt %666 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_828 = torch.constant.int 1
    %668 = torch.aten.sub.Tensor %663, %result1_825, %int1_828 : !torch.vtensor<[8,32,16,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,262144],f32>
    %669 = torch.aten.mul.Tensor %668, %667 : !torch.vtensor<[8,32,16,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,262144],f32>
    %int8_829 = torch.constant.int 8
    %int512_830 = torch.constant.int 512
    %int512_831 = torch.constant.int 512
    %int512_832 = torch.constant.int 512
    %670 = torch.prim.ListConstruct %int8_829, %int512_830, %int512_831, %int512_832 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %671 = torch.aten.view %669, %670 : !torch.vtensor<[8,32,16,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,512,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16>
    %672 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_833 = torch.constant.int 0
    %673 = torch.aten.unsqueeze %672, %int0_833 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_834 = torch.constant.int 2
    %674 = torch.aten.unsqueeze %673, %int2_834 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_835 = torch.constant.int 3
    %675 = torch.aten.unsqueeze %674, %int3_835 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16>
    %676 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_836 = torch.constant.int 0
    %677 = torch.aten.unsqueeze %676, %int0_836 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_837 = torch.constant.int 2
    %678 = torch.aten.unsqueeze %677, %int2_837 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_838 = torch.constant.int 3
    %679 = torch.aten.unsqueeze %678, %int3_838 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %680 = torch.aten.mul.Tensor %671, %679 : !torch.vtensor<[8,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,512,512],f32>
    %int1_839 = torch.constant.int 1
    %681 = torch.aten.add.Tensor %680, %675, %int1_839 : !torch.vtensor<[8,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,512,512],f32>
    %int5_840 = torch.constant.int 5
    %682 = torch.prims.convert_element_type %681, %int5_840 : !torch.vtensor<[8,512,512,512],f32>, !torch.int -> !torch.vtensor<[8,512,512,512],f16>
    %683 = torch.aten.silu %682 : !torch.vtensor<[8,512,512,512],f16> -> !torch.vtensor<[8,512,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16>
    %684 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16> -> !torch.vtensor<[256,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16>
    %685 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_841 = torch.constant.int 1
    %int1_842 = torch.constant.int 1
    %686 = torch.prim.ListConstruct %int1_841, %int1_842 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_843 = torch.constant.int 1
    %int1_844 = torch.constant.int 1
    %687 = torch.prim.ListConstruct %int1_843, %int1_844 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_845 = torch.constant.int 1
    %int1_846 = torch.constant.int 1
    %688 = torch.prim.ListConstruct %int1_845, %int1_846 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_847 = torch.constant.bool false
    %int0_848 = torch.constant.int 0
    %int0_849 = torch.constant.int 0
    %689 = torch.prim.ListConstruct %int0_848, %int0_849 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_850 = torch.constant.int 1
    %690 = torch.aten.convolution %683, %684, %685, %686, %687, %688, %false_847, %689, %int1_850 : !torch.vtensor<[8,512,512,512],f16>, !torch.vtensor<[256,512,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int8_851 = torch.constant.int 8
    %int32_852 = torch.constant.int 32
    %int8_853 = torch.constant.int 8
    %int262144_854 = torch.constant.int 262144
    %691 = torch.prim.ListConstruct %int8_851, %int32_852, %int8_853, %int262144_854 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %692 = torch.aten.view %690, %691 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_855 = torch.constant.int 6
    %693 = torch.prims.convert_element_type %692, %int6_855 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_856 = torch.constant.int 2
    %int3_857 = torch.constant.int 3
    %694 = torch.prim.ListConstruct %int2_856, %int3_857 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_858 = torch.constant.int 0
    %true_859 = torch.constant.bool true
    %result0_860, %result1_861 = torch.aten.var_mean.correction %693, %694, %int0_858, %true_859 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_862 = torch.constant.float 9.9999999999999995E-7
    %int1_863 = torch.constant.int 1
    %695 = torch.aten.add.Scalar %result0_860, %float9.999990e-07_862, %int1_863 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %696 = torch.aten.rsqrt %695 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_864 = torch.constant.int 1
    %697 = torch.aten.sub.Tensor %692, %result1_861, %int1_864 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %698 = torch.aten.mul.Tensor %697, %696 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_865 = torch.constant.int 8
    %int256_866 = torch.constant.int 256
    %int512_867 = torch.constant.int 512
    %int512_868 = torch.constant.int 512
    %699 = torch.prim.ListConstruct %int8_865, %int256_866, %int512_867, %int512_868 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %700 = torch.aten.view %698, %699 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16>
    %701 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_869 = torch.constant.int 0
    %702 = torch.aten.unsqueeze %701, %int0_869 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_870 = torch.constant.int 2
    %703 = torch.aten.unsqueeze %702, %int2_870 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_871 = torch.constant.int 3
    %704 = torch.aten.unsqueeze %703, %int3_871 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16>
    %705 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_872 = torch.constant.int 0
    %706 = torch.aten.unsqueeze %705, %int0_872 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_873 = torch.constant.int 2
    %707 = torch.aten.unsqueeze %706, %int2_873 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_874 = torch.constant.int 3
    %708 = torch.aten.unsqueeze %707, %int3_874 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %709 = torch.aten.mul.Tensor %700, %708 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_875 = torch.constant.int 1
    %710 = torch.aten.add.Tensor %709, %704, %int1_875 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_876 = torch.constant.int 5
    %711 = torch.prims.convert_element_type %710, %int5_876 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %712 = torch.aten.silu %711 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %none_877 = torch.constant.none
    %713 = torch.aten.clone %712, %none_877 : !torch.vtensor<[8,256,512,512],f16>, !torch.none -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %714 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16>
    %715 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_878 = torch.constant.int 1
    %int1_879 = torch.constant.int 1
    %716 = torch.prim.ListConstruct %int1_878, %int1_879 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_880 = torch.constant.int 1
    %int1_881 = torch.constant.int 1
    %717 = torch.prim.ListConstruct %int1_880, %int1_881 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_882 = torch.constant.int 1
    %int1_883 = torch.constant.int 1
    %718 = torch.prim.ListConstruct %int1_882, %int1_883 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_884 = torch.constant.bool false
    %int0_885 = torch.constant.int 0
    %int0_886 = torch.constant.int 0
    %719 = torch.prim.ListConstruct %int0_885, %int0_886 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_887 = torch.constant.int 1
    %720 = torch.aten.convolution %713, %714, %715, %716, %717, %718, %false_884, %719, %int1_887 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16>
    %721 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16> -> !torch.vtensor<[256,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %722 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_888 = torch.constant.int 1
    %int1_889 = torch.constant.int 1
    %723 = torch.prim.ListConstruct %int1_888, %int1_889 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_890 = torch.constant.int 0
    %int0_891 = torch.constant.int 0
    %724 = torch.prim.ListConstruct %int0_890, %int0_891 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_892 = torch.constant.int 1
    %int1_893 = torch.constant.int 1
    %725 = torch.prim.ListConstruct %int1_892, %int1_893 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_894 = torch.constant.bool false
    %int0_895 = torch.constant.int 0
    %int0_896 = torch.constant.int 0
    %726 = torch.prim.ListConstruct %int0_895, %int0_896 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_897 = torch.constant.int 1
    %727 = torch.aten.convolution %661, %721, %722, %723, %724, %725, %false_894, %726, %int1_897 : !torch.vtensor<[8,512,512,512],f16>, !torch.vtensor<[256,512,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int1_898 = torch.constant.int 1
    %728 = torch.aten.add.Tensor %727, %720, %int1_898 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %float1.000000e00_899 = torch.constant.float 1.000000e+00
    %729 = torch.aten.div.Scalar %728, %float1.000000e00_899 : !torch.vtensor<[8,256,512,512],f16>, !torch.float -> !torch.vtensor<[8,256,512,512],f16>
    %int8_900 = torch.constant.int 8
    %int32_901 = torch.constant.int 32
    %int8_902 = torch.constant.int 8
    %int262144_903 = torch.constant.int 262144
    %730 = torch.prim.ListConstruct %int8_900, %int32_901, %int8_902, %int262144_903 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %731 = torch.aten.view %729, %730 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_904 = torch.constant.int 6
    %732 = torch.prims.convert_element_type %731, %int6_904 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_905 = torch.constant.int 2
    %int3_906 = torch.constant.int 3
    %733 = torch.prim.ListConstruct %int2_905, %int3_906 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_907 = torch.constant.int 0
    %true_908 = torch.constant.bool true
    %result0_909, %result1_910 = torch.aten.var_mean.correction %732, %733, %int0_907, %true_908 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_911 = torch.constant.float 9.9999999999999995E-7
    %int1_912 = torch.constant.int 1
    %734 = torch.aten.add.Scalar %result0_909, %float9.999990e-07_911, %int1_912 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %735 = torch.aten.rsqrt %734 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_913 = torch.constant.int 1
    %736 = torch.aten.sub.Tensor %731, %result1_910, %int1_913 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %737 = torch.aten.mul.Tensor %736, %735 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_914 = torch.constant.int 8
    %int256_915 = torch.constant.int 256
    %int512_916 = torch.constant.int 512
    %int512_917 = torch.constant.int 512
    %738 = torch.prim.ListConstruct %int8_914, %int256_915, %int512_916, %int512_917 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %739 = torch.aten.view %737, %738 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16>
    %740 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_918 = torch.constant.int 0
    %741 = torch.aten.unsqueeze %740, %int0_918 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_919 = torch.constant.int 2
    %742 = torch.aten.unsqueeze %741, %int2_919 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_920 = torch.constant.int 3
    %743 = torch.aten.unsqueeze %742, %int3_920 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16>
    %744 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_921 = torch.constant.int 0
    %745 = torch.aten.unsqueeze %744, %int0_921 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_922 = torch.constant.int 2
    %746 = torch.aten.unsqueeze %745, %int2_922 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_923 = torch.constant.int 3
    %747 = torch.aten.unsqueeze %746, %int3_923 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %748 = torch.aten.mul.Tensor %739, %747 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_924 = torch.constant.int 1
    %749 = torch.aten.add.Tensor %748, %743, %int1_924 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_925 = torch.constant.int 5
    %750 = torch.prims.convert_element_type %749, %int5_925 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %751 = torch.aten.silu %750 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %752 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16>
    %753 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_926 = torch.constant.int 1
    %int1_927 = torch.constant.int 1
    %754 = torch.prim.ListConstruct %int1_926, %int1_927 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_928 = torch.constant.int 1
    %int1_929 = torch.constant.int 1
    %755 = torch.prim.ListConstruct %int1_928, %int1_929 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_930 = torch.constant.int 1
    %int1_931 = torch.constant.int 1
    %756 = torch.prim.ListConstruct %int1_930, %int1_931 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_932 = torch.constant.bool false
    %int0_933 = torch.constant.int 0
    %int0_934 = torch.constant.int 0
    %757 = torch.prim.ListConstruct %int0_933, %int0_934 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_935 = torch.constant.int 1
    %758 = torch.aten.convolution %751, %752, %753, %754, %755, %756, %false_932, %757, %int1_935 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int8_936 = torch.constant.int 8
    %int32_937 = torch.constant.int 32
    %int8_938 = torch.constant.int 8
    %int262144_939 = torch.constant.int 262144
    %759 = torch.prim.ListConstruct %int8_936, %int32_937, %int8_938, %int262144_939 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %760 = torch.aten.view %758, %759 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_940 = torch.constant.int 6
    %761 = torch.prims.convert_element_type %760, %int6_940 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_941 = torch.constant.int 2
    %int3_942 = torch.constant.int 3
    %762 = torch.prim.ListConstruct %int2_941, %int3_942 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_943 = torch.constant.int 0
    %true_944 = torch.constant.bool true
    %result0_945, %result1_946 = torch.aten.var_mean.correction %761, %762, %int0_943, %true_944 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_947 = torch.constant.float 9.9999999999999995E-7
    %int1_948 = torch.constant.int 1
    %763 = torch.aten.add.Scalar %result0_945, %float9.999990e-07_947, %int1_948 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %764 = torch.aten.rsqrt %763 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_949 = torch.constant.int 1
    %765 = torch.aten.sub.Tensor %760, %result1_946, %int1_949 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %766 = torch.aten.mul.Tensor %765, %764 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_950 = torch.constant.int 8
    %int256_951 = torch.constant.int 256
    %int512_952 = torch.constant.int 512
    %int512_953 = torch.constant.int 512
    %767 = torch.prim.ListConstruct %int8_950, %int256_951, %int512_952, %int512_953 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %768 = torch.aten.view %766, %767 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16>
    %769 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_954 = torch.constant.int 0
    %770 = torch.aten.unsqueeze %769, %int0_954 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_955 = torch.constant.int 2
    %771 = torch.aten.unsqueeze %770, %int2_955 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_956 = torch.constant.int 3
    %772 = torch.aten.unsqueeze %771, %int3_956 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16>
    %773 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_957 = torch.constant.int 0
    %774 = torch.aten.unsqueeze %773, %int0_957 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_958 = torch.constant.int 2
    %775 = torch.aten.unsqueeze %774, %int2_958 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_959 = torch.constant.int 3
    %776 = torch.aten.unsqueeze %775, %int3_959 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %777 = torch.aten.mul.Tensor %768, %776 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_960 = torch.constant.int 1
    %778 = torch.aten.add.Tensor %777, %772, %int1_960 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_961 = torch.constant.int 5
    %779 = torch.prims.convert_element_type %778, %int5_961 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %780 = torch.aten.silu %779 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %none_962 = torch.constant.none
    %781 = torch.aten.clone %780, %none_962 : !torch.vtensor<[8,256,512,512],f16>, !torch.none -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %782 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16>
    %783 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_963 = torch.constant.int 1
    %int1_964 = torch.constant.int 1
    %784 = torch.prim.ListConstruct %int1_963, %int1_964 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_965 = torch.constant.int 1
    %int1_966 = torch.constant.int 1
    %785 = torch.prim.ListConstruct %int1_965, %int1_966 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_967 = torch.constant.int 1
    %int1_968 = torch.constant.int 1
    %786 = torch.prim.ListConstruct %int1_967, %int1_968 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_969 = torch.constant.bool false
    %int0_970 = torch.constant.int 0
    %int0_971 = torch.constant.int 0
    %787 = torch.prim.ListConstruct %int0_970, %int0_971 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_972 = torch.constant.int 1
    %788 = torch.aten.convolution %781, %782, %783, %784, %785, %786, %false_969, %787, %int1_972 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int1_973 = torch.constant.int 1
    %789 = torch.aten.add.Tensor %729, %788, %int1_973 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %float1.000000e00_974 = torch.constant.float 1.000000e+00
    %790 = torch.aten.div.Scalar %789, %float1.000000e00_974 : !torch.vtensor<[8,256,512,512],f16>, !torch.float -> !torch.vtensor<[8,256,512,512],f16>
    %int8_975 = torch.constant.int 8
    %int32_976 = torch.constant.int 32
    %int8_977 = torch.constant.int 8
    %int262144_978 = torch.constant.int 262144
    %791 = torch.prim.ListConstruct %int8_975, %int32_976, %int8_977, %int262144_978 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %792 = torch.aten.view %790, %791 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_979 = torch.constant.int 6
    %793 = torch.prims.convert_element_type %792, %int6_979 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_980 = torch.constant.int 2
    %int3_981 = torch.constant.int 3
    %794 = torch.prim.ListConstruct %int2_980, %int3_981 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_982 = torch.constant.int 0
    %true_983 = torch.constant.bool true
    %result0_984, %result1_985 = torch.aten.var_mean.correction %793, %794, %int0_982, %true_983 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_986 = torch.constant.float 9.9999999999999995E-7
    %int1_987 = torch.constant.int 1
    %795 = torch.aten.add.Scalar %result0_984, %float9.999990e-07_986, %int1_987 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %796 = torch.aten.rsqrt %795 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_988 = torch.constant.int 1
    %797 = torch.aten.sub.Tensor %792, %result1_985, %int1_988 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %798 = torch.aten.mul.Tensor %797, %796 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_989 = torch.constant.int 8
    %int256_990 = torch.constant.int 256
    %int512_991 = torch.constant.int 512
    %int512_992 = torch.constant.int 512
    %799 = torch.prim.ListConstruct %int8_989, %int256_990, %int512_991, %int512_992 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %800 = torch.aten.view %798, %799 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16>
    %801 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_993 = torch.constant.int 0
    %802 = torch.aten.unsqueeze %801, %int0_993 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_994 = torch.constant.int 2
    %803 = torch.aten.unsqueeze %802, %int2_994 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_995 = torch.constant.int 3
    %804 = torch.aten.unsqueeze %803, %int3_995 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16>
    %805 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_996 = torch.constant.int 0
    %806 = torch.aten.unsqueeze %805, %int0_996 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_997 = torch.constant.int 2
    %807 = torch.aten.unsqueeze %806, %int2_997 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_998 = torch.constant.int 3
    %808 = torch.aten.unsqueeze %807, %int3_998 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %809 = torch.aten.mul.Tensor %800, %808 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_999 = torch.constant.int 1
    %810 = torch.aten.add.Tensor %809, %804, %int1_999 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_1000 = torch.constant.int 5
    %811 = torch.prims.convert_element_type %810, %int5_1000 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %812 = torch.aten.silu %811 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16>
    %813 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16>
    %814 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1001 = torch.constant.int 1
    %int1_1002 = torch.constant.int 1
    %815 = torch.prim.ListConstruct %int1_1001, %int1_1002 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1003 = torch.constant.int 1
    %int1_1004 = torch.constant.int 1
    %816 = torch.prim.ListConstruct %int1_1003, %int1_1004 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1005 = torch.constant.int 1
    %int1_1006 = torch.constant.int 1
    %817 = torch.prim.ListConstruct %int1_1005, %int1_1006 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1007 = torch.constant.bool false
    %int0_1008 = torch.constant.int 0
    %int0_1009 = torch.constant.int 0
    %818 = torch.prim.ListConstruct %int0_1008, %int0_1009 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1010 = torch.constant.int 1
    %819 = torch.aten.convolution %812, %813, %814, %815, %816, %817, %false_1007, %818, %int1_1010 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int8_1011 = torch.constant.int 8
    %int32_1012 = torch.constant.int 32
    %int8_1013 = torch.constant.int 8
    %int262144_1014 = torch.constant.int 262144
    %820 = torch.prim.ListConstruct %int8_1011, %int32_1012, %int8_1013, %int262144_1014 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %821 = torch.aten.view %819, %820 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_1015 = torch.constant.int 6
    %822 = torch.prims.convert_element_type %821, %int6_1015 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_1016 = torch.constant.int 2
    %int3_1017 = torch.constant.int 3
    %823 = torch.prim.ListConstruct %int2_1016, %int3_1017 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1018 = torch.constant.int 0
    %true_1019 = torch.constant.bool true
    %result0_1020, %result1_1021 = torch.aten.var_mean.correction %822, %823, %int0_1018, %true_1019 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1022 = torch.constant.float 9.9999999999999995E-7
    %int1_1023 = torch.constant.int 1
    %824 = torch.aten.add.Scalar %result0_1020, %float9.999990e-07_1022, %int1_1023 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %825 = torch.aten.rsqrt %824 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1024 = torch.constant.int 1
    %826 = torch.aten.sub.Tensor %821, %result1_1021, %int1_1024 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %827 = torch.aten.mul.Tensor %826, %825 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_1025 = torch.constant.int 8
    %int256_1026 = torch.constant.int 256
    %int512_1027 = torch.constant.int 512
    %int512_1028 = torch.constant.int 512
    %828 = torch.prim.ListConstruct %int8_1025, %int256_1026, %int512_1027, %int512_1028 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %829 = torch.aten.view %827, %828 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16>
    %830 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1029 = torch.constant.int 0
    %831 = torch.aten.unsqueeze %830, %int0_1029 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1030 = torch.constant.int 2
    %832 = torch.aten.unsqueeze %831, %int2_1030 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1031 = torch.constant.int 3
    %833 = torch.aten.unsqueeze %832, %int3_1031 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16>
    %834 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1032 = torch.constant.int 0
    %835 = torch.aten.unsqueeze %834, %int0_1032 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1033 = torch.constant.int 2
    %836 = torch.aten.unsqueeze %835, %int2_1033 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1034 = torch.constant.int 3
    %837 = torch.aten.unsqueeze %836, %int3_1034 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %838 = torch.aten.mul.Tensor %829, %837 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_1035 = torch.constant.int 1
    %839 = torch.aten.add.Tensor %838, %833, %int1_1035 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_1036 = torch.constant.int 5
    %840 = torch.prims.convert_element_type %839, %int5_1036 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %841 = torch.aten.silu %840 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %none_1037 = torch.constant.none
    %842 = torch.aten.clone %841, %none_1037 : !torch.vtensor<[8,256,512,512],f16>, !torch.none -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16>
    %843 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16>
    %844 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1038 = torch.constant.int 1
    %int1_1039 = torch.constant.int 1
    %845 = torch.prim.ListConstruct %int1_1038, %int1_1039 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1040 = torch.constant.int 1
    %int1_1041 = torch.constant.int 1
    %846 = torch.prim.ListConstruct %int1_1040, %int1_1041 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1042 = torch.constant.int 1
    %int1_1043 = torch.constant.int 1
    %847 = torch.prim.ListConstruct %int1_1042, %int1_1043 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1044 = torch.constant.bool false
    %int0_1045 = torch.constant.int 0
    %int0_1046 = torch.constant.int 0
    %848 = torch.prim.ListConstruct %int0_1045, %int0_1046 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1047 = torch.constant.int 1
    %849 = torch.aten.convolution %842, %843, %844, %845, %846, %847, %false_1044, %848, %int1_1047 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int1_1048 = torch.constant.int 1
    %850 = torch.aten.add.Tensor %790, %849, %int1_1048 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %float1.000000e00_1049 = torch.constant.float 1.000000e+00
    %851 = torch.aten.div.Scalar %850, %float1.000000e00_1049 : !torch.vtensor<[8,256,512,512],f16>, !torch.float -> !torch.vtensor<[8,256,512,512],f16>
    %int6_1050 = torch.constant.int 6
    %852 = torch.prims.convert_element_type %851, %int6_1050 : !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int1024 = torch.constant.int 1024
    %int6_1051 = torch.constant.int 6
    %none_1052 = torch.constant.none
    %cpu_1053 = torch.constant.device "cpu"
    %false_1054 = torch.constant.bool false
    %853 = torch.aten.arange %int1024, %int6_1051, %none_1052, %cpu_1053, %false_1054 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1055 = torch.constant.float 0.000000e+00
    %int1_1056 = torch.constant.int 1
    %854 = torch.aten.add.Scalar %853, %float0.000000e00_1055, %int1_1056 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1057 = torch.constant.float 5.000000e-01
    %855 = torch.aten.mul.Scalar %854, %float5.000000e-01_1057 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1058 = torch.constant.int 4
    %856 = torch.prims.convert_element_type %855, %int4_1058 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %int-1_1059 = torch.constant.int -1
    %857 = torch.aten.unsqueeze %856, %int-1_1059 : !torch.vtensor<[1024],si64>, !torch.int -> !torch.vtensor<[1024,1],si64>
    %int1024_1060 = torch.constant.int 1024
    %int6_1061 = torch.constant.int 6
    %none_1062 = torch.constant.none
    %cpu_1063 = torch.constant.device "cpu"
    %false_1064 = torch.constant.bool false
    %858 = torch.aten.arange %int1024_1060, %int6_1061, %none_1062, %cpu_1063, %false_1064 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1065 = torch.constant.float 0.000000e+00
    %int1_1066 = torch.constant.int 1
    %859 = torch.aten.add.Scalar %858, %float0.000000e00_1065, %int1_1066 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1067 = torch.constant.float 5.000000e-01
    %860 = torch.aten.mul.Scalar %859, %float5.000000e-01_1067 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1068 = torch.constant.int 4
    %861 = torch.prims.convert_element_type %860, %int4_1068 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %none_1069 = torch.constant.none
    %none_1070 = torch.constant.none
    %862 = torch.prim.ListConstruct %none_1069, %none_1070, %857, %861 : (!torch.none, !torch.none, !torch.vtensor<[1024,1],si64>, !torch.vtensor<[1024],si64>) -> !torch.list<optional<vtensor>>
    %863 = torch.aten.index.Tensor %852, %862 : !torch.vtensor<[8,256,512,512],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[8,256,1024,1024],f32>
    %int2_1071 = torch.constant.int 2
    %864 = torch.aten.clone %863, %int2_1071 : !torch.vtensor<[8,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,256,1024,1024],f32>
    %int5_1072 = torch.constant.int 5
    %865 = torch.prims.convert_element_type %864, %int5_1072 : !torch.vtensor<[8,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,256,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %866 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16>
    %867 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1073 = torch.constant.int 1
    %int1_1074 = torch.constant.int 1
    %868 = torch.prim.ListConstruct %int1_1073, %int1_1074 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1075 = torch.constant.int 1
    %int1_1076 = torch.constant.int 1
    %869 = torch.prim.ListConstruct %int1_1075, %int1_1076 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1077 = torch.constant.int 1
    %int1_1078 = torch.constant.int 1
    %870 = torch.prim.ListConstruct %int1_1077, %int1_1078 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1079 = torch.constant.bool false
    %int0_1080 = torch.constant.int 0
    %int0_1081 = torch.constant.int 0
    %871 = torch.prim.ListConstruct %int0_1080, %int0_1081 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1082 = torch.constant.int 1
    %872 = torch.aten.convolution %865, %866, %867, %868, %869, %870, %false_1079, %871, %int1_1082 : !torch.vtensor<[8,256,1024,1024],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,1024,1024],f16>
    %int8_1083 = torch.constant.int 8
    %int32_1084 = torch.constant.int 32
    %int8_1085 = torch.constant.int 8
    %int1048576 = torch.constant.int 1048576
    %873 = torch.prim.ListConstruct %int8_1083, %int32_1084, %int8_1085, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %874 = torch.aten.view %872, %873 : !torch.vtensor<[8,256,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,1048576],f16>
    %int6_1086 = torch.constant.int 6
    %875 = torch.prims.convert_element_type %874, %int6_1086 : !torch.vtensor<[8,32,8,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,8,1048576],f32>
    %int2_1087 = torch.constant.int 2
    %int3_1088 = torch.constant.int 3
    %876 = torch.prim.ListConstruct %int2_1087, %int3_1088 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1089 = torch.constant.int 0
    %true_1090 = torch.constant.bool true
    %result0_1091, %result1_1092 = torch.aten.var_mean.correction %875, %876, %int0_1089, %true_1090 : !torch.vtensor<[8,32,8,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1093 = torch.constant.float 9.9999999999999995E-7
    %int1_1094 = torch.constant.int 1
    %877 = torch.aten.add.Scalar %result0_1091, %float9.999990e-07_1093, %int1_1094 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %878 = torch.aten.rsqrt %877 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1095 = torch.constant.int 1
    %879 = torch.aten.sub.Tensor %874, %result1_1092, %int1_1095 : !torch.vtensor<[8,32,8,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,1048576],f32>
    %880 = torch.aten.mul.Tensor %879, %878 : !torch.vtensor<[8,32,8,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,1048576],f32>
    %int8_1096 = torch.constant.int 8
    %int256_1097 = torch.constant.int 256
    %int1024_1098 = torch.constant.int 1024
    %int1024_1099 = torch.constant.int 1024
    %881 = torch.prim.ListConstruct %int8_1096, %int256_1097, %int1024_1098, %int1024_1099 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %882 = torch.aten.view %880, %881 : !torch.vtensor<[8,32,8,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,256,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16>
    %883 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1100 = torch.constant.int 0
    %884 = torch.aten.unsqueeze %883, %int0_1100 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1101 = torch.constant.int 2
    %885 = torch.aten.unsqueeze %884, %int2_1101 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1102 = torch.constant.int 3
    %886 = torch.aten.unsqueeze %885, %int3_1102 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16>
    %887 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1103 = torch.constant.int 0
    %888 = torch.aten.unsqueeze %887, %int0_1103 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1104 = torch.constant.int 2
    %889 = torch.aten.unsqueeze %888, %int2_1104 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1105 = torch.constant.int 3
    %890 = torch.aten.unsqueeze %889, %int3_1105 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %891 = torch.aten.mul.Tensor %882, %890 : !torch.vtensor<[8,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,1024,1024],f32>
    %int1_1106 = torch.constant.int 1
    %892 = torch.aten.add.Tensor %891, %886, %int1_1106 : !torch.vtensor<[8,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,1024,1024],f32>
    %int5_1107 = torch.constant.int 5
    %893 = torch.prims.convert_element_type %892, %int5_1107 : !torch.vtensor<[8,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,256,1024,1024],f16>
    %894 = torch.aten.silu %893 : !torch.vtensor<[8,256,1024,1024],f16> -> !torch.vtensor<[8,256,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16>
    %895 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16> -> !torch.vtensor<[128,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16>
    %896 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1108 = torch.constant.int 1
    %int1_1109 = torch.constant.int 1
    %897 = torch.prim.ListConstruct %int1_1108, %int1_1109 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1110 = torch.constant.int 1
    %int1_1111 = torch.constant.int 1
    %898 = torch.prim.ListConstruct %int1_1110, %int1_1111 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1112 = torch.constant.int 1
    %int1_1113 = torch.constant.int 1
    %899 = torch.prim.ListConstruct %int1_1112, %int1_1113 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1114 = torch.constant.bool false
    %int0_1115 = torch.constant.int 0
    %int0_1116 = torch.constant.int 0
    %900 = torch.prim.ListConstruct %int0_1115, %int0_1116 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1117 = torch.constant.int 1
    %901 = torch.aten.convolution %894, %895, %896, %897, %898, %899, %false_1114, %900, %int1_1117 : !torch.vtensor<[8,256,1024,1024],f16>, !torch.vtensor<[128,256,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1118 = torch.constant.int 8
    %int32_1119 = torch.constant.int 32
    %int4_1120 = torch.constant.int 4
    %int1048576_1121 = torch.constant.int 1048576
    %902 = torch.prim.ListConstruct %int8_1118, %int32_1119, %int4_1120, %int1048576_1121 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %903 = torch.aten.view %901, %902 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1122 = torch.constant.int 6
    %904 = torch.prims.convert_element_type %903, %int6_1122 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1123 = torch.constant.int 2
    %int3_1124 = torch.constant.int 3
    %905 = torch.prim.ListConstruct %int2_1123, %int3_1124 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1125 = torch.constant.int 0
    %true_1126 = torch.constant.bool true
    %result0_1127, %result1_1128 = torch.aten.var_mean.correction %904, %905, %int0_1125, %true_1126 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1129 = torch.constant.float 9.9999999999999995E-7
    %int1_1130 = torch.constant.int 1
    %906 = torch.aten.add.Scalar %result0_1127, %float9.999990e-07_1129, %int1_1130 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %907 = torch.aten.rsqrt %906 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1131 = torch.constant.int 1
    %908 = torch.aten.sub.Tensor %903, %result1_1128, %int1_1131 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %909 = torch.aten.mul.Tensor %908, %907 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1132 = torch.constant.int 8
    %int128_1133 = torch.constant.int 128
    %int1024_1134 = torch.constant.int 1024
    %int1024_1135 = torch.constant.int 1024
    %910 = torch.prim.ListConstruct %int8_1132, %int128_1133, %int1024_1134, %int1024_1135 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %911 = torch.aten.view %909, %910 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16>
    %912 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1136 = torch.constant.int 0
    %913 = torch.aten.unsqueeze %912, %int0_1136 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1137 = torch.constant.int 2
    %914 = torch.aten.unsqueeze %913, %int2_1137 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1138 = torch.constant.int 3
    %915 = torch.aten.unsqueeze %914, %int3_1138 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16>
    %916 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1139 = torch.constant.int 0
    %917 = torch.aten.unsqueeze %916, %int0_1139 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1140 = torch.constant.int 2
    %918 = torch.aten.unsqueeze %917, %int2_1140 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1141 = torch.constant.int 3
    %919 = torch.aten.unsqueeze %918, %int3_1141 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %920 = torch.aten.mul.Tensor %911, %919 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1142 = torch.constant.int 1
    %921 = torch.aten.add.Tensor %920, %915, %int1_1142 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1143 = torch.constant.int 5
    %922 = torch.prims.convert_element_type %921, %int5_1143 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %923 = torch.aten.silu %922 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %none_1144 = torch.constant.none
    %924 = torch.aten.clone %923, %none_1144 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %925 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16>
    %926 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1145 = torch.constant.int 1
    %int1_1146 = torch.constant.int 1
    %927 = torch.prim.ListConstruct %int1_1145, %int1_1146 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1147 = torch.constant.int 1
    %int1_1148 = torch.constant.int 1
    %928 = torch.prim.ListConstruct %int1_1147, %int1_1148 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1149 = torch.constant.int 1
    %int1_1150 = torch.constant.int 1
    %929 = torch.prim.ListConstruct %int1_1149, %int1_1150 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1151 = torch.constant.bool false
    %int0_1152 = torch.constant.int 0
    %int0_1153 = torch.constant.int 0
    %930 = torch.prim.ListConstruct %int0_1152, %int0_1153 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1154 = torch.constant.int 1
    %931 = torch.aten.convolution %924, %925, %926, %927, %928, %929, %false_1151, %930, %int1_1154 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16>
    %932 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16> -> !torch.vtensor<[128,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16>
    %933 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1155 = torch.constant.int 1
    %int1_1156 = torch.constant.int 1
    %934 = torch.prim.ListConstruct %int1_1155, %int1_1156 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1157 = torch.constant.int 0
    %int0_1158 = torch.constant.int 0
    %935 = torch.prim.ListConstruct %int0_1157, %int0_1158 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1159 = torch.constant.int 1
    %int1_1160 = torch.constant.int 1
    %936 = torch.prim.ListConstruct %int1_1159, %int1_1160 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1161 = torch.constant.bool false
    %int0_1162 = torch.constant.int 0
    %int0_1163 = torch.constant.int 0
    %937 = torch.prim.ListConstruct %int0_1162, %int0_1163 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1164 = torch.constant.int 1
    %938 = torch.aten.convolution %872, %932, %933, %934, %935, %936, %false_1161, %937, %int1_1164 : !torch.vtensor<[8,256,1024,1024],f16>, !torch.vtensor<[128,256,1,1],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int1_1165 = torch.constant.int 1
    %939 = torch.aten.add.Tensor %938, %931, %int1_1165 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[8,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %float1.000000e00_1166 = torch.constant.float 1.000000e+00
    %940 = torch.aten.div.Scalar %939, %float1.000000e00_1166 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1167 = torch.constant.int 8
    %int32_1168 = torch.constant.int 32
    %int4_1169 = torch.constant.int 4
    %int1048576_1170 = torch.constant.int 1048576
    %941 = torch.prim.ListConstruct %int8_1167, %int32_1168, %int4_1169, %int1048576_1170 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %942 = torch.aten.view %940, %941 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1171 = torch.constant.int 6
    %943 = torch.prims.convert_element_type %942, %int6_1171 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1172 = torch.constant.int 2
    %int3_1173 = torch.constant.int 3
    %944 = torch.prim.ListConstruct %int2_1172, %int3_1173 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1174 = torch.constant.int 0
    %true_1175 = torch.constant.bool true
    %result0_1176, %result1_1177 = torch.aten.var_mean.correction %943, %944, %int0_1174, %true_1175 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1178 = torch.constant.float 9.9999999999999995E-7
    %int1_1179 = torch.constant.int 1
    %945 = torch.aten.add.Scalar %result0_1176, %float9.999990e-07_1178, %int1_1179 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %946 = torch.aten.rsqrt %945 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1180 = torch.constant.int 1
    %947 = torch.aten.sub.Tensor %942, %result1_1177, %int1_1180 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %948 = torch.aten.mul.Tensor %947, %946 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1181 = torch.constant.int 8
    %int128_1182 = torch.constant.int 128
    %int1024_1183 = torch.constant.int 1024
    %int1024_1184 = torch.constant.int 1024
    %949 = torch.prim.ListConstruct %int8_1181, %int128_1182, %int1024_1183, %int1024_1184 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %950 = torch.aten.view %948, %949 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16>
    %951 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1185 = torch.constant.int 0
    %952 = torch.aten.unsqueeze %951, %int0_1185 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1186 = torch.constant.int 2
    %953 = torch.aten.unsqueeze %952, %int2_1186 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1187 = torch.constant.int 3
    %954 = torch.aten.unsqueeze %953, %int3_1187 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16>
    %955 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1188 = torch.constant.int 0
    %956 = torch.aten.unsqueeze %955, %int0_1188 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1189 = torch.constant.int 2
    %957 = torch.aten.unsqueeze %956, %int2_1189 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1190 = torch.constant.int 3
    %958 = torch.aten.unsqueeze %957, %int3_1190 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %959 = torch.aten.mul.Tensor %950, %958 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1191 = torch.constant.int 1
    %960 = torch.aten.add.Tensor %959, %954, %int1_1191 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1192 = torch.constant.int 5
    %961 = torch.prims.convert_element_type %960, %int5_1192 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %962 = torch.aten.silu %961 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %963 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16>
    %964 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1193 = torch.constant.int 1
    %int1_1194 = torch.constant.int 1
    %965 = torch.prim.ListConstruct %int1_1193, %int1_1194 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1195 = torch.constant.int 1
    %int1_1196 = torch.constant.int 1
    %966 = torch.prim.ListConstruct %int1_1195, %int1_1196 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1197 = torch.constant.int 1
    %int1_1198 = torch.constant.int 1
    %967 = torch.prim.ListConstruct %int1_1197, %int1_1198 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1199 = torch.constant.bool false
    %int0_1200 = torch.constant.int 0
    %int0_1201 = torch.constant.int 0
    %968 = torch.prim.ListConstruct %int0_1200, %int0_1201 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1202 = torch.constant.int 1
    %969 = torch.aten.convolution %962, %963, %964, %965, %966, %967, %false_1199, %968, %int1_1202 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1203 = torch.constant.int 8
    %int32_1204 = torch.constant.int 32
    %int4_1205 = torch.constant.int 4
    %int1048576_1206 = torch.constant.int 1048576
    %970 = torch.prim.ListConstruct %int8_1203, %int32_1204, %int4_1205, %int1048576_1206 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %971 = torch.aten.view %969, %970 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1207 = torch.constant.int 6
    %972 = torch.prims.convert_element_type %971, %int6_1207 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1208 = torch.constant.int 2
    %int3_1209 = torch.constant.int 3
    %973 = torch.prim.ListConstruct %int2_1208, %int3_1209 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1210 = torch.constant.int 0
    %true_1211 = torch.constant.bool true
    %result0_1212, %result1_1213 = torch.aten.var_mean.correction %972, %973, %int0_1210, %true_1211 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1214 = torch.constant.float 9.9999999999999995E-7
    %int1_1215 = torch.constant.int 1
    %974 = torch.aten.add.Scalar %result0_1212, %float9.999990e-07_1214, %int1_1215 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %975 = torch.aten.rsqrt %974 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1216 = torch.constant.int 1
    %976 = torch.aten.sub.Tensor %971, %result1_1213, %int1_1216 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %977 = torch.aten.mul.Tensor %976, %975 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1217 = torch.constant.int 8
    %int128_1218 = torch.constant.int 128
    %int1024_1219 = torch.constant.int 1024
    %int1024_1220 = torch.constant.int 1024
    %978 = torch.prim.ListConstruct %int8_1217, %int128_1218, %int1024_1219, %int1024_1220 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %979 = torch.aten.view %977, %978 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16>
    %980 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1221 = torch.constant.int 0
    %981 = torch.aten.unsqueeze %980, %int0_1221 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1222 = torch.constant.int 2
    %982 = torch.aten.unsqueeze %981, %int2_1222 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1223 = torch.constant.int 3
    %983 = torch.aten.unsqueeze %982, %int3_1223 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16>
    %984 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1224 = torch.constant.int 0
    %985 = torch.aten.unsqueeze %984, %int0_1224 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1225 = torch.constant.int 2
    %986 = torch.aten.unsqueeze %985, %int2_1225 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1226 = torch.constant.int 3
    %987 = torch.aten.unsqueeze %986, %int3_1226 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %988 = torch.aten.mul.Tensor %979, %987 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1227 = torch.constant.int 1
    %989 = torch.aten.add.Tensor %988, %983, %int1_1227 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1228 = torch.constant.int 5
    %990 = torch.prims.convert_element_type %989, %int5_1228 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %991 = torch.aten.silu %990 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %none_1229 = torch.constant.none
    %992 = torch.aten.clone %991, %none_1229 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %993 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16>
    %994 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1230 = torch.constant.int 1
    %int1_1231 = torch.constant.int 1
    %995 = torch.prim.ListConstruct %int1_1230, %int1_1231 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1232 = torch.constant.int 1
    %int1_1233 = torch.constant.int 1
    %996 = torch.prim.ListConstruct %int1_1232, %int1_1233 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1234 = torch.constant.int 1
    %int1_1235 = torch.constant.int 1
    %997 = torch.prim.ListConstruct %int1_1234, %int1_1235 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1236 = torch.constant.bool false
    %int0_1237 = torch.constant.int 0
    %int0_1238 = torch.constant.int 0
    %998 = torch.prim.ListConstruct %int0_1237, %int0_1238 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1239 = torch.constant.int 1
    %999 = torch.aten.convolution %992, %993, %994, %995, %996, %997, %false_1236, %998, %int1_1239 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int1_1240 = torch.constant.int 1
    %1000 = torch.aten.add.Tensor %940, %999, %int1_1240 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[8,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %float1.000000e00_1241 = torch.constant.float 1.000000e+00
    %1001 = torch.aten.div.Scalar %1000, %float1.000000e00_1241 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1242 = torch.constant.int 8
    %int32_1243 = torch.constant.int 32
    %int4_1244 = torch.constant.int 4
    %int1048576_1245 = torch.constant.int 1048576
    %1002 = torch.prim.ListConstruct %int8_1242, %int32_1243, %int4_1244, %int1048576_1245 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1003 = torch.aten.view %1001, %1002 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1246 = torch.constant.int 6
    %1004 = torch.prims.convert_element_type %1003, %int6_1246 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1247 = torch.constant.int 2
    %int3_1248 = torch.constant.int 3
    %1005 = torch.prim.ListConstruct %int2_1247, %int3_1248 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1249 = torch.constant.int 0
    %true_1250 = torch.constant.bool true
    %result0_1251, %result1_1252 = torch.aten.var_mean.correction %1004, %1005, %int0_1249, %true_1250 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1253 = torch.constant.float 9.9999999999999995E-7
    %int1_1254 = torch.constant.int 1
    %1006 = torch.aten.add.Scalar %result0_1251, %float9.999990e-07_1253, %int1_1254 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %1007 = torch.aten.rsqrt %1006 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1255 = torch.constant.int 1
    %1008 = torch.aten.sub.Tensor %1003, %result1_1252, %int1_1255 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %1009 = torch.aten.mul.Tensor %1008, %1007 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1256 = torch.constant.int 8
    %int128_1257 = torch.constant.int 128
    %int1024_1258 = torch.constant.int 1024
    %int1024_1259 = torch.constant.int 1024
    %1010 = torch.prim.ListConstruct %int8_1256, %int128_1257, %int1024_1258, %int1024_1259 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1011 = torch.aten.view %1009, %1010 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16>
    %1012 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1260 = torch.constant.int 0
    %1013 = torch.aten.unsqueeze %1012, %int0_1260 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1261 = torch.constant.int 2
    %1014 = torch.aten.unsqueeze %1013, %int2_1261 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1262 = torch.constant.int 3
    %1015 = torch.aten.unsqueeze %1014, %int3_1262 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16>
    %1016 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1263 = torch.constant.int 0
    %1017 = torch.aten.unsqueeze %1016, %int0_1263 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1264 = torch.constant.int 2
    %1018 = torch.aten.unsqueeze %1017, %int2_1264 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1265 = torch.constant.int 3
    %1019 = torch.aten.unsqueeze %1018, %int3_1265 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1020 = torch.aten.mul.Tensor %1011, %1019 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1266 = torch.constant.int 1
    %1021 = torch.aten.add.Tensor %1020, %1015, %int1_1266 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1267 = torch.constant.int 5
    %1022 = torch.prims.convert_element_type %1021, %int5_1267 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %1023 = torch.aten.silu %1022 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16>
    %1024 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16>
    %1025 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1268 = torch.constant.int 1
    %int1_1269 = torch.constant.int 1
    %1026 = torch.prim.ListConstruct %int1_1268, %int1_1269 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1270 = torch.constant.int 1
    %int1_1271 = torch.constant.int 1
    %1027 = torch.prim.ListConstruct %int1_1270, %int1_1271 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1272 = torch.constant.int 1
    %int1_1273 = torch.constant.int 1
    %1028 = torch.prim.ListConstruct %int1_1272, %int1_1273 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1274 = torch.constant.bool false
    %int0_1275 = torch.constant.int 0
    %int0_1276 = torch.constant.int 0
    %1029 = torch.prim.ListConstruct %int0_1275, %int0_1276 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1277 = torch.constant.int 1
    %1030 = torch.aten.convolution %1023, %1024, %1025, %1026, %1027, %1028, %false_1274, %1029, %int1_1277 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1278 = torch.constant.int 8
    %int32_1279 = torch.constant.int 32
    %int4_1280 = torch.constant.int 4
    %int1048576_1281 = torch.constant.int 1048576
    %1031 = torch.prim.ListConstruct %int8_1278, %int32_1279, %int4_1280, %int1048576_1281 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1032 = torch.aten.view %1030, %1031 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1282 = torch.constant.int 6
    %1033 = torch.prims.convert_element_type %1032, %int6_1282 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1283 = torch.constant.int 2
    %int3_1284 = torch.constant.int 3
    %1034 = torch.prim.ListConstruct %int2_1283, %int3_1284 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1285 = torch.constant.int 0
    %true_1286 = torch.constant.bool true
    %result0_1287, %result1_1288 = torch.aten.var_mean.correction %1033, %1034, %int0_1285, %true_1286 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1289 = torch.constant.float 9.9999999999999995E-7
    %int1_1290 = torch.constant.int 1
    %1035 = torch.aten.add.Scalar %result0_1287, %float9.999990e-07_1289, %int1_1290 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %1036 = torch.aten.rsqrt %1035 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1291 = torch.constant.int 1
    %1037 = torch.aten.sub.Tensor %1032, %result1_1288, %int1_1291 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %1038 = torch.aten.mul.Tensor %1037, %1036 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1292 = torch.constant.int 8
    %int128_1293 = torch.constant.int 128
    %int1024_1294 = torch.constant.int 1024
    %int1024_1295 = torch.constant.int 1024
    %1039 = torch.prim.ListConstruct %int8_1292, %int128_1293, %int1024_1294, %int1024_1295 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1040 = torch.aten.view %1038, %1039 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16>
    %1041 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1296 = torch.constant.int 0
    %1042 = torch.aten.unsqueeze %1041, %int0_1296 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1297 = torch.constant.int 2
    %1043 = torch.aten.unsqueeze %1042, %int2_1297 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1298 = torch.constant.int 3
    %1044 = torch.aten.unsqueeze %1043, %int3_1298 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16>
    %1045 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1299 = torch.constant.int 0
    %1046 = torch.aten.unsqueeze %1045, %int0_1299 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1300 = torch.constant.int 2
    %1047 = torch.aten.unsqueeze %1046, %int2_1300 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1301 = torch.constant.int 3
    %1048 = torch.aten.unsqueeze %1047, %int3_1301 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1049 = torch.aten.mul.Tensor %1040, %1048 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1302 = torch.constant.int 1
    %1050 = torch.aten.add.Tensor %1049, %1044, %int1_1302 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1303 = torch.constant.int 5
    %1051 = torch.prims.convert_element_type %1050, %int5_1303 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %1052 = torch.aten.silu %1051 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %none_1304 = torch.constant.none
    %1053 = torch.aten.clone %1052, %none_1304 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16>
    %1054 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16>
    %1055 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1305 = torch.constant.int 1
    %int1_1306 = torch.constant.int 1
    %1056 = torch.prim.ListConstruct %int1_1305, %int1_1306 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1307 = torch.constant.int 1
    %int1_1308 = torch.constant.int 1
    %1057 = torch.prim.ListConstruct %int1_1307, %int1_1308 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1309 = torch.constant.int 1
    %int1_1310 = torch.constant.int 1
    %1058 = torch.prim.ListConstruct %int1_1309, %int1_1310 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1311 = torch.constant.bool false
    %int0_1312 = torch.constant.int 0
    %int0_1313 = torch.constant.int 0
    %1059 = torch.prim.ListConstruct %int0_1312, %int0_1313 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1314 = torch.constant.int 1
    %1060 = torch.aten.convolution %1053, %1054, %1055, %1056, %1057, %1058, %false_1311, %1059, %int1_1314 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int1_1315 = torch.constant.int 1
    %1061 = torch.aten.add.Tensor %1001, %1060, %int1_1315 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[8,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %float1.000000e00_1316 = torch.constant.float 1.000000e+00
    %1062 = torch.aten.div.Scalar %1061, %float1.000000e00_1316 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_1317 = torch.constant.int 8
    %int32_1318 = torch.constant.int 32
    %int4_1319 = torch.constant.int 4
    %int1048576_1320 = torch.constant.int 1048576
    %1063 = torch.prim.ListConstruct %int8_1317, %int32_1318, %int4_1319, %int1048576_1320 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1064 = torch.aten.view %1062, %1063 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_1321 = torch.constant.int 6
    %1065 = torch.prims.convert_element_type %1064, %int6_1321 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_1322 = torch.constant.int 2
    %int3_1323 = torch.constant.int 3
    %1066 = torch.prim.ListConstruct %int2_1322, %int3_1323 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1324 = torch.constant.int 0
    %true_1325 = torch.constant.bool true
    %result0_1326, %result1_1327 = torch.aten.var_mean.correction %1065, %1066, %int0_1324, %true_1325 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_1328 = torch.constant.float 9.9999999999999995E-7
    %int1_1329 = torch.constant.int 1
    %1067 = torch.aten.add.Scalar %result0_1326, %float9.999990e-07_1328, %int1_1329 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %1068 = torch.aten.rsqrt %1067 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_1330 = torch.constant.int 1
    %1069 = torch.aten.sub.Tensor %1064, %result1_1327, %int1_1330 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %1070 = torch.aten.mul.Tensor %1069, %1068 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_1331 = torch.constant.int 8
    %int128_1332 = torch.constant.int 128
    %int1024_1333 = torch.constant.int 1024
    %int1024_1334 = torch.constant.int 1024
    %1071 = torch.prim.ListConstruct %int8_1331, %int128_1332, %int1024_1333, %int1024_1334 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1072 = torch.aten.view %1070, %1071 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.decoder.conv_norm_out.bias = util.global.load @__auto.vae.decoder.conv_norm_out.bias : tensor<128xf16>
    %1073 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_norm_out.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1335 = torch.constant.int 0
    %1074 = torch.aten.unsqueeze %1073, %int0_1335 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1336 = torch.constant.int 2
    %1075 = torch.aten.unsqueeze %1074, %int2_1336 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1337 = torch.constant.int 3
    %1076 = torch.aten.unsqueeze %1075, %int3_1337 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.conv_norm_out.weight = util.global.load @__auto.vae.decoder.conv_norm_out.weight : tensor<128xf16>
    %1077 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_norm_out.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1338 = torch.constant.int 0
    %1078 = torch.aten.unsqueeze %1077, %int0_1338 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1339 = torch.constant.int 2
    %1079 = torch.aten.unsqueeze %1078, %int2_1339 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1340 = torch.constant.int 3
    %1080 = torch.aten.unsqueeze %1079, %int3_1340 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1081 = torch.aten.mul.Tensor %1072, %1080 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_1341 = torch.constant.int 1
    %1082 = torch.aten.add.Tensor %1081, %1076, %int1_1341 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_1342 = torch.constant.int 5
    %1083 = torch.prims.convert_element_type %1082, %int5_1342 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %1084 = torch.aten.silu %1083 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.decoder.conv_out.weight = util.global.load @__auto.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16>
    %1085 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16> -> !torch.vtensor<[3,128,3,3],f16>
    %__auto.vae.decoder.conv_out.bias = util.global.load @__auto.vae.decoder.conv_out.bias : tensor<3xf16>
    %1086 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_out.bias : tensor<3xf16> -> !torch.vtensor<[3],f16>
    %int1_1343 = torch.constant.int 1
    %int1_1344 = torch.constant.int 1
    %1087 = torch.prim.ListConstruct %int1_1343, %int1_1344 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1345 = torch.constant.int 1
    %int1_1346 = torch.constant.int 1
    %1088 = torch.prim.ListConstruct %int1_1345, %int1_1346 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1347 = torch.constant.int 1
    %int1_1348 = torch.constant.int 1
    %1089 = torch.prim.ListConstruct %int1_1347, %int1_1348 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1349 = torch.constant.bool false
    %int0_1350 = torch.constant.int 0
    %int0_1351 = torch.constant.int 0
    %1090 = torch.prim.ListConstruct %int0_1350, %int0_1351 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1352 = torch.constant.int 1
    %1091 = torch.aten.convolution %1084, %1085, %1086, %1087, %1088, %1089, %false_1349, %1090, %int1_1352 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[3,128,3,3],f16>, !torch.vtensor<[3],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,3,1024,1024],f16>
    %int2_1353 = torch.constant.int 2
    %1092 = torch.aten.div.Scalar %1091, %int2_1353 : !torch.vtensor<[8,3,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,3,1024,1024],f16>
    %float5.000000e-01_1354 = torch.constant.float 5.000000e-01
    %int1_1355 = torch.constant.int 1
    %1093 = torch.aten.add.Scalar %1092, %float5.000000e-01_1354, %int1_1355 : !torch.vtensor<[8,3,1024,1024],f16>, !torch.float, !torch.int -> !torch.vtensor<[8,3,1024,1024],f16>
    %int0_1356 = torch.constant.int 0
    %int1_1357 = torch.constant.int 1
    %1094 = torch.aten.clamp %1093, %int0_1356, %int1_1357 : !torch.vtensor<[8,3,1024,1024],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,3,1024,1024],f16>
    return %1094 : !torch.vtensor<[8,3,1024,1024],f16>
  }
  func.func @encode(%arg0: !torch.vtensor<[8,3,1024,1024],f16>) -> !torch.vtensor<[8,4,128,128],f16> attributes {iree.reflection = {input_dtypes = "\22['float16']\22", input_shapes = "\22[(8, 4, 128, 128)]\22", model_name = "\22vae_decode\22", output_dtypes = "\22['float32']\22", output_shapes = "\22[(3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024)]\22"}, torch.assume_strict_symbolic_shapes} {
    %__auto.vae.encoder.conv_in.weight = util.global.load @__auto.vae.encoder.conv_in.weight : tensor<128x3x3x3xf16>
    %0 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_in.weight : tensor<128x3x3x3xf16> -> !torch.vtensor<[128,3,3,3],f16>
    %__auto.vae.encoder.conv_in.bias = util.global.load @__auto.vae.encoder.conv_in.bias : tensor<128xf16>
    %1 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_in.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %2 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1 = torch.constant.int 1
    %int1_2 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1_1, %int1_2 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_3 = torch.constant.int 1
    %int1_4 = torch.constant.int 1
    %4 = torch.prim.ListConstruct %int1_3, %int1_4 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %5 = torch.prim.ListConstruct %int0, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %6 = torch.aten.convolution %arg0, %0, %1, %2, %3, %4, %false, %5, %int1_6 : !torch.vtensor<[8,3,1024,1024],f16>, !torch.vtensor<[128,3,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8 = torch.constant.int 8
    %int32 = torch.constant.int 32
    %int4 = torch.constant.int 4
    %int1048576 = torch.constant.int 1048576
    %7 = torch.prim.ListConstruct %int8, %int32, %int4, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %8 = torch.aten.view %6, %7 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6 = torch.constant.int 6
    %9 = torch.prims.convert_element_type %8, %int6 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %10 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_7 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %9, %10, %int0_7, %true : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_8 = torch.constant.int 1
    %11 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_8 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %12 = torch.aten.rsqrt %11 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_9 = torch.constant.int 1
    %13 = torch.aten.sub.Tensor %8, %result1, %int1_9 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %14 = torch.aten.mul.Tensor %13, %12 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_10 = torch.constant.int 8
    %int128 = torch.constant.int 128
    %int1024 = torch.constant.int 1024
    %int1024_11 = torch.constant.int 1024
    %15 = torch.prim.ListConstruct %int8_10, %int128, %int1024, %int1024_11 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.encoder.down_blocks.0.resnets.0.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.norm1.bias : tensor<128xf16>
    %17 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_12 = torch.constant.int 0
    %18 = torch.aten.unsqueeze %17, %int0_12 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_13 = torch.constant.int 2
    %19 = torch.aten.unsqueeze %18, %int2_13 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_14 = torch.constant.int 3
    %20 = torch.aten.unsqueeze %19, %int3_14 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.norm1.weight : tensor<128xf16>
    %21 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_15 = torch.constant.int 0
    %22 = torch.aten.unsqueeze %21, %int0_15 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_16 = torch.constant.int 2
    %23 = torch.aten.unsqueeze %22, %int2_16 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_17 = torch.constant.int 3
    %24 = torch.aten.unsqueeze %23, %int3_17 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %25 = torch.aten.mul.Tensor %16, %24 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_18 = torch.constant.int 1
    %26 = torch.aten.add.Tensor %25, %20, %int1_18 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5 = torch.constant.int 5
    %27 = torch.prims.convert_element_type %26, %int5 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %28 = torch.aten.silu %27 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.conv1.weight : tensor<128x128x3x3xf16>
    %29 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.conv1.bias : tensor<128xf16>
    %30 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_19 = torch.constant.int 1
    %int1_20 = torch.constant.int 1
    %31 = torch.prim.ListConstruct %int1_19, %int1_20 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_21 = torch.constant.int 1
    %int1_22 = torch.constant.int 1
    %32 = torch.prim.ListConstruct %int1_21, %int1_22 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_23 = torch.constant.int 1
    %int1_24 = torch.constant.int 1
    %33 = torch.prim.ListConstruct %int1_23, %int1_24 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_25 = torch.constant.bool false
    %int0_26 = torch.constant.int 0
    %int0_27 = torch.constant.int 0
    %34 = torch.prim.ListConstruct %int0_26, %int0_27 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_28 = torch.constant.int 1
    %35 = torch.aten.convolution %28, %29, %30, %31, %32, %33, %false_25, %34, %int1_28 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_29 = torch.constant.int 8
    %int32_30 = torch.constant.int 32
    %int4_31 = torch.constant.int 4
    %int1048576_32 = torch.constant.int 1048576
    %36 = torch.prim.ListConstruct %int8_29, %int32_30, %int4_31, %int1048576_32 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %37 = torch.aten.view %35, %36 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_33 = torch.constant.int 6
    %38 = torch.prims.convert_element_type %37, %int6_33 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_34 = torch.constant.int 2
    %int3_35 = torch.constant.int 3
    %39 = torch.prim.ListConstruct %int2_34, %int3_35 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_36 = torch.constant.int 0
    %true_37 = torch.constant.bool true
    %result0_38, %result1_39 = torch.aten.var_mean.correction %38, %39, %int0_36, %true_37 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_40 = torch.constant.float 9.9999999999999995E-7
    %int1_41 = torch.constant.int 1
    %40 = torch.aten.add.Scalar %result0_38, %float9.999990e-07_40, %int1_41 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %41 = torch.aten.rsqrt %40 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_42 = torch.constant.int 1
    %42 = torch.aten.sub.Tensor %37, %result1_39, %int1_42 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %43 = torch.aten.mul.Tensor %42, %41 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_43 = torch.constant.int 8
    %int128_44 = torch.constant.int 128
    %int1024_45 = torch.constant.int 1024
    %int1024_46 = torch.constant.int 1024
    %44 = torch.prim.ListConstruct %int8_43, %int128_44, %int1024_45, %int1024_46 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %45 = torch.aten.view %43, %44 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.encoder.down_blocks.0.resnets.0.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.norm2.bias : tensor<128xf16>
    %46 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_47 = torch.constant.int 0
    %47 = torch.aten.unsqueeze %46, %int0_47 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_48 = torch.constant.int 2
    %48 = torch.aten.unsqueeze %47, %int2_48 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_49 = torch.constant.int 3
    %49 = torch.aten.unsqueeze %48, %int3_49 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.norm2.weight : tensor<128xf16>
    %50 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_50 = torch.constant.int 0
    %51 = torch.aten.unsqueeze %50, %int0_50 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_51 = torch.constant.int 2
    %52 = torch.aten.unsqueeze %51, %int2_51 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_52 = torch.constant.int 3
    %53 = torch.aten.unsqueeze %52, %int3_52 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %54 = torch.aten.mul.Tensor %45, %53 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_53 = torch.constant.int 1
    %55 = torch.aten.add.Tensor %54, %49, %int1_53 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_54 = torch.constant.int 5
    %56 = torch.prims.convert_element_type %55, %int5_54 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %57 = torch.aten.silu %56 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %none = torch.constant.none
    %58 = torch.aten.clone %57, %none : !torch.vtensor<[8,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %59 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.0.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.0.conv2.bias : tensor<128xf16>
    %60 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_55 = torch.constant.int 1
    %int1_56 = torch.constant.int 1
    %61 = torch.prim.ListConstruct %int1_55, %int1_56 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_57 = torch.constant.int 1
    %int1_58 = torch.constant.int 1
    %62 = torch.prim.ListConstruct %int1_57, %int1_58 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_59 = torch.constant.int 1
    %int1_60 = torch.constant.int 1
    %63 = torch.prim.ListConstruct %int1_59, %int1_60 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_61 = torch.constant.bool false
    %int0_62 = torch.constant.int 0
    %int0_63 = torch.constant.int 0
    %64 = torch.prim.ListConstruct %int0_62, %int0_63 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_64 = torch.constant.int 1
    %65 = torch.aten.convolution %58, %59, %60, %61, %62, %63, %false_61, %64, %int1_64 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int1_65 = torch.constant.int 1
    %66 = torch.aten.add.Tensor %6, %65, %int1_65 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[8,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %67 = torch.aten.div.Scalar %66, %float1.000000e00 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_66 = torch.constant.int 8
    %int32_67 = torch.constant.int 32
    %int4_68 = torch.constant.int 4
    %int1048576_69 = torch.constant.int 1048576
    %68 = torch.prim.ListConstruct %int8_66, %int32_67, %int4_68, %int1048576_69 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %69 = torch.aten.view %67, %68 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_70 = torch.constant.int 6
    %70 = torch.prims.convert_element_type %69, %int6_70 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_71 = torch.constant.int 2
    %int3_72 = torch.constant.int 3
    %71 = torch.prim.ListConstruct %int2_71, %int3_72 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_73 = torch.constant.int 0
    %true_74 = torch.constant.bool true
    %result0_75, %result1_76 = torch.aten.var_mean.correction %70, %71, %int0_73, %true_74 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_77 = torch.constant.float 9.9999999999999995E-7
    %int1_78 = torch.constant.int 1
    %72 = torch.aten.add.Scalar %result0_75, %float9.999990e-07_77, %int1_78 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %73 = torch.aten.rsqrt %72 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_79 = torch.constant.int 1
    %74 = torch.aten.sub.Tensor %69, %result1_76, %int1_79 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %75 = torch.aten.mul.Tensor %74, %73 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_80 = torch.constant.int 8
    %int128_81 = torch.constant.int 128
    %int1024_82 = torch.constant.int 1024
    %int1024_83 = torch.constant.int 1024
    %76 = torch.prim.ListConstruct %int8_80, %int128_81, %int1024_82, %int1024_83 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %75, %76 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.encoder.down_blocks.0.resnets.1.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.norm1.bias : tensor<128xf16>
    %78 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_84 = torch.constant.int 0
    %79 = torch.aten.unsqueeze %78, %int0_84 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_85 = torch.constant.int 2
    %80 = torch.aten.unsqueeze %79, %int2_85 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_86 = torch.constant.int 3
    %81 = torch.aten.unsqueeze %80, %int3_86 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.norm1.weight : tensor<128xf16>
    %82 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_87 = torch.constant.int 0
    %83 = torch.aten.unsqueeze %82, %int0_87 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_88 = torch.constant.int 2
    %84 = torch.aten.unsqueeze %83, %int2_88 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_89 = torch.constant.int 3
    %85 = torch.aten.unsqueeze %84, %int3_89 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %86 = torch.aten.mul.Tensor %77, %85 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_90 = torch.constant.int 1
    %87 = torch.aten.add.Tensor %86, %81, %int1_90 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_91 = torch.constant.int 5
    %88 = torch.prims.convert_element_type %87, %int5_91 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %89 = torch.aten.silu %88 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %90 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.conv1.bias : tensor<128xf16>
    %91 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_92 = torch.constant.int 1
    %int1_93 = torch.constant.int 1
    %92 = torch.prim.ListConstruct %int1_92, %int1_93 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_94 = torch.constant.int 1
    %int1_95 = torch.constant.int 1
    %93 = torch.prim.ListConstruct %int1_94, %int1_95 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_96 = torch.constant.int 1
    %int1_97 = torch.constant.int 1
    %94 = torch.prim.ListConstruct %int1_96, %int1_97 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_98 = torch.constant.bool false
    %int0_99 = torch.constant.int 0
    %int0_100 = torch.constant.int 0
    %95 = torch.prim.ListConstruct %int0_99, %int0_100 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_101 = torch.constant.int 1
    %96 = torch.aten.convolution %89, %90, %91, %92, %93, %94, %false_98, %95, %int1_101 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int8_102 = torch.constant.int 8
    %int32_103 = torch.constant.int 32
    %int4_104 = torch.constant.int 4
    %int1048576_105 = torch.constant.int 1048576
    %97 = torch.prim.ListConstruct %int8_102, %int32_103, %int4_104, %int1048576_105 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %98 = torch.aten.view %96, %97 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,1048576],f16>
    %int6_106 = torch.constant.int 6
    %99 = torch.prims.convert_element_type %98, %int6_106 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %int2_107 = torch.constant.int 2
    %int3_108 = torch.constant.int 3
    %100 = torch.prim.ListConstruct %int2_107, %int3_108 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_109 = torch.constant.int 0
    %true_110 = torch.constant.bool true
    %result0_111, %result1_112 = torch.aten.var_mean.correction %99, %100, %int0_109, %true_110 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_113 = torch.constant.float 9.9999999999999995E-7
    %int1_114 = torch.constant.int 1
    %101 = torch.aten.add.Scalar %result0_111, %float9.999990e-07_113, %int1_114 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %102 = torch.aten.rsqrt %101 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_115 = torch.constant.int 1
    %103 = torch.aten.sub.Tensor %98, %result1_112, %int1_115 : !torch.vtensor<[8,32,4,1048576],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,1048576],f32>
    %104 = torch.aten.mul.Tensor %103, %102 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,1048576],f32>
    %int8_116 = torch.constant.int 8
    %int128_117 = torch.constant.int 128
    %int1024_118 = torch.constant.int 1024
    %int1024_119 = torch.constant.int 1024
    %105 = torch.prim.ListConstruct %int8_116, %int128_117, %int1024_118, %int1024_119 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %106 = torch.aten.view %104, %105 : !torch.vtensor<[8,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[8,128,1024,1024],f32>
    %__auto.vae.encoder.down_blocks.0.resnets.1.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.norm2.bias : tensor<128xf16>
    %107 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_120 = torch.constant.int 0
    %108 = torch.aten.unsqueeze %107, %int0_120 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_121 = torch.constant.int 2
    %109 = torch.aten.unsqueeze %108, %int2_121 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_122 = torch.constant.int 3
    %110 = torch.aten.unsqueeze %109, %int3_122 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.norm2.weight : tensor<128xf16>
    %111 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_123 = torch.constant.int 0
    %112 = torch.aten.unsqueeze %111, %int0_123 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_124 = torch.constant.int 2
    %113 = torch.aten.unsqueeze %112, %int2_124 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_125 = torch.constant.int 3
    %114 = torch.aten.unsqueeze %113, %int3_125 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %115 = torch.aten.mul.Tensor %106, %114 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,1024,1024],f32>
    %int1_126 = torch.constant.int 1
    %116 = torch.aten.add.Tensor %115, %110, %int1_126 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f32>
    %int5_127 = torch.constant.int 5
    %117 = torch.prims.convert_element_type %116, %int5_127 : !torch.vtensor<[8,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %118 = torch.aten.silu %117 : !torch.vtensor<[8,128,1024,1024],f16> -> !torch.vtensor<[8,128,1024,1024],f16>
    %none_128 = torch.constant.none
    %119 = torch.aten.clone %118, %none_128 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[8,128,1024,1024],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %120 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.0.resnets.1.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.0.resnets.1.conv2.bias : tensor<128xf16>
    %121 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_129 = torch.constant.int 1
    %int1_130 = torch.constant.int 1
    %122 = torch.prim.ListConstruct %int1_129, %int1_130 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_131 = torch.constant.int 1
    %int1_132 = torch.constant.int 1
    %123 = torch.prim.ListConstruct %int1_131, %int1_132 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_133 = torch.constant.int 1
    %int1_134 = torch.constant.int 1
    %124 = torch.prim.ListConstruct %int1_133, %int1_134 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_135 = torch.constant.bool false
    %int0_136 = torch.constant.int 0
    %int0_137 = torch.constant.int 0
    %125 = torch.prim.ListConstruct %int0_136, %int0_137 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_138 = torch.constant.int 1
    %126 = torch.aten.convolution %119, %120, %121, %122, %123, %124, %false_135, %125, %int1_138 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %int1_139 = torch.constant.int 1
    %127 = torch.aten.add.Tensor %67, %126, %int1_139 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.vtensor<[8,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[8,128,1024,1024],f16>
    %float1.000000e00_140 = torch.constant.float 1.000000e+00
    %128 = torch.aten.div.Scalar %127, %float1.000000e00_140 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[8,128,1024,1024],f16>
    %int0_141 = torch.constant.int 0
    %int1_142 = torch.constant.int 1
    %int0_143 = torch.constant.int 0
    %int1_144 = torch.constant.int 1
    %129 = torch.prim.ListConstruct %int0_141, %int1_142, %int0_143, %int1_144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %130 = torch.aten.constant_pad_nd %128, %129, %float0.000000e00 : !torch.vtensor<[8,128,1024,1024],f16>, !torch.list<int>, !torch.float -> !torch.vtensor<[8,128,1025,1025],f16>
    %__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.weight = util.global.load @__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.weight : tensor<128x128x3x3xf16>
    %131 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.bias = util.global.load @__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.bias : tensor<128xf16>
    %132 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.0.downsamplers.0.conv.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int2_145 = torch.constant.int 2
    %int2_146 = torch.constant.int 2
    %133 = torch.prim.ListConstruct %int2_145, %int2_146 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_147 = torch.constant.int 0
    %int0_148 = torch.constant.int 0
    %134 = torch.prim.ListConstruct %int0_147, %int0_148 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_149 = torch.constant.int 1
    %int1_150 = torch.constant.int 1
    %135 = torch.prim.ListConstruct %int1_149, %int1_150 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_151 = torch.constant.bool false
    %int0_152 = torch.constant.int 0
    %int0_153 = torch.constant.int 0
    %136 = torch.prim.ListConstruct %int0_152, %int0_153 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_154 = torch.constant.int 1
    %137 = torch.aten.convolution %130, %131, %132, %133, %134, %135, %false_151, %136, %int1_154 : !torch.vtensor<[8,128,1025,1025],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,128,512,512],f16>
    %int8_155 = torch.constant.int 8
    %int32_156 = torch.constant.int 32
    %int4_157 = torch.constant.int 4
    %int262144 = torch.constant.int 262144
    %138 = torch.prim.ListConstruct %int8_155, %int32_156, %int4_157, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %139 = torch.aten.view %137, %138 : !torch.vtensor<[8,128,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,4,262144],f16>
    %int6_158 = torch.constant.int 6
    %140 = torch.prims.convert_element_type %139, %int6_158 : !torch.vtensor<[8,32,4,262144],f16>, !torch.int -> !torch.vtensor<[8,32,4,262144],f32>
    %int2_159 = torch.constant.int 2
    %int3_160 = torch.constant.int 3
    %141 = torch.prim.ListConstruct %int2_159, %int3_160 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_161 = torch.constant.int 0
    %true_162 = torch.constant.bool true
    %result0_163, %result1_164 = torch.aten.var_mean.correction %140, %141, %int0_161, %true_162 : !torch.vtensor<[8,32,4,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_165 = torch.constant.float 9.9999999999999995E-7
    %int1_166 = torch.constant.int 1
    %142 = torch.aten.add.Scalar %result0_163, %float9.999990e-07_165, %int1_166 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %143 = torch.aten.rsqrt %142 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_167 = torch.constant.int 1
    %144 = torch.aten.sub.Tensor %139, %result1_164, %int1_167 : !torch.vtensor<[8,32,4,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,4,262144],f32>
    %145 = torch.aten.mul.Tensor %144, %143 : !torch.vtensor<[8,32,4,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,4,262144],f32>
    %int8_168 = torch.constant.int 8
    %int128_169 = torch.constant.int 128
    %int512 = torch.constant.int 512
    %int512_170 = torch.constant.int 512
    %146 = torch.prim.ListConstruct %int8_168, %int128_169, %int512, %int512_170 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %147 = torch.aten.view %145, %146 : !torch.vtensor<[8,32,4,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,128,512,512],f32>
    %__auto.vae.encoder.down_blocks.1.resnets.0.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.norm1.bias : tensor<128xf16>
    %148 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_171 = torch.constant.int 0
    %149 = torch.aten.unsqueeze %148, %int0_171 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_172 = torch.constant.int 2
    %150 = torch.aten.unsqueeze %149, %int2_172 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_173 = torch.constant.int 3
    %151 = torch.aten.unsqueeze %150, %int3_173 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.norm1.weight : tensor<128xf16>
    %152 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_174 = torch.constant.int 0
    %153 = torch.aten.unsqueeze %152, %int0_174 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_175 = torch.constant.int 2
    %154 = torch.aten.unsqueeze %153, %int2_175 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_176 = torch.constant.int 3
    %155 = torch.aten.unsqueeze %154, %int3_176 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %156 = torch.aten.mul.Tensor %147, %155 : !torch.vtensor<[8,128,512,512],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[8,128,512,512],f32>
    %int1_177 = torch.constant.int 1
    %157 = torch.aten.add.Tensor %156, %151, %int1_177 : !torch.vtensor<[8,128,512,512],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[8,128,512,512],f32>
    %int5_178 = torch.constant.int 5
    %158 = torch.prims.convert_element_type %157, %int5_178 : !torch.vtensor<[8,128,512,512],f32>, !torch.int -> !torch.vtensor<[8,128,512,512],f16>
    %159 = torch.aten.silu %158 : !torch.vtensor<[8,128,512,512],f16> -> !torch.vtensor<[8,128,512,512],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv1.weight : tensor<256x128x3x3xf16>
    %160 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv1.weight : tensor<256x128x3x3xf16> -> !torch.vtensor<[256,128,3,3],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv1.bias : tensor<256xf16>
    %161 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_179 = torch.constant.int 1
    %int1_180 = torch.constant.int 1
    %162 = torch.prim.ListConstruct %int1_179, %int1_180 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_181 = torch.constant.int 1
    %int1_182 = torch.constant.int 1
    %163 = torch.prim.ListConstruct %int1_181, %int1_182 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_183 = torch.constant.int 1
    %int1_184 = torch.constant.int 1
    %164 = torch.prim.ListConstruct %int1_183, %int1_184 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_185 = torch.constant.bool false
    %int0_186 = torch.constant.int 0
    %int0_187 = torch.constant.int 0
    %165 = torch.prim.ListConstruct %int0_186, %int0_187 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_188 = torch.constant.int 1
    %166 = torch.aten.convolution %159, %160, %161, %162, %163, %164, %false_185, %165, %int1_188 : !torch.vtensor<[8,128,512,512],f16>, !torch.vtensor<[256,128,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int8_189 = torch.constant.int 8
    %int32_190 = torch.constant.int 32
    %int8_191 = torch.constant.int 8
    %int262144_192 = torch.constant.int 262144
    %167 = torch.prim.ListConstruct %int8_189, %int32_190, %int8_191, %int262144_192 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %168 = torch.aten.view %166, %167 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_193 = torch.constant.int 6
    %169 = torch.prims.convert_element_type %168, %int6_193 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_194 = torch.constant.int 2
    %int3_195 = torch.constant.int 3
    %170 = torch.prim.ListConstruct %int2_194, %int3_195 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_196 = torch.constant.int 0
    %true_197 = torch.constant.bool true
    %result0_198, %result1_199 = torch.aten.var_mean.correction %169, %170, %int0_196, %true_197 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_200 = torch.constant.float 9.9999999999999995E-7
    %int1_201 = torch.constant.int 1
    %171 = torch.aten.add.Scalar %result0_198, %float9.999990e-07_200, %int1_201 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %172 = torch.aten.rsqrt %171 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_202 = torch.constant.int 1
    %173 = torch.aten.sub.Tensor %168, %result1_199, %int1_202 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %174 = torch.aten.mul.Tensor %173, %172 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_203 = torch.constant.int 8
    %int256 = torch.constant.int 256
    %int512_204 = torch.constant.int 512
    %int512_205 = torch.constant.int 512
    %175 = torch.prim.ListConstruct %int8_203, %int256, %int512_204, %int512_205 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %176 = torch.aten.view %174, %175 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.encoder.down_blocks.1.resnets.0.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.norm2.bias : tensor<256xf16>
    %177 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_206 = torch.constant.int 0
    %178 = torch.aten.unsqueeze %177, %int0_206 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_207 = torch.constant.int 2
    %179 = torch.aten.unsqueeze %178, %int2_207 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_208 = torch.constant.int 3
    %180 = torch.aten.unsqueeze %179, %int3_208 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.norm2.weight : tensor<256xf16>
    %181 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_209 = torch.constant.int 0
    %182 = torch.aten.unsqueeze %181, %int0_209 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_210 = torch.constant.int 2
    %183 = torch.aten.unsqueeze %182, %int2_210 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_211 = torch.constant.int 3
    %184 = torch.aten.unsqueeze %183, %int3_211 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %185 = torch.aten.mul.Tensor %176, %184 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_212 = torch.constant.int 1
    %186 = torch.aten.add.Tensor %185, %180, %int1_212 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_213 = torch.constant.int 5
    %187 = torch.prims.convert_element_type %186, %int5_213 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %188 = torch.aten.silu %187 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %none_214 = torch.constant.none
    %189 = torch.aten.clone %188, %none_214 : !torch.vtensor<[8,256,512,512],f16>, !torch.none -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %190 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv2.bias : tensor<256xf16>
    %191 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_215 = torch.constant.int 1
    %int1_216 = torch.constant.int 1
    %192 = torch.prim.ListConstruct %int1_215, %int1_216 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_217 = torch.constant.int 1
    %int1_218 = torch.constant.int 1
    %193 = torch.prim.ListConstruct %int1_217, %int1_218 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_219 = torch.constant.int 1
    %int1_220 = torch.constant.int 1
    %194 = torch.prim.ListConstruct %int1_219, %int1_220 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_221 = torch.constant.bool false
    %int0_222 = torch.constant.int 0
    %int0_223 = torch.constant.int 0
    %195 = torch.prim.ListConstruct %int0_222, %int0_223 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_224 = torch.constant.int 1
    %196 = torch.aten.convolution %189, %190, %191, %192, %193, %194, %false_221, %195, %int1_224 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight : tensor<256x128x1x1xf16>
    %197 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight : tensor<256x128x1x1xf16> -> !torch.vtensor<[256,128,1,1],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %198 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_225 = torch.constant.int 1
    %int1_226 = torch.constant.int 1
    %199 = torch.prim.ListConstruct %int1_225, %int1_226 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_227 = torch.constant.int 0
    %int0_228 = torch.constant.int 0
    %200 = torch.prim.ListConstruct %int0_227, %int0_228 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_229 = torch.constant.int 1
    %int1_230 = torch.constant.int 1
    %201 = torch.prim.ListConstruct %int1_229, %int1_230 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_231 = torch.constant.bool false
    %int0_232 = torch.constant.int 0
    %int0_233 = torch.constant.int 0
    %202 = torch.prim.ListConstruct %int0_232, %int0_233 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_234 = torch.constant.int 1
    %203 = torch.aten.convolution %137, %197, %198, %199, %200, %201, %false_231, %202, %int1_234 : !torch.vtensor<[8,128,512,512],f16>, !torch.vtensor<[256,128,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int1_235 = torch.constant.int 1
    %204 = torch.aten.add.Tensor %203, %196, %int1_235 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %float1.000000e00_236 = torch.constant.float 1.000000e+00
    %205 = torch.aten.div.Scalar %204, %float1.000000e00_236 : !torch.vtensor<[8,256,512,512],f16>, !torch.float -> !torch.vtensor<[8,256,512,512],f16>
    %int8_237 = torch.constant.int 8
    %int32_238 = torch.constant.int 32
    %int8_239 = torch.constant.int 8
    %int262144_240 = torch.constant.int 262144
    %206 = torch.prim.ListConstruct %int8_237, %int32_238, %int8_239, %int262144_240 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %207 = torch.aten.view %205, %206 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_241 = torch.constant.int 6
    %208 = torch.prims.convert_element_type %207, %int6_241 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_242 = torch.constant.int 2
    %int3_243 = torch.constant.int 3
    %209 = torch.prim.ListConstruct %int2_242, %int3_243 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_244 = torch.constant.int 0
    %true_245 = torch.constant.bool true
    %result0_246, %result1_247 = torch.aten.var_mean.correction %208, %209, %int0_244, %true_245 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_248 = torch.constant.float 9.9999999999999995E-7
    %int1_249 = torch.constant.int 1
    %210 = torch.aten.add.Scalar %result0_246, %float9.999990e-07_248, %int1_249 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %211 = torch.aten.rsqrt %210 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_250 = torch.constant.int 1
    %212 = torch.aten.sub.Tensor %207, %result1_247, %int1_250 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %213 = torch.aten.mul.Tensor %212, %211 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_251 = torch.constant.int 8
    %int256_252 = torch.constant.int 256
    %int512_253 = torch.constant.int 512
    %int512_254 = torch.constant.int 512
    %214 = torch.prim.ListConstruct %int8_251, %int256_252, %int512_253, %int512_254 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %215 = torch.aten.view %213, %214 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.encoder.down_blocks.1.resnets.1.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.norm1.bias : tensor<256xf16>
    %216 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_255 = torch.constant.int 0
    %217 = torch.aten.unsqueeze %216, %int0_255 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_256 = torch.constant.int 2
    %218 = torch.aten.unsqueeze %217, %int2_256 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_257 = torch.constant.int 3
    %219 = torch.aten.unsqueeze %218, %int3_257 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.norm1.weight : tensor<256xf16>
    %220 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_258 = torch.constant.int 0
    %221 = torch.aten.unsqueeze %220, %int0_258 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_259 = torch.constant.int 2
    %222 = torch.aten.unsqueeze %221, %int2_259 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_260 = torch.constant.int 3
    %223 = torch.aten.unsqueeze %222, %int3_260 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %224 = torch.aten.mul.Tensor %215, %223 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_261 = torch.constant.int 1
    %225 = torch.aten.add.Tensor %224, %219, %int1_261 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_262 = torch.constant.int 5
    %226 = torch.prims.convert_element_type %225, %int5_262 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %227 = torch.aten.silu %226 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %228 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.conv1.bias : tensor<256xf16>
    %229 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_263 = torch.constant.int 1
    %int1_264 = torch.constant.int 1
    %230 = torch.prim.ListConstruct %int1_263, %int1_264 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_265 = torch.constant.int 1
    %int1_266 = torch.constant.int 1
    %231 = torch.prim.ListConstruct %int1_265, %int1_266 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_267 = torch.constant.int 1
    %int1_268 = torch.constant.int 1
    %232 = torch.prim.ListConstruct %int1_267, %int1_268 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_269 = torch.constant.bool false
    %int0_270 = torch.constant.int 0
    %int0_271 = torch.constant.int 0
    %233 = torch.prim.ListConstruct %int0_270, %int0_271 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_272 = torch.constant.int 1
    %234 = torch.aten.convolution %227, %228, %229, %230, %231, %232, %false_269, %233, %int1_272 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int8_273 = torch.constant.int 8
    %int32_274 = torch.constant.int 32
    %int8_275 = torch.constant.int 8
    %int262144_276 = torch.constant.int 262144
    %235 = torch.prim.ListConstruct %int8_273, %int32_274, %int8_275, %int262144_276 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %236 = torch.aten.view %234, %235 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,262144],f16>
    %int6_277 = torch.constant.int 6
    %237 = torch.prims.convert_element_type %236, %int6_277 : !torch.vtensor<[8,32,8,262144],f16>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %int2_278 = torch.constant.int 2
    %int3_279 = torch.constant.int 3
    %238 = torch.prim.ListConstruct %int2_278, %int3_279 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_280 = torch.constant.int 0
    %true_281 = torch.constant.bool true
    %result0_282, %result1_283 = torch.aten.var_mean.correction %237, %238, %int0_280, %true_281 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_284 = torch.constant.float 9.9999999999999995E-7
    %int1_285 = torch.constant.int 1
    %239 = torch.aten.add.Scalar %result0_282, %float9.999990e-07_284, %int1_285 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %240 = torch.aten.rsqrt %239 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_286 = torch.constant.int 1
    %241 = torch.aten.sub.Tensor %236, %result1_283, %int1_286 : !torch.vtensor<[8,32,8,262144],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,262144],f32>
    %242 = torch.aten.mul.Tensor %241, %240 : !torch.vtensor<[8,32,8,262144],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,262144],f32>
    %int8_287 = torch.constant.int 8
    %int256_288 = torch.constant.int 256
    %int512_289 = torch.constant.int 512
    %int512_290 = torch.constant.int 512
    %243 = torch.prim.ListConstruct %int8_287, %int256_288, %int512_289, %int512_290 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %244 = torch.aten.view %242, %243 : !torch.vtensor<[8,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[8,256,512,512],f32>
    %__auto.vae.encoder.down_blocks.1.resnets.1.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.norm2.bias : tensor<256xf16>
    %245 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_291 = torch.constant.int 0
    %246 = torch.aten.unsqueeze %245, %int0_291 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_292 = torch.constant.int 2
    %247 = torch.aten.unsqueeze %246, %int2_292 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_293 = torch.constant.int 3
    %248 = torch.aten.unsqueeze %247, %int3_293 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.norm2.weight : tensor<256xf16>
    %249 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_294 = torch.constant.int 0
    %250 = torch.aten.unsqueeze %249, %int0_294 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_295 = torch.constant.int 2
    %251 = torch.aten.unsqueeze %250, %int2_295 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_296 = torch.constant.int 3
    %252 = torch.aten.unsqueeze %251, %int3_296 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %253 = torch.aten.mul.Tensor %244, %252 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,512,512],f32>
    %int1_297 = torch.constant.int 1
    %254 = torch.aten.add.Tensor %253, %248, %int1_297 : !torch.vtensor<[8,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f32>
    %int5_298 = torch.constant.int 5
    %255 = torch.prims.convert_element_type %254, %int5_298 : !torch.vtensor<[8,256,512,512],f32>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %256 = torch.aten.silu %255 : !torch.vtensor<[8,256,512,512],f16> -> !torch.vtensor<[8,256,512,512],f16>
    %none_299 = torch.constant.none
    %257 = torch.aten.clone %256, %none_299 : !torch.vtensor<[8,256,512,512],f16>, !torch.none -> !torch.vtensor<[8,256,512,512],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %258 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.encoder.down_blocks.1.resnets.1.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.1.resnets.1.conv2.bias : tensor<256xf16>
    %259 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_300 = torch.constant.int 1
    %int1_301 = torch.constant.int 1
    %260 = torch.prim.ListConstruct %int1_300, %int1_301 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_302 = torch.constant.int 1
    %int1_303 = torch.constant.int 1
    %261 = torch.prim.ListConstruct %int1_302, %int1_303 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_304 = torch.constant.int 1
    %int1_305 = torch.constant.int 1
    %262 = torch.prim.ListConstruct %int1_304, %int1_305 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_306 = torch.constant.bool false
    %int0_307 = torch.constant.int 0
    %int0_308 = torch.constant.int 0
    %263 = torch.prim.ListConstruct %int0_307, %int0_308 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_309 = torch.constant.int 1
    %264 = torch.aten.convolution %257, %258, %259, %260, %261, %262, %false_306, %263, %int1_309 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %int1_310 = torch.constant.int 1
    %265 = torch.aten.add.Tensor %205, %264, %int1_310 : !torch.vtensor<[8,256,512,512],f16>, !torch.vtensor<[8,256,512,512],f16>, !torch.int -> !torch.vtensor<[8,256,512,512],f16>
    %float1.000000e00_311 = torch.constant.float 1.000000e+00
    %266 = torch.aten.div.Scalar %265, %float1.000000e00_311 : !torch.vtensor<[8,256,512,512],f16>, !torch.float -> !torch.vtensor<[8,256,512,512],f16>
    %int0_312 = torch.constant.int 0
    %int1_313 = torch.constant.int 1
    %int0_314 = torch.constant.int 0
    %int1_315 = torch.constant.int 1
    %267 = torch.prim.ListConstruct %int0_312, %int1_313, %int0_314, %int1_315 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %float0.000000e00_316 = torch.constant.float 0.000000e+00
    %268 = torch.aten.constant_pad_nd %266, %267, %float0.000000e00_316 : !torch.vtensor<[8,256,512,512],f16>, !torch.list<int>, !torch.float -> !torch.vtensor<[8,256,513,513],f16>
    %__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.weight = util.global.load @__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %269 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.bias = util.global.load @__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.bias : tensor<256xf16>
    %270 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.1.downsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int2_317 = torch.constant.int 2
    %int2_318 = torch.constant.int 2
    %271 = torch.prim.ListConstruct %int2_317, %int2_318 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_319 = torch.constant.int 0
    %int0_320 = torch.constant.int 0
    %272 = torch.prim.ListConstruct %int0_319, %int0_320 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_321 = torch.constant.int 1
    %int1_322 = torch.constant.int 1
    %273 = torch.prim.ListConstruct %int1_321, %int1_322 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_323 = torch.constant.bool false
    %int0_324 = torch.constant.int 0
    %int0_325 = torch.constant.int 0
    %274 = torch.prim.ListConstruct %int0_324, %int0_325 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_326 = torch.constant.int 1
    %275 = torch.aten.convolution %268, %269, %270, %271, %272, %273, %false_323, %274, %int1_326 : !torch.vtensor<[8,256,513,513],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,256,256,256],f16>
    %int8_327 = torch.constant.int 8
    %int32_328 = torch.constant.int 32
    %int8_329 = torch.constant.int 8
    %int65536 = torch.constant.int 65536
    %276 = torch.prim.ListConstruct %int8_327, %int32_328, %int8_329, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %277 = torch.aten.view %275, %276 : !torch.vtensor<[8,256,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,8,65536],f16>
    %int6_330 = torch.constant.int 6
    %278 = torch.prims.convert_element_type %277, %int6_330 : !torch.vtensor<[8,32,8,65536],f16>, !torch.int -> !torch.vtensor<[8,32,8,65536],f32>
    %int2_331 = torch.constant.int 2
    %int3_332 = torch.constant.int 3
    %279 = torch.prim.ListConstruct %int2_331, %int3_332 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_333 = torch.constant.int 0
    %true_334 = torch.constant.bool true
    %result0_335, %result1_336 = torch.aten.var_mean.correction %278, %279, %int0_333, %true_334 : !torch.vtensor<[8,32,8,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_337 = torch.constant.float 9.9999999999999995E-7
    %int1_338 = torch.constant.int 1
    %280 = torch.aten.add.Scalar %result0_335, %float9.999990e-07_337, %int1_338 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %281 = torch.aten.rsqrt %280 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_339 = torch.constant.int 1
    %282 = torch.aten.sub.Tensor %277, %result1_336, %int1_339 : !torch.vtensor<[8,32,8,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,8,65536],f32>
    %283 = torch.aten.mul.Tensor %282, %281 : !torch.vtensor<[8,32,8,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,8,65536],f32>
    %int8_340 = torch.constant.int 8
    %int256_341 = torch.constant.int 256
    %int256_342 = torch.constant.int 256
    %int256_343 = torch.constant.int 256
    %284 = torch.prim.ListConstruct %int8_340, %int256_341, %int256_342, %int256_343 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %285 = torch.aten.view %283, %284 : !torch.vtensor<[8,32,8,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,256,256,256],f32>
    %__auto.vae.encoder.down_blocks.2.resnets.0.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.norm1.bias : tensor<256xf16>
    %286 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_344 = torch.constant.int 0
    %287 = torch.aten.unsqueeze %286, %int0_344 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_345 = torch.constant.int 2
    %288 = torch.aten.unsqueeze %287, %int2_345 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_346 = torch.constant.int 3
    %289 = torch.aten.unsqueeze %288, %int3_346 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.norm1.weight : tensor<256xf16>
    %290 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_347 = torch.constant.int 0
    %291 = torch.aten.unsqueeze %290, %int0_347 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_348 = torch.constant.int 2
    %292 = torch.aten.unsqueeze %291, %int2_348 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_349 = torch.constant.int 3
    %293 = torch.aten.unsqueeze %292, %int3_349 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %294 = torch.aten.mul.Tensor %285, %293 : !torch.vtensor<[8,256,256,256],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[8,256,256,256],f32>
    %int1_350 = torch.constant.int 1
    %295 = torch.aten.add.Tensor %294, %289, %int1_350 : !torch.vtensor<[8,256,256,256],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[8,256,256,256],f32>
    %int5_351 = torch.constant.int 5
    %296 = torch.prims.convert_element_type %295, %int5_351 : !torch.vtensor<[8,256,256,256],f32>, !torch.int -> !torch.vtensor<[8,256,256,256],f16>
    %297 = torch.aten.silu %296 : !torch.vtensor<[8,256,256,256],f16> -> !torch.vtensor<[8,256,256,256],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv1.weight : tensor<512x256x3x3xf16>
    %298 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv1.weight : tensor<512x256x3x3xf16> -> !torch.vtensor<[512,256,3,3],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv1.bias : tensor<512xf16>
    %299 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_352 = torch.constant.int 1
    %int1_353 = torch.constant.int 1
    %300 = torch.prim.ListConstruct %int1_352, %int1_353 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_354 = torch.constant.int 1
    %int1_355 = torch.constant.int 1
    %301 = torch.prim.ListConstruct %int1_354, %int1_355 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_356 = torch.constant.int 1
    %int1_357 = torch.constant.int 1
    %302 = torch.prim.ListConstruct %int1_356, %int1_357 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_358 = torch.constant.bool false
    %int0_359 = torch.constant.int 0
    %int0_360 = torch.constant.int 0
    %303 = torch.prim.ListConstruct %int0_359, %int0_360 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_361 = torch.constant.int 1
    %304 = torch.aten.convolution %297, %298, %299, %300, %301, %302, %false_358, %303, %int1_361 : !torch.vtensor<[8,256,256,256],f16>, !torch.vtensor<[512,256,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_362 = torch.constant.int 8
    %int32_363 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int65536_364 = torch.constant.int 65536
    %305 = torch.prim.ListConstruct %int8_362, %int32_363, %int16, %int65536_364 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %306 = torch.aten.view %304, %305 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_365 = torch.constant.int 6
    %307 = torch.prims.convert_element_type %306, %int6_365 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_366 = torch.constant.int 2
    %int3_367 = torch.constant.int 3
    %308 = torch.prim.ListConstruct %int2_366, %int3_367 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_368 = torch.constant.int 0
    %true_369 = torch.constant.bool true
    %result0_370, %result1_371 = torch.aten.var_mean.correction %307, %308, %int0_368, %true_369 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_372 = torch.constant.float 9.9999999999999995E-7
    %int1_373 = torch.constant.int 1
    %309 = torch.aten.add.Scalar %result0_370, %float9.999990e-07_372, %int1_373 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %310 = torch.aten.rsqrt %309 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_374 = torch.constant.int 1
    %311 = torch.aten.sub.Tensor %306, %result1_371, %int1_374 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %312 = torch.aten.mul.Tensor %311, %310 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_375 = torch.constant.int 8
    %int512_376 = torch.constant.int 512
    %int256_377 = torch.constant.int 256
    %int256_378 = torch.constant.int 256
    %313 = torch.prim.ListConstruct %int8_375, %int512_376, %int256_377, %int256_378 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %314 = torch.aten.view %312, %313 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.encoder.down_blocks.2.resnets.0.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.norm2.bias : tensor<512xf16>
    %315 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_379 = torch.constant.int 0
    %316 = torch.aten.unsqueeze %315, %int0_379 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_380 = torch.constant.int 2
    %317 = torch.aten.unsqueeze %316, %int2_380 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_381 = torch.constant.int 3
    %318 = torch.aten.unsqueeze %317, %int3_381 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.norm2.weight : tensor<512xf16>
    %319 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_382 = torch.constant.int 0
    %320 = torch.aten.unsqueeze %319, %int0_382 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_383 = torch.constant.int 2
    %321 = torch.aten.unsqueeze %320, %int2_383 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_384 = torch.constant.int 3
    %322 = torch.aten.unsqueeze %321, %int3_384 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %323 = torch.aten.mul.Tensor %314, %322 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_385 = torch.constant.int 1
    %324 = torch.aten.add.Tensor %323, %318, %int1_385 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_386 = torch.constant.int 5
    %325 = torch.prims.convert_element_type %324, %int5_386 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %326 = torch.aten.silu %325 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %none_387 = torch.constant.none
    %327 = torch.aten.clone %326, %none_387 : !torch.vtensor<[8,512,256,256],f16>, !torch.none -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %328 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv2.bias : tensor<512xf16>
    %329 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_388 = torch.constant.int 1
    %int1_389 = torch.constant.int 1
    %330 = torch.prim.ListConstruct %int1_388, %int1_389 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_390 = torch.constant.int 1
    %int1_391 = torch.constant.int 1
    %331 = torch.prim.ListConstruct %int1_390, %int1_391 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_392 = torch.constant.int 1
    %int1_393 = torch.constant.int 1
    %332 = torch.prim.ListConstruct %int1_392, %int1_393 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_394 = torch.constant.bool false
    %int0_395 = torch.constant.int 0
    %int0_396 = torch.constant.int 0
    %333 = torch.prim.ListConstruct %int0_395, %int0_396 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_397 = torch.constant.int 1
    %334 = torch.aten.convolution %327, %328, %329, %330, %331, %332, %false_394, %333, %int1_397 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight : tensor<512x256x1x1xf16>
    %335 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight : tensor<512x256x1x1xf16> -> !torch.vtensor<[512,256,1,1],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias : tensor<512xf16>
    %336 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_398 = torch.constant.int 1
    %int1_399 = torch.constant.int 1
    %337 = torch.prim.ListConstruct %int1_398, %int1_399 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_400 = torch.constant.int 0
    %int0_401 = torch.constant.int 0
    %338 = torch.prim.ListConstruct %int0_400, %int0_401 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_402 = torch.constant.int 1
    %int1_403 = torch.constant.int 1
    %339 = torch.prim.ListConstruct %int1_402, %int1_403 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_404 = torch.constant.bool false
    %int0_405 = torch.constant.int 0
    %int0_406 = torch.constant.int 0
    %340 = torch.prim.ListConstruct %int0_405, %int0_406 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_407 = torch.constant.int 1
    %341 = torch.aten.convolution %275, %335, %336, %337, %338, %339, %false_404, %340, %int1_407 : !torch.vtensor<[8,256,256,256],f16>, !torch.vtensor<[512,256,1,1],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int1_408 = torch.constant.int 1
    %342 = torch.aten.add.Tensor %341, %334, %int1_408 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %float1.000000e00_409 = torch.constant.float 1.000000e+00
    %343 = torch.aten.div.Scalar %342, %float1.000000e00_409 : !torch.vtensor<[8,512,256,256],f16>, !torch.float -> !torch.vtensor<[8,512,256,256],f16>
    %int8_410 = torch.constant.int 8
    %int32_411 = torch.constant.int 32
    %int16_412 = torch.constant.int 16
    %int65536_413 = torch.constant.int 65536
    %344 = torch.prim.ListConstruct %int8_410, %int32_411, %int16_412, %int65536_413 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %345 = torch.aten.view %343, %344 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_414 = torch.constant.int 6
    %346 = torch.prims.convert_element_type %345, %int6_414 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_415 = torch.constant.int 2
    %int3_416 = torch.constant.int 3
    %347 = torch.prim.ListConstruct %int2_415, %int3_416 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_417 = torch.constant.int 0
    %true_418 = torch.constant.bool true
    %result0_419, %result1_420 = torch.aten.var_mean.correction %346, %347, %int0_417, %true_418 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_421 = torch.constant.float 9.9999999999999995E-7
    %int1_422 = torch.constant.int 1
    %348 = torch.aten.add.Scalar %result0_419, %float9.999990e-07_421, %int1_422 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %349 = torch.aten.rsqrt %348 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_423 = torch.constant.int 1
    %350 = torch.aten.sub.Tensor %345, %result1_420, %int1_423 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %351 = torch.aten.mul.Tensor %350, %349 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_424 = torch.constant.int 8
    %int512_425 = torch.constant.int 512
    %int256_426 = torch.constant.int 256
    %int256_427 = torch.constant.int 256
    %352 = torch.prim.ListConstruct %int8_424, %int512_425, %int256_426, %int256_427 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %353 = torch.aten.view %351, %352 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.encoder.down_blocks.2.resnets.1.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.norm1.bias : tensor<512xf16>
    %354 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_428 = torch.constant.int 0
    %355 = torch.aten.unsqueeze %354, %int0_428 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_429 = torch.constant.int 2
    %356 = torch.aten.unsqueeze %355, %int2_429 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_430 = torch.constant.int 3
    %357 = torch.aten.unsqueeze %356, %int3_430 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.norm1.weight : tensor<512xf16>
    %358 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_431 = torch.constant.int 0
    %359 = torch.aten.unsqueeze %358, %int0_431 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_432 = torch.constant.int 2
    %360 = torch.aten.unsqueeze %359, %int2_432 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_433 = torch.constant.int 3
    %361 = torch.aten.unsqueeze %360, %int3_433 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %362 = torch.aten.mul.Tensor %353, %361 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_434 = torch.constant.int 1
    %363 = torch.aten.add.Tensor %362, %357, %int1_434 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_435 = torch.constant.int 5
    %364 = torch.prims.convert_element_type %363, %int5_435 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %365 = torch.aten.silu %364 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %366 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.conv1.bias : tensor<512xf16>
    %367 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_436 = torch.constant.int 1
    %int1_437 = torch.constant.int 1
    %368 = torch.prim.ListConstruct %int1_436, %int1_437 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_438 = torch.constant.int 1
    %int1_439 = torch.constant.int 1
    %369 = torch.prim.ListConstruct %int1_438, %int1_439 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_440 = torch.constant.int 1
    %int1_441 = torch.constant.int 1
    %370 = torch.prim.ListConstruct %int1_440, %int1_441 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_442 = torch.constant.bool false
    %int0_443 = torch.constant.int 0
    %int0_444 = torch.constant.int 0
    %371 = torch.prim.ListConstruct %int0_443, %int0_444 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_445 = torch.constant.int 1
    %372 = torch.aten.convolution %365, %366, %367, %368, %369, %370, %false_442, %371, %int1_445 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int8_446 = torch.constant.int 8
    %int32_447 = torch.constant.int 32
    %int16_448 = torch.constant.int 16
    %int65536_449 = torch.constant.int 65536
    %373 = torch.prim.ListConstruct %int8_446, %int32_447, %int16_448, %int65536_449 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %374 = torch.aten.view %372, %373 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,65536],f16>
    %int6_450 = torch.constant.int 6
    %375 = torch.prims.convert_element_type %374, %int6_450 : !torch.vtensor<[8,32,16,65536],f16>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %int2_451 = torch.constant.int 2
    %int3_452 = torch.constant.int 3
    %376 = torch.prim.ListConstruct %int2_451, %int3_452 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_453 = torch.constant.int 0
    %true_454 = torch.constant.bool true
    %result0_455, %result1_456 = torch.aten.var_mean.correction %375, %376, %int0_453, %true_454 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_457 = torch.constant.float 9.9999999999999995E-7
    %int1_458 = torch.constant.int 1
    %377 = torch.aten.add.Scalar %result0_455, %float9.999990e-07_457, %int1_458 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %378 = torch.aten.rsqrt %377 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_459 = torch.constant.int 1
    %379 = torch.aten.sub.Tensor %374, %result1_456, %int1_459 : !torch.vtensor<[8,32,16,65536],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,65536],f32>
    %380 = torch.aten.mul.Tensor %379, %378 : !torch.vtensor<[8,32,16,65536],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,65536],f32>
    %int8_460 = torch.constant.int 8
    %int512_461 = torch.constant.int 512
    %int256_462 = torch.constant.int 256
    %int256_463 = torch.constant.int 256
    %381 = torch.prim.ListConstruct %int8_460, %int512_461, %int256_462, %int256_463 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %382 = torch.aten.view %380, %381 : !torch.vtensor<[8,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[8,512,256,256],f32>
    %__auto.vae.encoder.down_blocks.2.resnets.1.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.norm2.bias : tensor<512xf16>
    %383 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_464 = torch.constant.int 0
    %384 = torch.aten.unsqueeze %383, %int0_464 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_465 = torch.constant.int 2
    %385 = torch.aten.unsqueeze %384, %int2_465 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_466 = torch.constant.int 3
    %386 = torch.aten.unsqueeze %385, %int3_466 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.norm2.weight : tensor<512xf16>
    %387 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_467 = torch.constant.int 0
    %388 = torch.aten.unsqueeze %387, %int0_467 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_468 = torch.constant.int 2
    %389 = torch.aten.unsqueeze %388, %int2_468 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_469 = torch.constant.int 3
    %390 = torch.aten.unsqueeze %389, %int3_469 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %391 = torch.aten.mul.Tensor %382, %390 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,256,256],f32>
    %int1_470 = torch.constant.int 1
    %392 = torch.aten.add.Tensor %391, %386, %int1_470 : !torch.vtensor<[8,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f32>
    %int5_471 = torch.constant.int 5
    %393 = torch.prims.convert_element_type %392, %int5_471 : !torch.vtensor<[8,512,256,256],f32>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %394 = torch.aten.silu %393 : !torch.vtensor<[8,512,256,256],f16> -> !torch.vtensor<[8,512,256,256],f16>
    %none_472 = torch.constant.none
    %395 = torch.aten.clone %394, %none_472 : !torch.vtensor<[8,512,256,256],f16>, !torch.none -> !torch.vtensor<[8,512,256,256],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %396 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.2.resnets.1.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.2.resnets.1.conv2.bias : tensor<512xf16>
    %397 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_473 = torch.constant.int 1
    %int1_474 = torch.constant.int 1
    %398 = torch.prim.ListConstruct %int1_473, %int1_474 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_475 = torch.constant.int 1
    %int1_476 = torch.constant.int 1
    %399 = torch.prim.ListConstruct %int1_475, %int1_476 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_477 = torch.constant.int 1
    %int1_478 = torch.constant.int 1
    %400 = torch.prim.ListConstruct %int1_477, %int1_478 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_479 = torch.constant.bool false
    %int0_480 = torch.constant.int 0
    %int0_481 = torch.constant.int 0
    %401 = torch.prim.ListConstruct %int0_480, %int0_481 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_482 = torch.constant.int 1
    %402 = torch.aten.convolution %395, %396, %397, %398, %399, %400, %false_479, %401, %int1_482 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %int1_483 = torch.constant.int 1
    %403 = torch.aten.add.Tensor %343, %402, %int1_483 : !torch.vtensor<[8,512,256,256],f16>, !torch.vtensor<[8,512,256,256],f16>, !torch.int -> !torch.vtensor<[8,512,256,256],f16>
    %float1.000000e00_484 = torch.constant.float 1.000000e+00
    %404 = torch.aten.div.Scalar %403, %float1.000000e00_484 : !torch.vtensor<[8,512,256,256],f16>, !torch.float -> !torch.vtensor<[8,512,256,256],f16>
    %int0_485 = torch.constant.int 0
    %int1_486 = torch.constant.int 1
    %int0_487 = torch.constant.int 0
    %int1_488 = torch.constant.int 1
    %405 = torch.prim.ListConstruct %int0_485, %int1_486, %int0_487, %int1_488 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %float0.000000e00_489 = torch.constant.float 0.000000e+00
    %406 = torch.aten.constant_pad_nd %404, %405, %float0.000000e00_489 : !torch.vtensor<[8,512,256,256],f16>, !torch.list<int>, !torch.float -> !torch.vtensor<[8,512,257,257],f16>
    %__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.weight = util.global.load @__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %407 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.bias = util.global.load @__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.bias : tensor<512xf16>
    %408 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.2.downsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int2_490 = torch.constant.int 2
    %int2_491 = torch.constant.int 2
    %409 = torch.prim.ListConstruct %int2_490, %int2_491 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_492 = torch.constant.int 0
    %int0_493 = torch.constant.int 0
    %410 = torch.prim.ListConstruct %int0_492, %int0_493 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_494 = torch.constant.int 1
    %int1_495 = torch.constant.int 1
    %411 = torch.prim.ListConstruct %int1_494, %int1_495 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_496 = torch.constant.bool false
    %int0_497 = torch.constant.int 0
    %int0_498 = torch.constant.int 0
    %412 = torch.prim.ListConstruct %int0_497, %int0_498 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_499 = torch.constant.int 1
    %413 = torch.aten.convolution %406, %407, %408, %409, %410, %411, %false_496, %412, %int1_499 : !torch.vtensor<[8,512,257,257],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_500 = torch.constant.int 8
    %int32_501 = torch.constant.int 32
    %int16_502 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %414 = torch.prim.ListConstruct %int8_500, %int32_501, %int16_502, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %415 = torch.aten.view %413, %414 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_503 = torch.constant.int 6
    %416 = torch.prims.convert_element_type %415, %int6_503 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_504 = torch.constant.int 2
    %int3_505 = torch.constant.int 3
    %417 = torch.prim.ListConstruct %int2_504, %int3_505 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_506 = torch.constant.int 0
    %true_507 = torch.constant.bool true
    %result0_508, %result1_509 = torch.aten.var_mean.correction %416, %417, %int0_506, %true_507 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_510 = torch.constant.float 9.9999999999999995E-7
    %int1_511 = torch.constant.int 1
    %418 = torch.aten.add.Scalar %result0_508, %float9.999990e-07_510, %int1_511 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %419 = torch.aten.rsqrt %418 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_512 = torch.constant.int 1
    %420 = torch.aten.sub.Tensor %415, %result1_509, %int1_512 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %421 = torch.aten.mul.Tensor %420, %419 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_513 = torch.constant.int 8
    %int512_514 = torch.constant.int 512
    %int128_515 = torch.constant.int 128
    %int128_516 = torch.constant.int 128
    %422 = torch.prim.ListConstruct %int8_513, %int512_514, %int128_515, %int128_516 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %423 = torch.aten.view %421, %422 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.down_blocks.3.resnets.0.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.norm1.bias : tensor<512xf16>
    %424 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_517 = torch.constant.int 0
    %425 = torch.aten.unsqueeze %424, %int0_517 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_518 = torch.constant.int 2
    %426 = torch.aten.unsqueeze %425, %int2_518 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_519 = torch.constant.int 3
    %427 = torch.aten.unsqueeze %426, %int3_519 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.norm1.weight : tensor<512xf16>
    %428 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_520 = torch.constant.int 0
    %429 = torch.aten.unsqueeze %428, %int0_520 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_521 = torch.constant.int 2
    %430 = torch.aten.unsqueeze %429, %int2_521 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_522 = torch.constant.int 3
    %431 = torch.aten.unsqueeze %430, %int3_522 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %432 = torch.aten.mul.Tensor %423, %431 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_523 = torch.constant.int 1
    %433 = torch.aten.add.Tensor %432, %427, %int1_523 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_524 = torch.constant.int 5
    %434 = torch.prims.convert_element_type %433, %int5_524 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %435 = torch.aten.silu %434 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %436 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.conv1.bias : tensor<512xf16>
    %437 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_525 = torch.constant.int 1
    %int1_526 = torch.constant.int 1
    %438 = torch.prim.ListConstruct %int1_525, %int1_526 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_527 = torch.constant.int 1
    %int1_528 = torch.constant.int 1
    %439 = torch.prim.ListConstruct %int1_527, %int1_528 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_529 = torch.constant.int 1
    %int1_530 = torch.constant.int 1
    %440 = torch.prim.ListConstruct %int1_529, %int1_530 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_531 = torch.constant.bool false
    %int0_532 = torch.constant.int 0
    %int0_533 = torch.constant.int 0
    %441 = torch.prim.ListConstruct %int0_532, %int0_533 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_534 = torch.constant.int 1
    %442 = torch.aten.convolution %435, %436, %437, %438, %439, %440, %false_531, %441, %int1_534 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_535 = torch.constant.int 8
    %int32_536 = torch.constant.int 32
    %int16_537 = torch.constant.int 16
    %int16384_538 = torch.constant.int 16384
    %443 = torch.prim.ListConstruct %int8_535, %int32_536, %int16_537, %int16384_538 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %444 = torch.aten.view %442, %443 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_539 = torch.constant.int 6
    %445 = torch.prims.convert_element_type %444, %int6_539 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_540 = torch.constant.int 2
    %int3_541 = torch.constant.int 3
    %446 = torch.prim.ListConstruct %int2_540, %int3_541 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_542 = torch.constant.int 0
    %true_543 = torch.constant.bool true
    %result0_544, %result1_545 = torch.aten.var_mean.correction %445, %446, %int0_542, %true_543 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_546 = torch.constant.float 9.9999999999999995E-7
    %int1_547 = torch.constant.int 1
    %447 = torch.aten.add.Scalar %result0_544, %float9.999990e-07_546, %int1_547 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %448 = torch.aten.rsqrt %447 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_548 = torch.constant.int 1
    %449 = torch.aten.sub.Tensor %444, %result1_545, %int1_548 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %450 = torch.aten.mul.Tensor %449, %448 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_549 = torch.constant.int 8
    %int512_550 = torch.constant.int 512
    %int128_551 = torch.constant.int 128
    %int128_552 = torch.constant.int 128
    %451 = torch.prim.ListConstruct %int8_549, %int512_550, %int128_551, %int128_552 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %452 = torch.aten.view %450, %451 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.down_blocks.3.resnets.0.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.norm2.bias : tensor<512xf16>
    %453 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_553 = torch.constant.int 0
    %454 = torch.aten.unsqueeze %453, %int0_553 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_554 = torch.constant.int 2
    %455 = torch.aten.unsqueeze %454, %int2_554 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_555 = torch.constant.int 3
    %456 = torch.aten.unsqueeze %455, %int3_555 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.norm2.weight : tensor<512xf16>
    %457 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_556 = torch.constant.int 0
    %458 = torch.aten.unsqueeze %457, %int0_556 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_557 = torch.constant.int 2
    %459 = torch.aten.unsqueeze %458, %int2_557 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_558 = torch.constant.int 3
    %460 = torch.aten.unsqueeze %459, %int3_558 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %461 = torch.aten.mul.Tensor %452, %460 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_559 = torch.constant.int 1
    %462 = torch.aten.add.Tensor %461, %456, %int1_559 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_560 = torch.constant.int 5
    %463 = torch.prims.convert_element_type %462, %int5_560 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %464 = torch.aten.silu %463 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_561 = torch.constant.none
    %465 = torch.aten.clone %464, %none_561 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %466 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.0.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.0.conv2.bias : tensor<512xf16>
    %467 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_562 = torch.constant.int 1
    %int1_563 = torch.constant.int 1
    %468 = torch.prim.ListConstruct %int1_562, %int1_563 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_564 = torch.constant.int 1
    %int1_565 = torch.constant.int 1
    %469 = torch.prim.ListConstruct %int1_564, %int1_565 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_566 = torch.constant.int 1
    %int1_567 = torch.constant.int 1
    %470 = torch.prim.ListConstruct %int1_566, %int1_567 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_568 = torch.constant.bool false
    %int0_569 = torch.constant.int 0
    %int0_570 = torch.constant.int 0
    %471 = torch.prim.ListConstruct %int0_569, %int0_570 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_571 = torch.constant.int 1
    %472 = torch.aten.convolution %465, %466, %467, %468, %469, %470, %false_568, %471, %int1_571 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_572 = torch.constant.int 1
    %473 = torch.aten.add.Tensor %413, %472, %int1_572 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %float1.000000e00_573 = torch.constant.float 1.000000e+00
    %474 = torch.aten.div.Scalar %473, %float1.000000e00_573 : !torch.vtensor<[8,512,128,128],f16>, !torch.float -> !torch.vtensor<[8,512,128,128],f16>
    %int8_574 = torch.constant.int 8
    %int32_575 = torch.constant.int 32
    %int16_576 = torch.constant.int 16
    %int16384_577 = torch.constant.int 16384
    %475 = torch.prim.ListConstruct %int8_574, %int32_575, %int16_576, %int16384_577 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %476 = torch.aten.view %474, %475 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_578 = torch.constant.int 6
    %477 = torch.prims.convert_element_type %476, %int6_578 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_579 = torch.constant.int 2
    %int3_580 = torch.constant.int 3
    %478 = torch.prim.ListConstruct %int2_579, %int3_580 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_581 = torch.constant.int 0
    %true_582 = torch.constant.bool true
    %result0_583, %result1_584 = torch.aten.var_mean.correction %477, %478, %int0_581, %true_582 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_585 = torch.constant.float 9.9999999999999995E-7
    %int1_586 = torch.constant.int 1
    %479 = torch.aten.add.Scalar %result0_583, %float9.999990e-07_585, %int1_586 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %480 = torch.aten.rsqrt %479 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_587 = torch.constant.int 1
    %481 = torch.aten.sub.Tensor %476, %result1_584, %int1_587 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %482 = torch.aten.mul.Tensor %481, %480 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_588 = torch.constant.int 8
    %int512_589 = torch.constant.int 512
    %int128_590 = torch.constant.int 128
    %int128_591 = torch.constant.int 128
    %483 = torch.prim.ListConstruct %int8_588, %int512_589, %int128_590, %int128_591 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %484 = torch.aten.view %482, %483 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.down_blocks.3.resnets.1.norm1.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.norm1.bias : tensor<512xf16>
    %485 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_592 = torch.constant.int 0
    %486 = torch.aten.unsqueeze %485, %int0_592 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_593 = torch.constant.int 2
    %487 = torch.aten.unsqueeze %486, %int2_593 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_594 = torch.constant.int 3
    %488 = torch.aten.unsqueeze %487, %int3_594 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.norm1.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.norm1.weight : tensor<512xf16>
    %489 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_595 = torch.constant.int 0
    %490 = torch.aten.unsqueeze %489, %int0_595 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_596 = torch.constant.int 2
    %491 = torch.aten.unsqueeze %490, %int2_596 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_597 = torch.constant.int 3
    %492 = torch.aten.unsqueeze %491, %int3_597 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %493 = torch.aten.mul.Tensor %484, %492 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_598 = torch.constant.int 1
    %494 = torch.aten.add.Tensor %493, %488, %int1_598 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_599 = torch.constant.int 5
    %495 = torch.prims.convert_element_type %494, %int5_599 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %496 = torch.aten.silu %495 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.conv1.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %497 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.conv1.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.conv1.bias : tensor<512xf16>
    %498 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_600 = torch.constant.int 1
    %int1_601 = torch.constant.int 1
    %499 = torch.prim.ListConstruct %int1_600, %int1_601 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_602 = torch.constant.int 1
    %int1_603 = torch.constant.int 1
    %500 = torch.prim.ListConstruct %int1_602, %int1_603 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_604 = torch.constant.int 1
    %int1_605 = torch.constant.int 1
    %501 = torch.prim.ListConstruct %int1_604, %int1_605 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_606 = torch.constant.bool false
    %int0_607 = torch.constant.int 0
    %int0_608 = torch.constant.int 0
    %502 = torch.prim.ListConstruct %int0_607, %int0_608 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_609 = torch.constant.int 1
    %503 = torch.aten.convolution %496, %497, %498, %499, %500, %501, %false_606, %502, %int1_609 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_610 = torch.constant.int 8
    %int32_611 = torch.constant.int 32
    %int16_612 = torch.constant.int 16
    %int16384_613 = torch.constant.int 16384
    %504 = torch.prim.ListConstruct %int8_610, %int32_611, %int16_612, %int16384_613 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %505 = torch.aten.view %503, %504 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_614 = torch.constant.int 6
    %506 = torch.prims.convert_element_type %505, %int6_614 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_615 = torch.constant.int 2
    %int3_616 = torch.constant.int 3
    %507 = torch.prim.ListConstruct %int2_615, %int3_616 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_617 = torch.constant.int 0
    %true_618 = torch.constant.bool true
    %result0_619, %result1_620 = torch.aten.var_mean.correction %506, %507, %int0_617, %true_618 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_621 = torch.constant.float 9.9999999999999995E-7
    %int1_622 = torch.constant.int 1
    %508 = torch.aten.add.Scalar %result0_619, %float9.999990e-07_621, %int1_622 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %509 = torch.aten.rsqrt %508 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_623 = torch.constant.int 1
    %510 = torch.aten.sub.Tensor %505, %result1_620, %int1_623 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %511 = torch.aten.mul.Tensor %510, %509 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_624 = torch.constant.int 8
    %int512_625 = torch.constant.int 512
    %int128_626 = torch.constant.int 128
    %int128_627 = torch.constant.int 128
    %512 = torch.prim.ListConstruct %int8_624, %int512_625, %int128_626, %int128_627 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %513 = torch.aten.view %511, %512 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.down_blocks.3.resnets.1.norm2.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.norm2.bias : tensor<512xf16>
    %514 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_628 = torch.constant.int 0
    %515 = torch.aten.unsqueeze %514, %int0_628 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_629 = torch.constant.int 2
    %516 = torch.aten.unsqueeze %515, %int2_629 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_630 = torch.constant.int 3
    %517 = torch.aten.unsqueeze %516, %int3_630 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.norm2.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.norm2.weight : tensor<512xf16>
    %518 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_631 = torch.constant.int 0
    %519 = torch.aten.unsqueeze %518, %int0_631 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_632 = torch.constant.int 2
    %520 = torch.aten.unsqueeze %519, %int2_632 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_633 = torch.constant.int 3
    %521 = torch.aten.unsqueeze %520, %int3_633 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %522 = torch.aten.mul.Tensor %513, %521 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_634 = torch.constant.int 1
    %523 = torch.aten.add.Tensor %522, %517, %int1_634 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_635 = torch.constant.int 5
    %524 = torch.prims.convert_element_type %523, %int5_635 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %525 = torch.aten.silu %524 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_636 = torch.constant.none
    %526 = torch.aten.clone %525, %none_636 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.conv2.weight = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %527 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.down_blocks.3.resnets.1.conv2.bias = util.global.load @__auto.vae.encoder.down_blocks.3.resnets.1.conv2.bias : tensor<512xf16>
    %528 = torch_c.from_builtin_tensor %__auto.vae.encoder.down_blocks.3.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_637 = torch.constant.int 1
    %int1_638 = torch.constant.int 1
    %529 = torch.prim.ListConstruct %int1_637, %int1_638 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_639 = torch.constant.int 1
    %int1_640 = torch.constant.int 1
    %530 = torch.prim.ListConstruct %int1_639, %int1_640 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_641 = torch.constant.int 1
    %int1_642 = torch.constant.int 1
    %531 = torch.prim.ListConstruct %int1_641, %int1_642 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_643 = torch.constant.bool false
    %int0_644 = torch.constant.int 0
    %int0_645 = torch.constant.int 0
    %532 = torch.prim.ListConstruct %int0_644, %int0_645 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_646 = torch.constant.int 1
    %533 = torch.aten.convolution %526, %527, %528, %529, %530, %531, %false_643, %532, %int1_646 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_647 = torch.constant.int 1
    %534 = torch.aten.add.Tensor %474, %533, %int1_647 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %float1.000000e00_648 = torch.constant.float 1.000000e+00
    %535 = torch.aten.div.Scalar %534, %float1.000000e00_648 : !torch.vtensor<[8,512,128,128],f16>, !torch.float -> !torch.vtensor<[8,512,128,128],f16>
    %int8_649 = torch.constant.int 8
    %int32_650 = torch.constant.int 32
    %int16_651 = torch.constant.int 16
    %int16384_652 = torch.constant.int 16384
    %536 = torch.prim.ListConstruct %int8_649, %int32_650, %int16_651, %int16384_652 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %537 = torch.aten.view %535, %536 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_653 = torch.constant.int 6
    %538 = torch.prims.convert_element_type %537, %int6_653 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_654 = torch.constant.int 2
    %int3_655 = torch.constant.int 3
    %539 = torch.prim.ListConstruct %int2_654, %int3_655 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_656 = torch.constant.int 0
    %true_657 = torch.constant.bool true
    %result0_658, %result1_659 = torch.aten.var_mean.correction %538, %539, %int0_656, %true_657 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_660 = torch.constant.float 9.9999999999999995E-7
    %int1_661 = torch.constant.int 1
    %540 = torch.aten.add.Scalar %result0_658, %float9.999990e-07_660, %int1_661 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %541 = torch.aten.rsqrt %540 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_662 = torch.constant.int 1
    %542 = torch.aten.sub.Tensor %537, %result1_659, %int1_662 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %543 = torch.aten.mul.Tensor %542, %541 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_663 = torch.constant.int 8
    %int512_664 = torch.constant.int 512
    %int128_665 = torch.constant.int 128
    %int128_666 = torch.constant.int 128
    %544 = torch.prim.ListConstruct %int8_663, %int512_664, %int128_665, %int128_666 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %545 = torch.aten.view %543, %544 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.mid_block.resnets.0.norm1.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %546 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_667 = torch.constant.int 0
    %547 = torch.aten.unsqueeze %546, %int0_667 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_668 = torch.constant.int 2
    %548 = torch.aten.unsqueeze %547, %int2_668 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_669 = torch.constant.int 3
    %549 = torch.aten.unsqueeze %548, %int3_669 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.mid_block.resnets.0.norm1.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %550 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_670 = torch.constant.int 0
    %551 = torch.aten.unsqueeze %550, %int0_670 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_671 = torch.constant.int 2
    %552 = torch.aten.unsqueeze %551, %int2_671 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_672 = torch.constant.int 3
    %553 = torch.aten.unsqueeze %552, %int3_672 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %554 = torch.aten.mul.Tensor %545, %553 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_673 = torch.constant.int 1
    %555 = torch.aten.add.Tensor %554, %549, %int1_673 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_674 = torch.constant.int 5
    %556 = torch.prims.convert_element_type %555, %int5_674 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %557 = torch.aten.silu %556 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.mid_block.resnets.0.conv1.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %558 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.mid_block.resnets.0.conv1.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %559 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_675 = torch.constant.int 1
    %int1_676 = torch.constant.int 1
    %560 = torch.prim.ListConstruct %int1_675, %int1_676 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_677 = torch.constant.int 1
    %int1_678 = torch.constant.int 1
    %561 = torch.prim.ListConstruct %int1_677, %int1_678 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_679 = torch.constant.int 1
    %int1_680 = torch.constant.int 1
    %562 = torch.prim.ListConstruct %int1_679, %int1_680 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_681 = torch.constant.bool false
    %int0_682 = torch.constant.int 0
    %int0_683 = torch.constant.int 0
    %563 = torch.prim.ListConstruct %int0_682, %int0_683 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_684 = torch.constant.int 1
    %564 = torch.aten.convolution %557, %558, %559, %560, %561, %562, %false_681, %563, %int1_684 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_685 = torch.constant.int 8
    %int32_686 = torch.constant.int 32
    %int16_687 = torch.constant.int 16
    %int16384_688 = torch.constant.int 16384
    %565 = torch.prim.ListConstruct %int8_685, %int32_686, %int16_687, %int16384_688 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %566 = torch.aten.view %564, %565 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_689 = torch.constant.int 6
    %567 = torch.prims.convert_element_type %566, %int6_689 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_690 = torch.constant.int 2
    %int3_691 = torch.constant.int 3
    %568 = torch.prim.ListConstruct %int2_690, %int3_691 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_692 = torch.constant.int 0
    %true_693 = torch.constant.bool true
    %result0_694, %result1_695 = torch.aten.var_mean.correction %567, %568, %int0_692, %true_693 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_696 = torch.constant.float 9.9999999999999995E-7
    %int1_697 = torch.constant.int 1
    %569 = torch.aten.add.Scalar %result0_694, %float9.999990e-07_696, %int1_697 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %570 = torch.aten.rsqrt %569 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_698 = torch.constant.int 1
    %571 = torch.aten.sub.Tensor %566, %result1_695, %int1_698 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %572 = torch.aten.mul.Tensor %571, %570 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_699 = torch.constant.int 8
    %int512_700 = torch.constant.int 512
    %int128_701 = torch.constant.int 128
    %int128_702 = torch.constant.int 128
    %573 = torch.prim.ListConstruct %int8_699, %int512_700, %int128_701, %int128_702 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %574 = torch.aten.view %572, %573 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.mid_block.resnets.0.norm2.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %575 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_703 = torch.constant.int 0
    %576 = torch.aten.unsqueeze %575, %int0_703 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_704 = torch.constant.int 2
    %577 = torch.aten.unsqueeze %576, %int2_704 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_705 = torch.constant.int 3
    %578 = torch.aten.unsqueeze %577, %int3_705 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.mid_block.resnets.0.norm2.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %579 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_706 = torch.constant.int 0
    %580 = torch.aten.unsqueeze %579, %int0_706 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_707 = torch.constant.int 2
    %581 = torch.aten.unsqueeze %580, %int2_707 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_708 = torch.constant.int 3
    %582 = torch.aten.unsqueeze %581, %int3_708 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %583 = torch.aten.mul.Tensor %574, %582 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_709 = torch.constant.int 1
    %584 = torch.aten.add.Tensor %583, %578, %int1_709 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_710 = torch.constant.int 5
    %585 = torch.prims.convert_element_type %584, %int5_710 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %586 = torch.aten.silu %585 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_711 = torch.constant.none
    %587 = torch.aten.clone %586, %none_711 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.mid_block.resnets.0.conv2.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %588 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.mid_block.resnets.0.conv2.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %589 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_712 = torch.constant.int 1
    %int1_713 = torch.constant.int 1
    %590 = torch.prim.ListConstruct %int1_712, %int1_713 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_714 = torch.constant.int 1
    %int1_715 = torch.constant.int 1
    %591 = torch.prim.ListConstruct %int1_714, %int1_715 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_716 = torch.constant.int 1
    %int1_717 = torch.constant.int 1
    %592 = torch.prim.ListConstruct %int1_716, %int1_717 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_718 = torch.constant.bool false
    %int0_719 = torch.constant.int 0
    %int0_720 = torch.constant.int 0
    %593 = torch.prim.ListConstruct %int0_719, %int0_720 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_721 = torch.constant.int 1
    %594 = torch.aten.convolution %587, %588, %589, %590, %591, %592, %false_718, %593, %int1_721 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_722 = torch.constant.int 1
    %595 = torch.aten.add.Tensor %535, %594, %int1_722 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_723 = torch.constant.int 1
    %596 = torch.aten.div.Scalar %595, %int1_723 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_724 = torch.constant.int 8
    %int512_725 = torch.constant.int 512
    %int16384_726 = torch.constant.int 16384
    %597 = torch.prim.ListConstruct %int8_724, %int512_725, %int16384_726 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %598 = torch.aten.view %596, %597 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f16>
    %int1_727 = torch.constant.int 1
    %int2_728 = torch.constant.int 2
    %599 = torch.aten.transpose.int %598, %int1_727, %int2_728 : !torch.vtensor<[8,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int1_729 = torch.constant.int 1
    %int2_730 = torch.constant.int 2
    %600 = torch.aten.transpose.int %599, %int1_729, %int2_730 : !torch.vtensor<[8,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int8_731 = torch.constant.int 8
    %int32_732 = torch.constant.int 32
    %int16_733 = torch.constant.int 16
    %int16384_734 = torch.constant.int 16384
    %601 = torch.prim.ListConstruct %int8_731, %int32_732, %int16_733, %int16384_734 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %602 = torch.aten.view %600, %601 : !torch.vtensor<[8,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_735 = torch.constant.int 6
    %603 = torch.prims.convert_element_type %602, %int6_735 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_736 = torch.constant.int 2
    %int3_737 = torch.constant.int 3
    %604 = torch.prim.ListConstruct %int2_736, %int3_737 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_738 = torch.constant.int 0
    %true_739 = torch.constant.bool true
    %result0_740, %result1_741 = torch.aten.var_mean.correction %603, %604, %int0_738, %true_739 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_742 = torch.constant.float 9.9999999999999995E-7
    %int1_743 = torch.constant.int 1
    %605 = torch.aten.add.Scalar %result0_740, %float9.999990e-07_742, %int1_743 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %606 = torch.aten.rsqrt %605 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_744 = torch.constant.int 1
    %607 = torch.aten.sub.Tensor %602, %result1_741, %int1_744 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %608 = torch.aten.mul.Tensor %607, %606 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_745 = torch.constant.int 8
    %int512_746 = torch.constant.int 512
    %int16384_747 = torch.constant.int 16384
    %609 = torch.prim.ListConstruct %int8_745, %int512_746, %int16384_747 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %610 = torch.aten.view %608, %609 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f32>
    %__auto.vae.encoder.mid_block.attentions.0.group_norm.bias = util.global.load @__auto.vae.encoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %611 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_748 = torch.constant.int 0
    %612 = torch.aten.unsqueeze %611, %int0_748 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_749 = torch.constant.int 2
    %613 = torch.aten.unsqueeze %612, %int2_749 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %__auto.vae.encoder.mid_block.attentions.0.group_norm.weight = util.global.load @__auto.vae.encoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %614 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_750 = torch.constant.int 0
    %615 = torch.aten.unsqueeze %614, %int0_750 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_751 = torch.constant.int 2
    %616 = torch.aten.unsqueeze %615, %int2_751 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %617 = torch.aten.mul.Tensor %610, %616 : !torch.vtensor<[8,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[8,512,16384],f32>
    %int1_752 = torch.constant.int 1
    %618 = torch.aten.add.Tensor %617, %613, %int1_752 : !torch.vtensor<[8,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[8,512,16384],f32>
    %int5_753 = torch.constant.int 5
    %619 = torch.prims.convert_element_type %618, %int5_753 : !torch.vtensor<[8,512,16384],f32>, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int1_754 = torch.constant.int 1
    %int2_755 = torch.constant.int 2
    %620 = torch.aten.transpose.int %619, %int1_754, %int2_755 : !torch.vtensor<[8,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_q.weight = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %621 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_756 = torch.constant.int 0
    %int1_757 = torch.constant.int 1
    %622 = torch.aten.transpose.int %621, %int0_756, %int1_757 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_758 = torch.constant.int 0
    %623 = torch.aten.clone %620, %int0_758 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072 = torch.constant.int 131072
    %int512_759 = torch.constant.int 512
    %624 = torch.prim.ListConstruct %int131072, %int512_759 : (!torch.int, !torch.int) -> !torch.list<int>
    %625 = torch.aten._unsafe_view %623, %624 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %626 = torch.aten.mm %625, %622 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_760 = torch.constant.int 8
    %int16384_761 = torch.constant.int 16384
    %int512_762 = torch.constant.int 512
    %627 = torch.prim.ListConstruct %int8_760, %int16384_761, %int512_762 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %628 = torch.aten.view %626, %627 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_q.bias = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %629 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_763 = torch.constant.int 1
    %630 = torch.aten.add.Tensor %628, %629, %int1_763 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_k.weight = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %631 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_764 = torch.constant.int 0
    %int1_765 = torch.constant.int 1
    %632 = torch.aten.transpose.int %631, %int0_764, %int1_765 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_766 = torch.constant.int 0
    %633 = torch.aten.clone %620, %int0_766 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_767 = torch.constant.int 131072
    %int512_768 = torch.constant.int 512
    %634 = torch.prim.ListConstruct %int131072_767, %int512_768 : (!torch.int, !torch.int) -> !torch.list<int>
    %635 = torch.aten._unsafe_view %633, %634 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %636 = torch.aten.mm %635, %632 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_769 = torch.constant.int 8
    %int16384_770 = torch.constant.int 16384
    %int512_771 = torch.constant.int 512
    %637 = torch.prim.ListConstruct %int8_769, %int16384_770, %int512_771 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %638 = torch.aten.view %636, %637 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_k.bias = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %639 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_772 = torch.constant.int 1
    %640 = torch.aten.add.Tensor %638, %639, %int1_772 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_v.weight = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %641 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_773 = torch.constant.int 0
    %int1_774 = torch.constant.int 1
    %642 = torch.aten.transpose.int %641, %int0_773, %int1_774 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_775 = torch.constant.int 0
    %643 = torch.aten.clone %620, %int0_775 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_776 = torch.constant.int 131072
    %int512_777 = torch.constant.int 512
    %644 = torch.prim.ListConstruct %int131072_776, %int512_777 : (!torch.int, !torch.int) -> !torch.list<int>
    %645 = torch.aten._unsafe_view %643, %644 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %646 = torch.aten.mm %645, %642 : !torch.vtensor<[131072,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[131072,512],f16>
    %int8_778 = torch.constant.int 8
    %int16384_779 = torch.constant.int 16384
    %int512_780 = torch.constant.int 512
    %647 = torch.prim.ListConstruct %int8_778, %int16384_779, %int512_780 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %648 = torch.aten.view %646, %647 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_v.bias = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %649 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_781 = torch.constant.int 1
    %650 = torch.aten.add.Tensor %648, %649, %int1_781 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int8_782 = torch.constant.int 8
    %int-1 = torch.constant.int -1
    %int1_783 = torch.constant.int 1
    %int512_784 = torch.constant.int 512
    %651 = torch.prim.ListConstruct %int8_782, %int-1, %int1_783, %int512_784 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %652 = torch.aten.view %630, %651 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_785 = torch.constant.int 1
    %int2_786 = torch.constant.int 2
    %653 = torch.aten.transpose.int %652, %int1_785, %int2_786 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_787 = torch.constant.int 8
    %int-1_788 = torch.constant.int -1
    %int1_789 = torch.constant.int 1
    %int512_790 = torch.constant.int 512
    %654 = torch.prim.ListConstruct %int8_787, %int-1_788, %int1_789, %int512_790 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %655 = torch.aten.view %640, %654 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_791 = torch.constant.int 1
    %int2_792 = torch.constant.int 2
    %656 = torch.aten.transpose.int %655, %int1_791, %int2_792 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_793 = torch.constant.int 8
    %int-1_794 = torch.constant.int -1
    %int1_795 = torch.constant.int 1
    %int512_796 = torch.constant.int 512
    %657 = torch.prim.ListConstruct %int8_793, %int-1_794, %int1_795, %int512_796 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %658 = torch.aten.view %650, %657 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_797 = torch.constant.int 1
    %int2_798 = torch.constant.int 2
    %659 = torch.aten.transpose.int %658, %int1_797, %int2_798 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %660 = torch.aten.mul.Scalar %653, %float2.102240e-01 : !torch.vtensor<[8,1,16384,512],f16>, !torch.float -> !torch.vtensor<[8,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_799 = torch.constant.int -1
    %661 = torch.aten.transpose.int %656, %int-2, %int-1_799 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,512,16384],f16>
    %float2.102240e-01_800 = torch.constant.float 0.21022410381342863
    %662 = torch.aten.mul.Scalar %661, %float2.102240e-01_800 : !torch.vtensor<[8,1,512,16384],f16>, !torch.float -> !torch.vtensor<[8,1,512,16384],f16>
    %int8_801 = torch.constant.int 8
    %int1_802 = torch.constant.int 1
    %int16384_803 = torch.constant.int 16384
    %int512_804 = torch.constant.int 512
    %663 = torch.prim.ListConstruct %int8_801, %int1_802, %int16384_803, %int512_804 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_805 = torch.constant.bool false
    %664 = torch.aten.expand %660, %663, %false_805 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_806 = torch.constant.int 8
    %int16384_807 = torch.constant.int 16384
    %int512_808 = torch.constant.int 512
    %665 = torch.prim.ListConstruct %int8_806, %int16384_807, %int512_808 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %666 = torch.aten.view %664, %665 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %int8_809 = torch.constant.int 8
    %int1_810 = torch.constant.int 1
    %int512_811 = torch.constant.int 512
    %int16384_812 = torch.constant.int 16384
    %667 = torch.prim.ListConstruct %int8_809, %int1_810, %int512_811, %int16384_812 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_813 = torch.constant.bool false
    %668 = torch.aten.expand %662, %667, %false_813 : !torch.vtensor<[8,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,512,16384],f16>
    %int8_814 = torch.constant.int 8
    %int512_815 = torch.constant.int 512
    %int16384_816 = torch.constant.int 16384
    %669 = torch.prim.ListConstruct %int8_814, %int512_815, %int16384_816 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %670 = torch.aten.view %668, %669 : !torch.vtensor<[8,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,512,16384],f16>
    %671 = torch.aten.bmm %666, %670 : !torch.vtensor<[8,16384,512],f16>, !torch.vtensor<[8,512,16384],f16> -> !torch.vtensor<[8,16384,16384],f16>
    %int8_817 = torch.constant.int 8
    %int1_818 = torch.constant.int 1
    %int16384_819 = torch.constant.int 16384
    %int16384_820 = torch.constant.int 16384
    %672 = torch.prim.ListConstruct %int8_817, %int1_818, %int16384_819, %int16384_820 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %673 = torch.aten.view %671, %672 : !torch.vtensor<[8,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,1,16384,16384],f16>
    %int-1_821 = torch.constant.int -1
    %false_822 = torch.constant.bool false
    %674 = torch.aten._softmax %673, %int-1_821, %false_822 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[8,1,16384,16384],f16>
    %int8_823 = torch.constant.int 8
    %int1_824 = torch.constant.int 1
    %int16384_825 = torch.constant.int 16384
    %int16384_826 = torch.constant.int 16384
    %675 = torch.prim.ListConstruct %int8_823, %int1_824, %int16384_825, %int16384_826 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_827 = torch.constant.bool false
    %676 = torch.aten.expand %674, %675, %false_827 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,16384],f16>
    %int8_828 = torch.constant.int 8
    %int16384_829 = torch.constant.int 16384
    %int16384_830 = torch.constant.int 16384
    %677 = torch.prim.ListConstruct %int8_828, %int16384_829, %int16384_830 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %678 = torch.aten.view %676, %677 : !torch.vtensor<[8,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,16384],f16>
    %int8_831 = torch.constant.int 8
    %int1_832 = torch.constant.int 1
    %int16384_833 = torch.constant.int 16384
    %int512_834 = torch.constant.int 512
    %679 = torch.prim.ListConstruct %int8_831, %int1_832, %int16384_833, %int512_834 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_835 = torch.constant.bool false
    %680 = torch.aten.expand %659, %679, %false_835 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1,16384,512],f16>
    %int8_836 = torch.constant.int 8
    %int16384_837 = torch.constant.int 16384
    %int512_838 = torch.constant.int 512
    %681 = torch.prim.ListConstruct %int8_836, %int16384_837, %int512_838 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %682 = torch.aten.view %680, %681 : !torch.vtensor<[8,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %683 = torch.aten.bmm %678, %682 : !torch.vtensor<[8,16384,16384],f16>, !torch.vtensor<[8,16384,512],f16> -> !torch.vtensor<[8,16384,512],f16>
    %int8_839 = torch.constant.int 8
    %int1_840 = torch.constant.int 1
    %int16384_841 = torch.constant.int 16384
    %int512_842 = torch.constant.int 512
    %684 = torch.prim.ListConstruct %int8_839, %int1_840, %int16384_841, %int512_842 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %685 = torch.aten.view %683, %684 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[8,1,16384,512],f16>
    %int1_843 = torch.constant.int 1
    %int2_844 = torch.constant.int 2
    %686 = torch.aten.transpose.int %685, %int1_843, %int2_844 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,1,512],f16>
    %int1_845 = torch.constant.int 1
    %int2_846 = torch.constant.int 2
    %687 = torch.aten.transpose.int %686, %int1_845, %int2_846 : !torch.vtensor<[8,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,1,16384,512],f16>
    %int1_847 = torch.constant.int 1
    %int2_848 = torch.constant.int 2
    %688 = torch.aten.transpose.int %687, %int1_847, %int2_848 : !torch.vtensor<[8,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,16384,1,512],f16>
    %int8_849 = torch.constant.int 8
    %int-1_850 = torch.constant.int -1
    %int512_851 = torch.constant.int 512
    %689 = torch.prim.ListConstruct %int8_849, %int-1_850, %int512_851 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %690 = torch.aten.view %688, %689 : !torch.vtensor<[8,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %int5_852 = torch.constant.int 5
    %691 = torch.prims.convert_element_type %690, %int5_852 : !torch.vtensor<[8,16384,512],f16>, !torch.int -> !torch.vtensor<[8,16384,512],f16>
    %int131072_853 = torch.constant.int 131072
    %int512_854 = torch.constant.int 512
    %692 = torch.prim.ListConstruct %int131072_853, %int512_854 : (!torch.int, !torch.int) -> !torch.list<int>
    %693 = torch.aten.view %691, %692 : !torch.vtensor<[8,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[131072,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_out.0.weight = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %694 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_855 = torch.constant.int 0
    %int1_856 = torch.constant.int 1
    %695 = torch.aten.transpose.int %694, %int0_855, %int1_856 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %__auto.vae.encoder.mid_block.attentions.0.to_out.0.bias = util.global.load @__auto.vae.encoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %696 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_857 = torch.constant.int 6
    %697 = torch.prims.convert_element_type %696, %int6_857 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_858 = torch.constant.int 6
    %698 = torch.prims.convert_element_type %693, %int6_858 : !torch.vtensor<[131072,512],f16>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int6_859 = torch.constant.int 6
    %699 = torch.prims.convert_element_type %695, %int6_859 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %700 = torch.aten.mm %698, %699 : !torch.vtensor<[131072,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[131072,512],f32>
    %int1_860 = torch.constant.int 1
    %701 = torch.aten.mul.Scalar %700, %int1_860 : !torch.vtensor<[131072,512],f32>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int1_861 = torch.constant.int 1
    %702 = torch.aten.mul.Scalar %697, %int1_861 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_862 = torch.constant.int 1
    %703 = torch.aten.add.Tensor %701, %702, %int1_862 : !torch.vtensor<[131072,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[131072,512],f32>
    %int5_863 = torch.constant.int 5
    %704 = torch.prims.convert_element_type %703, %int5_863 : !torch.vtensor<[131072,512],f32>, !torch.int -> !torch.vtensor<[131072,512],f16>
    %int8_864 = torch.constant.int 8
    %int16384_865 = torch.constant.int 16384
    %int512_866 = torch.constant.int 512
    %705 = torch.prim.ListConstruct %int8_864, %int16384_865, %int512_866 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %706 = torch.aten.view %704, %705 : !torch.vtensor<[131072,512],f16>, !torch.list<int> -> !torch.vtensor<[8,16384,512],f16>
    %none_867 = torch.constant.none
    %707 = torch.aten.clone %706, %none_867 : !torch.vtensor<[8,16384,512],f16>, !torch.none -> !torch.vtensor<[8,16384,512],f16>
    %int-1_868 = torch.constant.int -1
    %int-2_869 = torch.constant.int -2
    %708 = torch.aten.transpose.int %707, %int-1_868, %int-2_869 : !torch.vtensor<[8,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[8,512,16384],f16>
    %int8_870 = torch.constant.int 8
    %int512_871 = torch.constant.int 512
    %int128_872 = torch.constant.int 128
    %int128_873 = torch.constant.int 128
    %709 = torch.prim.ListConstruct %int8_870, %int512_871, %int128_872, %int128_873 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %710 = torch.aten.view %708, %709 : !torch.vtensor<[8,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f16>
    %int1_874 = torch.constant.int 1
    %711 = torch.aten.add.Tensor %710, %596, %int1_874 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_875 = torch.constant.int 1
    %712 = torch.aten.div.Scalar %711, %int1_875 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_876 = torch.constant.int 8
    %int32_877 = torch.constant.int 32
    %int16_878 = torch.constant.int 16
    %int16384_879 = torch.constant.int 16384
    %713 = torch.prim.ListConstruct %int8_876, %int32_877, %int16_878, %int16384_879 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %714 = torch.aten.view %712, %713 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_880 = torch.constant.int 6
    %715 = torch.prims.convert_element_type %714, %int6_880 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_881 = torch.constant.int 2
    %int3_882 = torch.constant.int 3
    %716 = torch.prim.ListConstruct %int2_881, %int3_882 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_883 = torch.constant.int 0
    %true_884 = torch.constant.bool true
    %result0_885, %result1_886 = torch.aten.var_mean.correction %715, %716, %int0_883, %true_884 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_887 = torch.constant.float 9.9999999999999995E-7
    %int1_888 = torch.constant.int 1
    %717 = torch.aten.add.Scalar %result0_885, %float9.999990e-07_887, %int1_888 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %718 = torch.aten.rsqrt %717 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_889 = torch.constant.int 1
    %719 = torch.aten.sub.Tensor %714, %result1_886, %int1_889 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %720 = torch.aten.mul.Tensor %719, %718 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_890 = torch.constant.int 8
    %int512_891 = torch.constant.int 512
    %int128_892 = torch.constant.int 128
    %int128_893 = torch.constant.int 128
    %721 = torch.prim.ListConstruct %int8_890, %int512_891, %int128_892, %int128_893 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %722 = torch.aten.view %720, %721 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.mid_block.resnets.1.norm1.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %723 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_894 = torch.constant.int 0
    %724 = torch.aten.unsqueeze %723, %int0_894 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_895 = torch.constant.int 2
    %725 = torch.aten.unsqueeze %724, %int2_895 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_896 = torch.constant.int 3
    %726 = torch.aten.unsqueeze %725, %int3_896 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.mid_block.resnets.1.norm1.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %727 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_897 = torch.constant.int 0
    %728 = torch.aten.unsqueeze %727, %int0_897 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_898 = torch.constant.int 2
    %729 = torch.aten.unsqueeze %728, %int2_898 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_899 = torch.constant.int 3
    %730 = torch.aten.unsqueeze %729, %int3_899 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %731 = torch.aten.mul.Tensor %722, %730 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_900 = torch.constant.int 1
    %732 = torch.aten.add.Tensor %731, %726, %int1_900 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_901 = torch.constant.int 5
    %733 = torch.prims.convert_element_type %732, %int5_901 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %734 = torch.aten.silu %733 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.mid_block.resnets.1.conv1.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %735 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.mid_block.resnets.1.conv1.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %736 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_902 = torch.constant.int 1
    %int1_903 = torch.constant.int 1
    %737 = torch.prim.ListConstruct %int1_902, %int1_903 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_904 = torch.constant.int 1
    %int1_905 = torch.constant.int 1
    %738 = torch.prim.ListConstruct %int1_904, %int1_905 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_906 = torch.constant.int 1
    %int1_907 = torch.constant.int 1
    %739 = torch.prim.ListConstruct %int1_906, %int1_907 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_908 = torch.constant.bool false
    %int0_909 = torch.constant.int 0
    %int0_910 = torch.constant.int 0
    %740 = torch.prim.ListConstruct %int0_909, %int0_910 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_911 = torch.constant.int 1
    %741 = torch.aten.convolution %734, %735, %736, %737, %738, %739, %false_908, %740, %int1_911 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_912 = torch.constant.int 8
    %int32_913 = torch.constant.int 32
    %int16_914 = torch.constant.int 16
    %int16384_915 = torch.constant.int 16384
    %742 = torch.prim.ListConstruct %int8_912, %int32_913, %int16_914, %int16384_915 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %743 = torch.aten.view %741, %742 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_916 = torch.constant.int 6
    %744 = torch.prims.convert_element_type %743, %int6_916 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_917 = torch.constant.int 2
    %int3_918 = torch.constant.int 3
    %745 = torch.prim.ListConstruct %int2_917, %int3_918 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_919 = torch.constant.int 0
    %true_920 = torch.constant.bool true
    %result0_921, %result1_922 = torch.aten.var_mean.correction %744, %745, %int0_919, %true_920 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_923 = torch.constant.float 9.9999999999999995E-7
    %int1_924 = torch.constant.int 1
    %746 = torch.aten.add.Scalar %result0_921, %float9.999990e-07_923, %int1_924 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %747 = torch.aten.rsqrt %746 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_925 = torch.constant.int 1
    %748 = torch.aten.sub.Tensor %743, %result1_922, %int1_925 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %749 = torch.aten.mul.Tensor %748, %747 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_926 = torch.constant.int 8
    %int512_927 = torch.constant.int 512
    %int128_928 = torch.constant.int 128
    %int128_929 = torch.constant.int 128
    %750 = torch.prim.ListConstruct %int8_926, %int512_927, %int128_928, %int128_929 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %751 = torch.aten.view %749, %750 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.mid_block.resnets.1.norm2.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %752 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_930 = torch.constant.int 0
    %753 = torch.aten.unsqueeze %752, %int0_930 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_931 = torch.constant.int 2
    %754 = torch.aten.unsqueeze %753, %int2_931 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_932 = torch.constant.int 3
    %755 = torch.aten.unsqueeze %754, %int3_932 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.mid_block.resnets.1.norm2.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %756 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_933 = torch.constant.int 0
    %757 = torch.aten.unsqueeze %756, %int0_933 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_934 = torch.constant.int 2
    %758 = torch.aten.unsqueeze %757, %int2_934 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_935 = torch.constant.int 3
    %759 = torch.aten.unsqueeze %758, %int3_935 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %760 = torch.aten.mul.Tensor %751, %759 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_936 = torch.constant.int 1
    %761 = torch.aten.add.Tensor %760, %755, %int1_936 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_937 = torch.constant.int 5
    %762 = torch.prims.convert_element_type %761, %int5_937 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %763 = torch.aten.silu %762 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %none_938 = torch.constant.none
    %764 = torch.aten.clone %763, %none_938 : !torch.vtensor<[8,512,128,128],f16>, !torch.none -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.mid_block.resnets.1.conv2.weight = util.global.load @__auto.vae.encoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %765 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.encoder.mid_block.resnets.1.conv2.bias = util.global.load @__auto.vae.encoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %766 = torch_c.from_builtin_tensor %__auto.vae.encoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_939 = torch.constant.int 1
    %int1_940 = torch.constant.int 1
    %767 = torch.prim.ListConstruct %int1_939, %int1_940 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_941 = torch.constant.int 1
    %int1_942 = torch.constant.int 1
    %768 = torch.prim.ListConstruct %int1_941, %int1_942 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_943 = torch.constant.int 1
    %int1_944 = torch.constant.int 1
    %769 = torch.prim.ListConstruct %int1_943, %int1_944 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_945 = torch.constant.bool false
    %int0_946 = torch.constant.int 0
    %int0_947 = torch.constant.int 0
    %770 = torch.prim.ListConstruct %int0_946, %int0_947 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_948 = torch.constant.int 1
    %771 = torch.aten.convolution %764, %765, %766, %767, %768, %769, %false_945, %770, %int1_948 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_949 = torch.constant.int 1
    %772 = torch.aten.add.Tensor %712, %771, %int1_949 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int1_950 = torch.constant.int 1
    %773 = torch.aten.div.Scalar %772, %int1_950 : !torch.vtensor<[8,512,128,128],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %int8_951 = torch.constant.int 8
    %int32_952 = torch.constant.int 32
    %int16_953 = torch.constant.int 16
    %int16384_954 = torch.constant.int 16384
    %774 = torch.prim.ListConstruct %int8_951, %int32_952, %int16_953, %int16384_954 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %775 = torch.aten.view %773, %774 : !torch.vtensor<[8,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[8,32,16,16384],f16>
    %int6_955 = torch.constant.int 6
    %776 = torch.prims.convert_element_type %775, %int6_955 : !torch.vtensor<[8,32,16,16384],f16>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %int2_956 = torch.constant.int 2
    %int3_957 = torch.constant.int 3
    %777 = torch.prim.ListConstruct %int2_956, %int3_957 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_958 = torch.constant.int 0
    %true_959 = torch.constant.bool true
    %result0_960, %result1_961 = torch.aten.var_mean.correction %776, %777, %int0_958, %true_959 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[8,32,1,1],f32>, !torch.vtensor<[8,32,1,1],f32>
    %float9.999990e-07_962 = torch.constant.float 9.9999999999999995E-7
    %int1_963 = torch.constant.int 1
    %778 = torch.aten.add.Scalar %result0_960, %float9.999990e-07_962, %int1_963 : !torch.vtensor<[8,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[8,32,1,1],f32>
    %779 = torch.aten.rsqrt %778 : !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,1,1],f32>
    %int1_964 = torch.constant.int 1
    %780 = torch.aten.sub.Tensor %775, %result1_961, %int1_964 : !torch.vtensor<[8,32,16,16384],f16>, !torch.vtensor<[8,32,1,1],f32>, !torch.int -> !torch.vtensor<[8,32,16,16384],f32>
    %781 = torch.aten.mul.Tensor %780, %779 : !torch.vtensor<[8,32,16,16384],f32>, !torch.vtensor<[8,32,1,1],f32> -> !torch.vtensor<[8,32,16,16384],f32>
    %int8_965 = torch.constant.int 8
    %int512_966 = torch.constant.int 512
    %int128_967 = torch.constant.int 128
    %int128_968 = torch.constant.int 128
    %782 = torch.prim.ListConstruct %int8_965, %int512_966, %int128_967, %int128_968 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %783 = torch.aten.view %781, %782 : !torch.vtensor<[8,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[8,512,128,128],f32>
    %__auto.vae.encoder.conv_norm_out.bias = util.global.load @__auto.vae.encoder.conv_norm_out.bias : tensor<512xf16>
    %784 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_norm_out.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_969 = torch.constant.int 0
    %785 = torch.aten.unsqueeze %784, %int0_969 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_970 = torch.constant.int 2
    %786 = torch.aten.unsqueeze %785, %int2_970 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_971 = torch.constant.int 3
    %787 = torch.aten.unsqueeze %786, %int3_971 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.encoder.conv_norm_out.weight = util.global.load @__auto.vae.encoder.conv_norm_out.weight : tensor<512xf16>
    %788 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_norm_out.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_972 = torch.constant.int 0
    %789 = torch.aten.unsqueeze %788, %int0_972 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_973 = torch.constant.int 2
    %790 = torch.aten.unsqueeze %789, %int2_973 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_974 = torch.constant.int 3
    %791 = torch.aten.unsqueeze %790, %int3_974 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %792 = torch.aten.mul.Tensor %783, %791 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[8,512,128,128],f32>
    %int1_975 = torch.constant.int 1
    %793 = torch.aten.add.Tensor %792, %787, %int1_975 : !torch.vtensor<[8,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[8,512,128,128],f32>
    %int5_976 = torch.constant.int 5
    %794 = torch.prims.convert_element_type %793, %int5_976 : !torch.vtensor<[8,512,128,128],f32>, !torch.int -> !torch.vtensor<[8,512,128,128],f16>
    %795 = torch.aten.silu %794 : !torch.vtensor<[8,512,128,128],f16> -> !torch.vtensor<[8,512,128,128],f16>
    %__auto.vae.encoder.conv_out.weight = util.global.load @__auto.vae.encoder.conv_out.weight : tensor<8x512x3x3xf16>
    %796 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_out.weight : tensor<8x512x3x3xf16> -> !torch.vtensor<[8,512,3,3],f16>
    %__auto.vae.encoder.conv_out.bias = util.global.load @__auto.vae.encoder.conv_out.bias : tensor<8xf16>
    %797 = torch_c.from_builtin_tensor %__auto.vae.encoder.conv_out.bias : tensor<8xf16> -> !torch.vtensor<[8],f16>
    %int1_977 = torch.constant.int 1
    %int1_978 = torch.constant.int 1
    %798 = torch.prim.ListConstruct %int1_977, %int1_978 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_979 = torch.constant.int 1
    %int1_980 = torch.constant.int 1
    %799 = torch.prim.ListConstruct %int1_979, %int1_980 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_981 = torch.constant.int 1
    %int1_982 = torch.constant.int 1
    %800 = torch.prim.ListConstruct %int1_981, %int1_982 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_983 = torch.constant.bool false
    %int0_984 = torch.constant.int 0
    %int0_985 = torch.constant.int 0
    %801 = torch.prim.ListConstruct %int0_984, %int0_985 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_986 = torch.constant.int 1
    %802 = torch.aten.convolution %795, %796, %797, %798, %799, %800, %false_983, %801, %int1_986 : !torch.vtensor<[8,512,128,128],f16>, !torch.vtensor<[8,512,3,3],f16>, !torch.vtensor<[8],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,8,128,128],f16>
    %__auto.vae.quant_conv.weight = util.global.load @__auto.vae.quant_conv.weight : tensor<8x8x1x1xf16>
    %803 = torch_c.from_builtin_tensor %__auto.vae.quant_conv.weight : tensor<8x8x1x1xf16> -> !torch.vtensor<[8,8,1,1],f16>
    %__auto.vae.quant_conv.bias = util.global.load @__auto.vae.quant_conv.bias : tensor<8xf16>
    %804 = torch_c.from_builtin_tensor %__auto.vae.quant_conv.bias : tensor<8xf16> -> !torch.vtensor<[8],f16>
    %int1_987 = torch.constant.int 1
    %int1_988 = torch.constant.int 1
    %805 = torch.prim.ListConstruct %int1_987, %int1_988 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_989 = torch.constant.int 0
    %int0_990 = torch.constant.int 0
    %806 = torch.prim.ListConstruct %int0_989, %int0_990 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_991 = torch.constant.int 1
    %int1_992 = torch.constant.int 1
    %807 = torch.prim.ListConstruct %int1_991, %int1_992 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_993 = torch.constant.bool false
    %int0_994 = torch.constant.int 0
    %int0_995 = torch.constant.int 0
    %808 = torch.prim.ListConstruct %int0_994, %int0_995 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_996 = torch.constant.int 1
    %809 = torch.aten.convolution %802, %803, %804, %805, %806, %807, %false_993, %808, %int1_996 : !torch.vtensor<[8,8,128,128],f16>, !torch.vtensor<[8,8,1,1],f16>, !torch.vtensor<[8],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[8,8,128,128],f16>
    %int1_997 = torch.constant.int 1
    %int0_998 = torch.constant.int 0
    %int4_999 = torch.constant.int 4
    %int1_1000 = torch.constant.int 1
    %810 = torch.aten.slice.Tensor %809, %int1_997, %int0_998, %int4_999, %int1_1000 : !torch.vtensor<[8,8,128,128],f16>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[8,4,128,128],f16>
    %int1_1001 = torch.constant.int 1
    %int4_1002 = torch.constant.int 4
    %int8_1003 = torch.constant.int 8
    %int1_1004 = torch.constant.int 1
    %811 = torch.aten.slice.Tensor %809, %int1_1001, %int4_1002, %int8_1003, %int1_1004 : !torch.vtensor<[8,8,128,128],f16>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[8,4,128,128],f16>
    %float-3.000000e01 = torch.constant.float -3.000000e+01
    %float2.000000e01 = torch.constant.float 2.000000e+01
    %812 = torch.aten.clamp %811, %float-3.000000e01, %float2.000000e01 : !torch.vtensor<[8,4,128,128],f16>, !torch.float, !torch.float -> !torch.vtensor<[8,4,128,128],f16>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %813 = torch.aten.mul.Scalar %812, %float5.000000e-01 : !torch.vtensor<[8,4,128,128],f16>, !torch.float -> !torch.vtensor<[8,4,128,128],f16>
    %814 = torch.aten.exp %813 : !torch.vtensor<[8,4,128,128],f16> -> !torch.vtensor<[8,4,128,128],f16>
    %int8_1005 = torch.constant.int 8
    %int4_1006 = torch.constant.int 4
    %int128_1007 = torch.constant.int 128
    %int128_1008 = torch.constant.int 128
    %815 = torch.prim.ListConstruct %int8_1005, %int4_1006, %int128_1007, %int128_1008 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %none_1009 = torch.constant.none
    %int5_1010 = torch.constant.int 5
    %int0_1011 = torch.constant.int 0
    %cpu = torch.constant.device "cpu"
    %false_1012 = torch.constant.bool false
    %816 = torch.aten.randn.generator %815, %none_1009, %int5_1010, %int0_1011, %cpu, %false_1012 : !torch.list<int>, !torch.none, !torch.int, !torch.int, !torch.Device, !torch.bool -> !torch.vtensor<[8,4,128,128],f16>
    %int5_1013 = torch.constant.int 5
    %817 = torch.prims.convert_element_type %816, %int5_1013 : !torch.vtensor<[8,4,128,128],f16>, !torch.int -> !torch.vtensor<[8,4,128,128],f16>
    %818 = torch.aten.mul.Tensor %814, %817 : !torch.vtensor<[8,4,128,128],f16>, !torch.vtensor<[8,4,128,128],f16> -> !torch.vtensor<[8,4,128,128],f16>
    %int1_1014 = torch.constant.int 1
    %819 = torch.aten.add.Tensor %810, %818, %int1_1014 : !torch.vtensor<[8,4,128,128],f16>, !torch.vtensor<[8,4,128,128],f16>, !torch.int -> !torch.vtensor<[8,4,128,128],f16>
    %float1.302500e-01 = torch.constant.float 1.302500e-01
    %820 = torch.aten.mul.Scalar %819, %float1.302500e-01 : !torch.vtensor<[8,4,128,128],f16>, !torch.float -> !torch.vtensor<[8,4,128,128],f16>
    return %820 : !torch.vtensor<[8,4,128,128],f16>
  }
}
