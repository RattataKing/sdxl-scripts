module @compiled_vae {
  util.global private @_params.vae.encoder.conv_in.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_in.weight"> : tensor<128x3x3x3xf16>
  util.global private @_params.vae.encoder.conv_in.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_in.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm1.weight"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm1.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.0.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.0.downsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.downsamplers.0.conv.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.0.downsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.0.downsamplers.0.conv.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm1.weight"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm1.bias"> : tensor<128xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv1.weight"> : tensor<256x128x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv_shortcut.weight"> : tensor<256x128x1x1xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.1.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.1.downsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.downsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.1.downsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.1.downsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv1.weight"> : tensor<512x256x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<512x256x1x1xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.2.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.2.downsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.downsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.2.downsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.2.downsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.down_blocks.3.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.down_blocks.3.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.group_norm.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.group_norm.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_q.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_q.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_k.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_k.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_v.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_v.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_out.0.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.encoder.mid_block.attentions.0.to_out.0.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.encoder.mid_block.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.conv_norm_out.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_norm_out.weight"> : tensor<512xf16>
  util.global private @_params.vae.encoder.conv_norm_out.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_norm_out.bias"> : tensor<512xf16>
  util.global private @_params.vae.encoder.conv_out.weight {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_out.weight"> : tensor<8x512x3x3xf16>
  util.global private @_params.vae.encoder.conv_out.bias {noinline} = #stream.parameter.named<"model"::"vae.encoder.conv_out.bias"> : tensor<8xf16>
  util.global private @_params.vae.decoder.conv_in.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_in.weight"> : tensor<512x4x3x3xf16>
  util.global private @_params.vae.decoder.conv_in.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_in.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.resnets.2.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.0.upsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.0.upsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.resnets.2.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.1.upsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.1.upsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.weight"> : tensor<256x512x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<256x512x1x1xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.resnets.2.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.2.upsamplers.0.conv.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.2.upsamplers.0.conv.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.weight"> : tensor<128x256x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight"> : tensor<128x256x1x1xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @_params.vae.decoder.up_blocks.3.resnets.2.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.group_norm.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.group_norm.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_q.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_q.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_k.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_k.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_v.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_v.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_out.0.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @_params.vae.decoder.mid_block.attentions.0.to_out.0.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.0.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.norm1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.norm1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.conv1.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.conv1.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.norm2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.norm2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.conv2.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @_params.vae.decoder.mid_block.resnets.1.conv2.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @_params.vae.decoder.conv_norm_out.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.weight"> : tensor<128xf16>
  util.global private @_params.vae.decoder.conv_norm_out.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.bias"> : tensor<128xf16>
  util.global private @_params.vae.decoder.conv_out.weight {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_out.weight"> : tensor<3x128x3x3xf16>
  util.global private @_params.vae.decoder.conv_out.bias {noinline} = #stream.parameter.named<"model"::"vae.decoder.conv_out.bias"> : tensor<3xf16>
  util.global private @_params.vae.quant_conv.weight {noinline} = #stream.parameter.named<"model"::"vae.quant_conv.weight"> : tensor<8x8x1x1xf16>
  util.global private @_params.vae.quant_conv.bias {noinline} = #stream.parameter.named<"model"::"vae.quant_conv.bias"> : tensor<8xf16>
  util.global private @_params.vae.post_quant_conv.weight {noinline} = #stream.parameter.named<"model"::"vae.post_quant_conv.weight"> : tensor<4x4x1x1xf16>
  util.global private @_params.vae.post_quant_conv.bias {noinline} = #stream.parameter.named<"model"::"vae.post_quant_conv.bias"> : tensor<4xf16>
  func.func @main(%arg0: tensor<1x4x128x128xf16>) -> tensor<1x3x1024x1024xf16> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<1x4x128x128xf16> -> !torch.vtensor<[1,4,128,128],f16>
    %1 = call @decode_inp(%0) : (!torch.vtensor<[1,4,128,128],f16>) -> !torch.vtensor<[1,3,1024,1024],f16>
    %2 = torch_c.to_builtin_tensor %1 : !torch.vtensor<[1,3,1024,1024],f16> -> tensor<1x3x1024x1024xf16>
    return %2 : tensor<1x3x1024x1024xf16>
  }
  func.func private @decode_inp(%arg0: !torch.vtensor<[1,4,128,128],f16>) -> !torch.vtensor<[1,3,1024,1024],f16> {
    %float7.677540e00 = torch.constant.float 7.6775431861804221
    %0 = torch.aten.mul.Scalar %arg0, %float7.677540e00 : !torch.vtensor<[1,4,128,128],f16>, !torch.float -> !torch.vtensor<[1,4,128,128],f16>
    %_params.vae.post_quant_conv.weight = util.global.load @_params.vae.post_quant_conv.weight : tensor<4x4x1x1xf16>
    %1 = torch_c.from_builtin_tensor %_params.vae.post_quant_conv.weight : tensor<4x4x1x1xf16> -> !torch.vtensor<[4,4,1,1],f16>
    %_params.vae.post_quant_conv.bias = util.global.load @_params.vae.post_quant_conv.bias : tensor<4xf16>
    %2 = torch_c.from_builtin_tensor %_params.vae.post_quant_conv.bias : tensor<4xf16> -> !torch.vtensor<[4],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %int0_1 = torch.constant.int 0
    %4 = torch.prim.ListConstruct %int0, %int0_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_2 = torch.constant.int 1
    %int1_3 = torch.constant.int 1
    %5 = torch.prim.ListConstruct %int1_2, %int1_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0_4 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %6 = torch.prim.ListConstruct %int0_4, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %7 = torch.aten.convolution %0, %1, %2, %3, %4, %5, %false, %6, %int1_6 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[4,4,1,1],f16>, !torch.vtensor<[4],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,4,128,128],f16>
    %_params.vae.decoder.conv_in.weight = util.global.load @_params.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16>
    %8 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16> -> !torch.vtensor<[512,4,3,3],f16>
    %_params.vae.decoder.conv_in.bias = util.global.load @_params.vae.decoder.conv_in.bias : tensor<512xf16>
    %9 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_in.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_7 = torch.constant.int 1
    %int1_8 = torch.constant.int 1
    %10 = torch.prim.ListConstruct %int1_7, %int1_8 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_9 = torch.constant.int 1
    %int1_10 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int1_9, %int1_10 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_11 = torch.constant.int 1
    %int1_12 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_11, %int1_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_13 = torch.constant.bool false
    %int0_14 = torch.constant.int 0
    %int0_15 = torch.constant.int 0
    %13 = torch.prim.ListConstruct %int0_14, %int0_15 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_16 = torch.constant.int 1
    %14 = torch.aten.convolution %7, %8, %9, %10, %11, %12, %false_13, %13, %int1_16 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[512,4,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_17 = torch.constant.int 1
    %int32 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %15 = torch.prim.ListConstruct %int1_17, %int32, %int16, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6 = torch.constant.int 6
    %17 = torch.prims.convert_element_type %16, %int6 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %18 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_18 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %17, %18, %int0_18, %true : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_19 = torch.constant.int 1
    %19 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_19 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %20 = torch.aten.rsqrt %19 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_20 = torch.constant.int 1
    %21 = torch.aten.sub.Tensor %16, %result1, %int1_20 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %22 = torch.aten.mul.Tensor %21, %20 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_21 = torch.constant.int 1
    %int512 = torch.constant.int 512
    %int128 = torch.constant.int 128
    %int128_22 = torch.constant.int 128
    %23 = torch.prim.ListConstruct %int1_21, %int512, %int128, %int128_22 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %24 = torch.aten.view %22, %23 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.mid_block.resnets.0.norm1.bias = util.global.load @_params.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %25 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_23 = torch.constant.int 0
    %26 = torch.aten.unsqueeze %25, %int0_23 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_24 = torch.constant.int 2
    %27 = torch.aten.unsqueeze %26, %int2_24 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_25 = torch.constant.int 3
    %28 = torch.aten.unsqueeze %27, %int3_25 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.mid_block.resnets.0.norm1.weight = util.global.load @_params.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %29 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_26 = torch.constant.int 0
    %30 = torch.aten.unsqueeze %29, %int0_26 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_27 = torch.constant.int 2
    %31 = torch.aten.unsqueeze %30, %int2_27 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_28 = torch.constant.int 3
    %32 = torch.aten.unsqueeze %31, %int3_28 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %33 = torch.aten.mul.Tensor %24, %32 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_29 = torch.constant.int 1
    %34 = torch.aten.add.Tensor %33, %28, %int1_29 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5 = torch.constant.int 5
    %35 = torch.prims.convert_element_type %34, %int5 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_30 = torch.constant.int 5
    %36 = torch.prims.convert_element_type %result1, %int5_30 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_31 = torch.constant.int 5
    %37 = torch.prims.convert_element_type %20, %int5_31 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_32 = torch.constant.int 3
    %38 = torch.prim.ListConstruct %int3_32 : (!torch.int) -> !torch.list<int>
    %39 = torch.prims.squeeze %36, %38 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_33 = torch.constant.int 2
    %40 = torch.prim.ListConstruct %int2_33 : (!torch.int) -> !torch.list<int>
    %41 = torch.prims.squeeze %39, %40 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_34 = torch.constant.int 3
    %42 = torch.prim.ListConstruct %int3_34 : (!torch.int) -> !torch.list<int>
    %43 = torch.prims.squeeze %37, %42 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_35 = torch.constant.int 2
    %44 = torch.prim.ListConstruct %int2_35 : (!torch.int) -> !torch.list<int>
    %45 = torch.prims.squeeze %43, %44 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %46 = torch.aten.detach %41 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %47 = torch.aten.detach %45 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %48 = torch.aten.silu %35 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.mid_block.resnets.0.conv1.weight = util.global.load @_params.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %49 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.mid_block.resnets.0.conv1.bias = util.global.load @_params.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %50 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_36 = torch.constant.int 1
    %int1_37 = torch.constant.int 1
    %51 = torch.prim.ListConstruct %int1_36, %int1_37 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_38 = torch.constant.int 1
    %int1_39 = torch.constant.int 1
    %52 = torch.prim.ListConstruct %int1_38, %int1_39 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_40 = torch.constant.int 1
    %int1_41 = torch.constant.int 1
    %53 = torch.prim.ListConstruct %int1_40, %int1_41 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_42 = torch.constant.bool false
    %int0_43 = torch.constant.int 0
    %int0_44 = torch.constant.int 0
    %54 = torch.prim.ListConstruct %int0_43, %int0_44 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_45 = torch.constant.int 1
    %55 = torch.aten.convolution %48, %49, %50, %51, %52, %53, %false_42, %54, %int1_45 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_46 = torch.constant.int 1
    %int32_47 = torch.constant.int 32
    %int16_48 = torch.constant.int 16
    %int16384_49 = torch.constant.int 16384
    %56 = torch.prim.ListConstruct %int1_46, %int32_47, %int16_48, %int16384_49 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %57 = torch.aten.view %55, %56 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_50 = torch.constant.int 6
    %58 = torch.prims.convert_element_type %57, %int6_50 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_51 = torch.constant.int 2
    %int3_52 = torch.constant.int 3
    %59 = torch.prim.ListConstruct %int2_51, %int3_52 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_53 = torch.constant.int 0
    %true_54 = torch.constant.bool true
    %result0_55, %result1_56 = torch.aten.var_mean.correction %58, %59, %int0_53, %true_54 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_57 = torch.constant.float 9.9999999999999995E-7
    %int1_58 = torch.constant.int 1
    %60 = torch.aten.add.Scalar %result0_55, %float9.999990e-07_57, %int1_58 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %61 = torch.aten.rsqrt %60 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_59 = torch.constant.int 1
    %62 = torch.aten.sub.Tensor %57, %result1_56, %int1_59 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %63 = torch.aten.mul.Tensor %62, %61 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_60 = torch.constant.int 1
    %int512_61 = torch.constant.int 512
    %int128_62 = torch.constant.int 128
    %int128_63 = torch.constant.int 128
    %64 = torch.prim.ListConstruct %int1_60, %int512_61, %int128_62, %int128_63 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %65 = torch.aten.view %63, %64 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.mid_block.resnets.0.norm2.bias = util.global.load @_params.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %66 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_64 = torch.constant.int 0
    %67 = torch.aten.unsqueeze %66, %int0_64 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_65 = torch.constant.int 2
    %68 = torch.aten.unsqueeze %67, %int2_65 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_66 = torch.constant.int 3
    %69 = torch.aten.unsqueeze %68, %int3_66 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.mid_block.resnets.0.norm2.weight = util.global.load @_params.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %70 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_67 = torch.constant.int 0
    %71 = torch.aten.unsqueeze %70, %int0_67 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_68 = torch.constant.int 2
    %72 = torch.aten.unsqueeze %71, %int2_68 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_69 = torch.constant.int 3
    %73 = torch.aten.unsqueeze %72, %int3_69 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %74 = torch.aten.mul.Tensor %65, %73 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_70 = torch.constant.int 1
    %75 = torch.aten.add.Tensor %74, %69, %int1_70 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_71 = torch.constant.int 5
    %76 = torch.prims.convert_element_type %75, %int5_71 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_72 = torch.constant.int 5
    %77 = torch.prims.convert_element_type %result1_56, %int5_72 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_73 = torch.constant.int 5
    %78 = torch.prims.convert_element_type %61, %int5_73 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_74 = torch.constant.int 3
    %79 = torch.prim.ListConstruct %int3_74 : (!torch.int) -> !torch.list<int>
    %80 = torch.prims.squeeze %77, %79 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_75 = torch.constant.int 2
    %81 = torch.prim.ListConstruct %int2_75 : (!torch.int) -> !torch.list<int>
    %82 = torch.prims.squeeze %80, %81 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_76 = torch.constant.int 3
    %83 = torch.prim.ListConstruct %int3_76 : (!torch.int) -> !torch.list<int>
    %84 = torch.prims.squeeze %78, %83 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_77 = torch.constant.int 2
    %85 = torch.prim.ListConstruct %int2_77 : (!torch.int) -> !torch.list<int>
    %86 = torch.prims.squeeze %84, %85 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %87 = torch.aten.detach %82 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %88 = torch.aten.detach %86 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %89 = torch.aten.silu %76 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none = torch.constant.none
    %90 = torch.aten.clone %89, %none : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.mid_block.resnets.0.conv2.weight = util.global.load @_params.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %91 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.mid_block.resnets.0.conv2.bias = util.global.load @_params.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %92 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_78 = torch.constant.int 1
    %int1_79 = torch.constant.int 1
    %93 = torch.prim.ListConstruct %int1_78, %int1_79 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_80 = torch.constant.int 1
    %int1_81 = torch.constant.int 1
    %94 = torch.prim.ListConstruct %int1_80, %int1_81 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_82 = torch.constant.int 1
    %int1_83 = torch.constant.int 1
    %95 = torch.prim.ListConstruct %int1_82, %int1_83 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_84 = torch.constant.bool false
    %int0_85 = torch.constant.int 0
    %int0_86 = torch.constant.int 0
    %96 = torch.prim.ListConstruct %int0_85, %int0_86 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_87 = torch.constant.int 1
    %97 = torch.aten.convolution %90, %91, %92, %93, %94, %95, %false_84, %96, %int1_87 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_88 = torch.constant.int 1
    %98 = torch.aten.add.Tensor %14, %97, %int1_88 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_89 = torch.constant.int 1
    %99 = torch.aten.div.Scalar %98, %int1_89 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_90 = torch.constant.int 1
    %int512_91 = torch.constant.int 512
    %int16384_92 = torch.constant.int 16384
    %100 = torch.prim.ListConstruct %int1_90, %int512_91, %int16384_92 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %101 = torch.aten.view %99, %100 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %int1_93 = torch.constant.int 1
    %int2_94 = torch.constant.int 2
    %102 = torch.aten.transpose.int %101, %int1_93, %int2_94 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_95 = torch.constant.int 1
    %int2_96 = torch.constant.int 2
    %103 = torch.aten.transpose.int %102, %int1_95, %int2_96 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_97 = torch.constant.int 1
    %int32_98 = torch.constant.int 32
    %int16_99 = torch.constant.int 16
    %int16384_100 = torch.constant.int 16384
    %104 = torch.prim.ListConstruct %int1_97, %int32_98, %int16_99, %int16384_100 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %105 = torch.aten.view %103, %104 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_101 = torch.constant.int 6
    %106 = torch.prims.convert_element_type %105, %int6_101 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_102 = torch.constant.int 2
    %int3_103 = torch.constant.int 3
    %107 = torch.prim.ListConstruct %int2_102, %int3_103 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_104 = torch.constant.int 0
    %true_105 = torch.constant.bool true
    %result0_106, %result1_107 = torch.aten.var_mean.correction %106, %107, %int0_104, %true_105 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_108 = torch.constant.float 9.9999999999999995E-7
    %int1_109 = torch.constant.int 1
    %108 = torch.aten.add.Scalar %result0_106, %float9.999990e-07_108, %int1_109 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %109 = torch.aten.rsqrt %108 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_110 = torch.constant.int 1
    %110 = torch.aten.sub.Tensor %105, %result1_107, %int1_110 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %111 = torch.aten.mul.Tensor %110, %109 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_111 = torch.constant.int 1
    %int512_112 = torch.constant.int 512
    %int16384_113 = torch.constant.int 16384
    %112 = torch.prim.ListConstruct %int1_111, %int512_112, %int16384_113 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %113 = torch.aten.view %111, %112 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f32>
    %_params.vae.decoder.mid_block.attentions.0.group_norm.bias = util.global.load @_params.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %114 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_114 = torch.constant.int 0
    %115 = torch.aten.unsqueeze %114, %int0_114 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_115 = torch.constant.int 2
    %116 = torch.aten.unsqueeze %115, %int2_115 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %_params.vae.decoder.mid_block.attentions.0.group_norm.weight = util.global.load @_params.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %117 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_116 = torch.constant.int 0
    %118 = torch.aten.unsqueeze %117, %int0_116 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_117 = torch.constant.int 2
    %119 = torch.aten.unsqueeze %118, %int2_117 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %120 = torch.aten.mul.Tensor %113, %119 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[1,512,16384],f32>
    %int1_118 = torch.constant.int 1
    %121 = torch.aten.add.Tensor %120, %116, %int1_118 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,16384],f32>
    %int5_119 = torch.constant.int 5
    %122 = torch.prims.convert_element_type %121, %int5_119 : !torch.vtensor<[1,512,16384],f32>, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int5_120 = torch.constant.int 5
    %123 = torch.prims.convert_element_type %result1_107, %int5_120 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_121 = torch.constant.int 5
    %124 = torch.prims.convert_element_type %109, %int5_121 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_122 = torch.constant.int 3
    %125 = torch.prim.ListConstruct %int3_122 : (!torch.int) -> !torch.list<int>
    %126 = torch.prims.squeeze %123, %125 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_123 = torch.constant.int 2
    %127 = torch.prim.ListConstruct %int2_123 : (!torch.int) -> !torch.list<int>
    %128 = torch.prims.squeeze %126, %127 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_124 = torch.constant.int 3
    %129 = torch.prim.ListConstruct %int3_124 : (!torch.int) -> !torch.list<int>
    %130 = torch.prims.squeeze %124, %129 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_125 = torch.constant.int 2
    %131 = torch.prim.ListConstruct %int2_125 : (!torch.int) -> !torch.list<int>
    %132 = torch.prims.squeeze %130, %131 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %133 = torch.aten.detach %128 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %134 = torch.aten.detach %132 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %int1_126 = torch.constant.int 1
    %int2_127 = torch.constant.int 2
    %135 = torch.aten.transpose.int %122, %int1_126, %int2_127 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_q.weight = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %136 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_128 = torch.constant.int 0
    %int1_129 = torch.constant.int 1
    %137 = torch.aten.transpose.int %136, %int0_128, %int1_129 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_130 = torch.constant.int 16384
    %int512_131 = torch.constant.int 512
    %138 = torch.prim.ListConstruct %int16384_130, %int512_131 : (!torch.int, !torch.int) -> !torch.list<int>
    %139 = torch.aten.view %135, %138 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %140 = torch.aten.mm %139, %137 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_132 = torch.constant.int 1
    %int16384_133 = torch.constant.int 16384
    %int512_134 = torch.constant.int 512
    %141 = torch.prim.ListConstruct %int1_132, %int16384_133, %int512_134 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %142 = torch.aten.view %140, %141 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_q.bias = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %143 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_135 = torch.constant.int 1
    %144 = torch.aten.add.Tensor %142, %143, %int1_135 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_k.weight = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %145 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_136 = torch.constant.int 0
    %int1_137 = torch.constant.int 1
    %146 = torch.aten.transpose.int %145, %int0_136, %int1_137 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_138 = torch.constant.int 16384
    %int512_139 = torch.constant.int 512
    %147 = torch.prim.ListConstruct %int16384_138, %int512_139 : (!torch.int, !torch.int) -> !torch.list<int>
    %148 = torch.aten.view %135, %147 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %149 = torch.aten.mm %148, %146 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_140 = torch.constant.int 1
    %int16384_141 = torch.constant.int 16384
    %int512_142 = torch.constant.int 512
    %150 = torch.prim.ListConstruct %int1_140, %int16384_141, %int512_142 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %151 = torch.aten.view %149, %150 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_k.bias = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %152 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_143 = torch.constant.int 1
    %153 = torch.aten.add.Tensor %151, %152, %int1_143 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_v.weight = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %154 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_144 = torch.constant.int 0
    %int1_145 = torch.constant.int 1
    %155 = torch.aten.transpose.int %154, %int0_144, %int1_145 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_146 = torch.constant.int 16384
    %int512_147 = torch.constant.int 512
    %156 = torch.prim.ListConstruct %int16384_146, %int512_147 : (!torch.int, !torch.int) -> !torch.list<int>
    %157 = torch.aten.view %135, %156 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %158 = torch.aten.mm %157, %155 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_148 = torch.constant.int 1
    %int16384_149 = torch.constant.int 16384
    %int512_150 = torch.constant.int 512
    %159 = torch.prim.ListConstruct %int1_148, %int16384_149, %int512_150 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %160 = torch.aten.view %158, %159 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_v.bias = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %161 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_151 = torch.constant.int 1
    %162 = torch.aten.add.Tensor %160, %161, %int1_151 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_152 = torch.constant.int 1
    %int-1 = torch.constant.int -1
    %int1_153 = torch.constant.int 1
    %int512_154 = torch.constant.int 512
    %163 = torch.prim.ListConstruct %int1_152, %int-1, %int1_153, %int512_154 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %164 = torch.aten.view %144, %163 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_155 = torch.constant.int 1
    %int2_156 = torch.constant.int 2
    %165 = torch.aten.transpose.int %164, %int1_155, %int2_156 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_157 = torch.constant.int 1
    %int-1_158 = torch.constant.int -1
    %int1_159 = torch.constant.int 1
    %int512_160 = torch.constant.int 512
    %166 = torch.prim.ListConstruct %int1_157, %int-1_158, %int1_159, %int512_160 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %167 = torch.aten.view %153, %166 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_161 = torch.constant.int 1
    %int2_162 = torch.constant.int 2
    %168 = torch.aten.transpose.int %167, %int1_161, %int2_162 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_163 = torch.constant.int 1
    %int-1_164 = torch.constant.int -1
    %int1_165 = torch.constant.int 1
    %int512_166 = torch.constant.int 512
    %169 = torch.prim.ListConstruct %int1_163, %int-1_164, %int1_165, %int512_166 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %170 = torch.aten.view %162, %169 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_167 = torch.constant.int 1
    %int2_168 = torch.constant.int 2
    %171 = torch.aten.transpose.int %170, %int1_167, %int2_168 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %172 = torch.aten.mul.Scalar %165, %float2.102240e-01 : !torch.vtensor<[1,1,16384,512],f16>, !torch.float -> !torch.vtensor<[1,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_169 = torch.constant.int -1
    %173 = torch.aten.transpose.int %168, %int-2, %int-1_169 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,512,16384],f16>
    %float2.102240e-01_170 = torch.constant.float 0.21022410381342863
    %174 = torch.aten.mul.Scalar %173, %float2.102240e-01_170 : !torch.vtensor<[1,1,512,16384],f16>, !torch.float -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_171 = torch.constant.int 1
    %int1_172 = torch.constant.int 1
    %int16384_173 = torch.constant.int 16384
    %int512_174 = torch.constant.int 512
    %175 = torch.prim.ListConstruct %int1_171, %int1_172, %int16384_173, %int512_174 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_175 = torch.constant.bool false
    %176 = torch.aten.expand %172, %175, %false_175 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_176 = torch.constant.int 1
    %int16384_177 = torch.constant.int 16384
    %int512_178 = torch.constant.int 512
    %177 = torch.prim.ListConstruct %int1_176, %int16384_177, %int512_178 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %178 = torch.aten.view %176, %177 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int1_179 = torch.constant.int 1
    %int1_180 = torch.constant.int 1
    %int512_181 = torch.constant.int 512
    %int16384_182 = torch.constant.int 16384
    %179 = torch.prim.ListConstruct %int1_179, %int1_180, %int512_181, %int16384_182 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_183 = torch.constant.bool false
    %180 = torch.aten.expand %174, %179, %false_183 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_184 = torch.constant.int 1
    %int512_185 = torch.constant.int 512
    %int16384_186 = torch.constant.int 16384
    %181 = torch.prim.ListConstruct %int1_184, %int512_185, %int16384_186 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %182 = torch.aten.view %180, %181 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %183 = torch.aten.bmm %178, %182 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[1,512,16384],f16> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_187 = torch.constant.int 1
    %int1_188 = torch.constant.int 1
    %int16384_189 = torch.constant.int 16384
    %int16384_190 = torch.constant.int 16384
    %184 = torch.prim.ListConstruct %int1_187, %int1_188, %int16384_189, %int16384_190 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %185 = torch.aten.view %183, %184 : !torch.vtensor<[1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,16384],f16>
    %int-1_191 = torch.constant.int -1
    %false_192 = torch.constant.bool false
    %186 = torch.aten._softmax %185, %int-1_191, %false_192 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_193 = torch.constant.int 1
    %int1_194 = torch.constant.int 1
    %int16384_195 = torch.constant.int 16384
    %int16384_196 = torch.constant.int 16384
    %187 = torch.prim.ListConstruct %int1_193, %int1_194, %int16384_195, %int16384_196 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_197 = torch.constant.bool false
    %188 = torch.aten.expand %186, %187, %false_197 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_198 = torch.constant.int 1
    %int16384_199 = torch.constant.int 16384
    %int16384_200 = torch.constant.int 16384
    %189 = torch.prim.ListConstruct %int1_198, %int16384_199, %int16384_200 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %190 = torch.aten.view %188, %189 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_201 = torch.constant.int 1
    %int1_202 = torch.constant.int 1
    %int16384_203 = torch.constant.int 16384
    %int512_204 = torch.constant.int 512
    %191 = torch.prim.ListConstruct %int1_201, %int1_202, %int16384_203, %int512_204 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_205 = torch.constant.bool false
    %192 = torch.aten.expand %171, %191, %false_205 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_206 = torch.constant.int 1
    %int16384_207 = torch.constant.int 16384
    %int512_208 = torch.constant.int 512
    %193 = torch.prim.ListConstruct %int1_206, %int16384_207, %int512_208 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %194 = torch.aten.view %192, %193 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %195 = torch.aten.bmm %190, %194 : !torch.vtensor<[1,16384,16384],f16>, !torch.vtensor<[1,16384,512],f16> -> !torch.vtensor<[1,16384,512],f16>
    %int1_209 = torch.constant.int 1
    %int1_210 = torch.constant.int 1
    %int16384_211 = torch.constant.int 16384
    %int512_212 = torch.constant.int 512
    %196 = torch.prim.ListConstruct %int1_209, %int1_210, %int16384_211, %int512_212 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %197 = torch.aten.view %195, %196 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_213 = torch.constant.int 1
    %int2_214 = torch.constant.int 2
    %198 = torch.aten.transpose.int %197, %int1_213, %int2_214 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_215 = torch.constant.int 1
    %int2_216 = torch.constant.int 2
    %199 = torch.aten.transpose.int %198, %int1_215, %int2_216 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %200 = torch.aten.detach %199 : !torch.vtensor<[1,1,16384,512],f16> -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_217 = torch.constant.int 1
    %int2_218 = torch.constant.int 2
    %201 = torch.aten.transpose.int %199, %int1_217, %int2_218 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_219 = torch.constant.int 1
    %int-1_220 = torch.constant.int -1
    %int512_221 = torch.constant.int 512
    %202 = torch.prim.ListConstruct %int1_219, %int-1_220, %int512_221 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %203 = torch.aten.view %201, %202 : !torch.vtensor<[1,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int16384_222 = torch.constant.int 16384
    %int512_223 = torch.constant.int 512
    %204 = torch.prim.ListConstruct %int16384_222, %int512_223 : (!torch.int, !torch.int) -> !torch.list<int>
    %205 = torch.aten.view %203, %204 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_out.0.weight = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %206 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_224 = torch.constant.int 0
    %int1_225 = torch.constant.int 1
    %207 = torch.aten.transpose.int %206, %int0_224, %int1_225 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %_params.vae.decoder.mid_block.attentions.0.to_out.0.bias = util.global.load @_params.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %208 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_226 = torch.constant.int 6
    %209 = torch.prims.convert_element_type %208, %int6_226 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_227 = torch.constant.int 6
    %210 = torch.prims.convert_element_type %205, %int6_227 : !torch.vtensor<[16384,512],f16>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int6_228 = torch.constant.int 6
    %211 = torch.prims.convert_element_type %207, %int6_228 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %212 = torch.aten.mm %210, %211 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[16384,512],f32>
    %int1_229 = torch.constant.int 1
    %213 = torch.aten.mul.Scalar %212, %int1_229 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int1_230 = torch.constant.int 1
    %214 = torch.aten.mul.Scalar %209, %int1_230 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_231 = torch.constant.int 1
    %215 = torch.aten.add.Tensor %213, %214, %int1_231 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int5_232 = torch.constant.int 5
    %216 = torch.prims.convert_element_type %215, %int5_232 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f16>
    %int1_233 = torch.constant.int 1
    %int16384_234 = torch.constant.int 16384
    %int512_235 = torch.constant.int 512
    %217 = torch.prim.ListConstruct %int1_233, %int16384_234, %int512_235 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %218 = torch.aten.view %216, %217 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %none_236 = torch.constant.none
    %219 = torch.aten.clone %218, %none_236 : !torch.vtensor<[1,16384,512],f16>, !torch.none -> !torch.vtensor<[1,16384,512],f16>
    %int-1_237 = torch.constant.int -1
    %int-2_238 = torch.constant.int -2
    %220 = torch.aten.transpose.int %219, %int-1_237, %int-2_238 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_239 = torch.constant.int 1
    %int512_240 = torch.constant.int 512
    %int128_241 = torch.constant.int 128
    %int128_242 = torch.constant.int 128
    %221 = torch.prim.ListConstruct %int1_239, %int512_240, %int128_241, %int128_242 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %222 = torch.aten.view %220, %221 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f16>
    %int1_243 = torch.constant.int 1
    %223 = torch.aten.add.Tensor %222, %99, %int1_243 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_244 = torch.constant.int 1
    %224 = torch.aten.div.Scalar %223, %int1_244 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_245 = torch.constant.int 2
    %225 = torch.aten.clone %224, %int2_245 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_246 = torch.constant.int 1
    %int32_247 = torch.constant.int 32
    %int16_248 = torch.constant.int 16
    %int16384_249 = torch.constant.int 16384
    %226 = torch.prim.ListConstruct %int1_246, %int32_247, %int16_248, %int16384_249 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %227 = torch.aten.view %225, %226 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_250 = torch.constant.int 6
    %228 = torch.prims.convert_element_type %227, %int6_250 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_251 = torch.constant.int 2
    %int3_252 = torch.constant.int 3
    %229 = torch.prim.ListConstruct %int2_251, %int3_252 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_253 = torch.constant.int 0
    %true_254 = torch.constant.bool true
    %result0_255, %result1_256 = torch.aten.var_mean.correction %228, %229, %int0_253, %true_254 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_257 = torch.constant.float 9.9999999999999995E-7
    %int1_258 = torch.constant.int 1
    %230 = torch.aten.add.Scalar %result0_255, %float9.999990e-07_257, %int1_258 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %231 = torch.aten.rsqrt %230 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_259 = torch.constant.int 1
    %232 = torch.aten.sub.Tensor %227, %result1_256, %int1_259 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %233 = torch.aten.mul.Tensor %232, %231 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_260 = torch.constant.int 1
    %int512_261 = torch.constant.int 512
    %int128_262 = torch.constant.int 128
    %int128_263 = torch.constant.int 128
    %234 = torch.prim.ListConstruct %int1_260, %int512_261, %int128_262, %int128_263 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %235 = torch.aten.view %233, %234 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.mid_block.resnets.1.norm1.bias = util.global.load @_params.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %236 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_264 = torch.constant.int 0
    %237 = torch.aten.unsqueeze %236, %int0_264 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_265 = torch.constant.int 2
    %238 = torch.aten.unsqueeze %237, %int2_265 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_266 = torch.constant.int 3
    %239 = torch.aten.unsqueeze %238, %int3_266 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.mid_block.resnets.1.norm1.weight = util.global.load @_params.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %240 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_267 = torch.constant.int 0
    %241 = torch.aten.unsqueeze %240, %int0_267 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_268 = torch.constant.int 2
    %242 = torch.aten.unsqueeze %241, %int2_268 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_269 = torch.constant.int 3
    %243 = torch.aten.unsqueeze %242, %int3_269 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %244 = torch.aten.mul.Tensor %235, %243 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_270 = torch.constant.int 1
    %245 = torch.aten.add.Tensor %244, %239, %int1_270 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_271 = torch.constant.int 5
    %246 = torch.prims.convert_element_type %245, %int5_271 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_272 = torch.constant.int 5
    %247 = torch.prims.convert_element_type %result1_256, %int5_272 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_273 = torch.constant.int 5
    %248 = torch.prims.convert_element_type %231, %int5_273 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_274 = torch.constant.int 3
    %249 = torch.prim.ListConstruct %int3_274 : (!torch.int) -> !torch.list<int>
    %250 = torch.prims.squeeze %247, %249 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_275 = torch.constant.int 2
    %251 = torch.prim.ListConstruct %int2_275 : (!torch.int) -> !torch.list<int>
    %252 = torch.prims.squeeze %250, %251 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_276 = torch.constant.int 3
    %253 = torch.prim.ListConstruct %int3_276 : (!torch.int) -> !torch.list<int>
    %254 = torch.prims.squeeze %248, %253 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_277 = torch.constant.int 2
    %255 = torch.prim.ListConstruct %int2_277 : (!torch.int) -> !torch.list<int>
    %256 = torch.prims.squeeze %254, %255 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %257 = torch.aten.detach %252 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %258 = torch.aten.detach %256 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %259 = torch.aten.silu %246 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.mid_block.resnets.1.conv1.weight = util.global.load @_params.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %260 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.mid_block.resnets.1.conv1.bias = util.global.load @_params.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %261 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_278 = torch.constant.int 1
    %int1_279 = torch.constant.int 1
    %262 = torch.prim.ListConstruct %int1_278, %int1_279 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_280 = torch.constant.int 1
    %int1_281 = torch.constant.int 1
    %263 = torch.prim.ListConstruct %int1_280, %int1_281 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_282 = torch.constant.int 1
    %int1_283 = torch.constant.int 1
    %264 = torch.prim.ListConstruct %int1_282, %int1_283 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_284 = torch.constant.bool false
    %int0_285 = torch.constant.int 0
    %int0_286 = torch.constant.int 0
    %265 = torch.prim.ListConstruct %int0_285, %int0_286 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_287 = torch.constant.int 1
    %266 = torch.aten.convolution %259, %260, %261, %262, %263, %264, %false_284, %265, %int1_287 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_288 = torch.constant.int 2
    %267 = torch.aten.clone %266, %int2_288 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_289 = torch.constant.int 1
    %int32_290 = torch.constant.int 32
    %int16_291 = torch.constant.int 16
    %int16384_292 = torch.constant.int 16384
    %268 = torch.prim.ListConstruct %int1_289, %int32_290, %int16_291, %int16384_292 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %269 = torch.aten.view %267, %268 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_293 = torch.constant.int 6
    %270 = torch.prims.convert_element_type %269, %int6_293 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_294 = torch.constant.int 2
    %int3_295 = torch.constant.int 3
    %271 = torch.prim.ListConstruct %int2_294, %int3_295 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_296 = torch.constant.int 0
    %true_297 = torch.constant.bool true
    %result0_298, %result1_299 = torch.aten.var_mean.correction %270, %271, %int0_296, %true_297 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_300 = torch.constant.float 9.9999999999999995E-7
    %int1_301 = torch.constant.int 1
    %272 = torch.aten.add.Scalar %result0_298, %float9.999990e-07_300, %int1_301 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %273 = torch.aten.rsqrt %272 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_302 = torch.constant.int 1
    %274 = torch.aten.sub.Tensor %269, %result1_299, %int1_302 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %275 = torch.aten.mul.Tensor %274, %273 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_303 = torch.constant.int 1
    %int512_304 = torch.constant.int 512
    %int128_305 = torch.constant.int 128
    %int128_306 = torch.constant.int 128
    %276 = torch.prim.ListConstruct %int1_303, %int512_304, %int128_305, %int128_306 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %277 = torch.aten.view %275, %276 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.mid_block.resnets.1.norm2.bias = util.global.load @_params.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %278 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_307 = torch.constant.int 0
    %279 = torch.aten.unsqueeze %278, %int0_307 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_308 = torch.constant.int 2
    %280 = torch.aten.unsqueeze %279, %int2_308 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_309 = torch.constant.int 3
    %281 = torch.aten.unsqueeze %280, %int3_309 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.mid_block.resnets.1.norm2.weight = util.global.load @_params.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %282 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_310 = torch.constant.int 0
    %283 = torch.aten.unsqueeze %282, %int0_310 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_311 = torch.constant.int 2
    %284 = torch.aten.unsqueeze %283, %int2_311 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_312 = torch.constant.int 3
    %285 = torch.aten.unsqueeze %284, %int3_312 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %286 = torch.aten.mul.Tensor %277, %285 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_313 = torch.constant.int 1
    %287 = torch.aten.add.Tensor %286, %281, %int1_313 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_314 = torch.constant.int 5
    %288 = torch.prims.convert_element_type %287, %int5_314 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_315 = torch.constant.int 5
    %289 = torch.prims.convert_element_type %result1_299, %int5_315 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_316 = torch.constant.int 5
    %290 = torch.prims.convert_element_type %273, %int5_316 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_317 = torch.constant.int 3
    %291 = torch.prim.ListConstruct %int3_317 : (!torch.int) -> !torch.list<int>
    %292 = torch.prims.squeeze %289, %291 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_318 = torch.constant.int 2
    %293 = torch.prim.ListConstruct %int2_318 : (!torch.int) -> !torch.list<int>
    %294 = torch.prims.squeeze %292, %293 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_319 = torch.constant.int 3
    %295 = torch.prim.ListConstruct %int3_319 : (!torch.int) -> !torch.list<int>
    %296 = torch.prims.squeeze %290, %295 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_320 = torch.constant.int 2
    %297 = torch.prim.ListConstruct %int2_320 : (!torch.int) -> !torch.list<int>
    %298 = torch.prims.squeeze %296, %297 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %299 = torch.aten.detach %294 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %300 = torch.aten.detach %298 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %301 = torch.aten.silu %288 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_321 = torch.constant.none
    %302 = torch.aten.clone %301, %none_321 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.mid_block.resnets.1.conv2.weight = util.global.load @_params.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %303 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.mid_block.resnets.1.conv2.bias = util.global.load @_params.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %304 = torch_c.from_builtin_tensor %_params.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_322 = torch.constant.int 1
    %int1_323 = torch.constant.int 1
    %305 = torch.prim.ListConstruct %int1_322, %int1_323 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_324 = torch.constant.int 1
    %int1_325 = torch.constant.int 1
    %306 = torch.prim.ListConstruct %int1_324, %int1_325 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_326 = torch.constant.int 1
    %int1_327 = torch.constant.int 1
    %307 = torch.prim.ListConstruct %int1_326, %int1_327 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_328 = torch.constant.bool false
    %int0_329 = torch.constant.int 0
    %int0_330 = torch.constant.int 0
    %308 = torch.prim.ListConstruct %int0_329, %int0_330 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_331 = torch.constant.int 1
    %309 = torch.aten.convolution %302, %303, %304, %305, %306, %307, %false_328, %308, %int1_331 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_332 = torch.constant.int 1
    %310 = torch.aten.add.Tensor %224, %309, %int1_332 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_333 = torch.constant.int 1
    %311 = torch.aten.div.Scalar %310, %int1_333 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_334 = torch.constant.int 2
    %312 = torch.aten.clone %311, %int2_334 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_335 = torch.constant.int 1
    %int32_336 = torch.constant.int 32
    %int16_337 = torch.constant.int 16
    %int16384_338 = torch.constant.int 16384
    %313 = torch.prim.ListConstruct %int1_335, %int32_336, %int16_337, %int16384_338 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %314 = torch.aten.view %312, %313 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_339 = torch.constant.int 6
    %315 = torch.prims.convert_element_type %314, %int6_339 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_340 = torch.constant.int 2
    %int3_341 = torch.constant.int 3
    %316 = torch.prim.ListConstruct %int2_340, %int3_341 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_342 = torch.constant.int 0
    %true_343 = torch.constant.bool true
    %result0_344, %result1_345 = torch.aten.var_mean.correction %315, %316, %int0_342, %true_343 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_346 = torch.constant.float 9.9999999999999995E-7
    %int1_347 = torch.constant.int 1
    %317 = torch.aten.add.Scalar %result0_344, %float9.999990e-07_346, %int1_347 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %318 = torch.aten.rsqrt %317 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_348 = torch.constant.int 1
    %319 = torch.aten.sub.Tensor %314, %result1_345, %int1_348 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %320 = torch.aten.mul.Tensor %319, %318 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_349 = torch.constant.int 1
    %int512_350 = torch.constant.int 512
    %int128_351 = torch.constant.int 128
    %int128_352 = torch.constant.int 128
    %321 = torch.prim.ListConstruct %int1_349, %int512_350, %int128_351, %int128_352 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %322 = torch.aten.view %320, %321 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.0.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16>
    %323 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_353 = torch.constant.int 0
    %324 = torch.aten.unsqueeze %323, %int0_353 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_354 = torch.constant.int 2
    %325 = torch.aten.unsqueeze %324, %int2_354 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_355 = torch.constant.int 3
    %326 = torch.aten.unsqueeze %325, %int3_355 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16>
    %327 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_356 = torch.constant.int 0
    %328 = torch.aten.unsqueeze %327, %int0_356 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_357 = torch.constant.int 2
    %329 = torch.aten.unsqueeze %328, %int2_357 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_358 = torch.constant.int 3
    %330 = torch.aten.unsqueeze %329, %int3_358 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %331 = torch.aten.mul.Tensor %322, %330 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_359 = torch.constant.int 1
    %332 = torch.aten.add.Tensor %331, %326, %int1_359 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_360 = torch.constant.int 5
    %333 = torch.prims.convert_element_type %332, %int5_360 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_361 = torch.constant.int 5
    %334 = torch.prims.convert_element_type %result1_345, %int5_361 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_362 = torch.constant.int 5
    %335 = torch.prims.convert_element_type %318, %int5_362 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_363 = torch.constant.int 3
    %336 = torch.prim.ListConstruct %int3_363 : (!torch.int) -> !torch.list<int>
    %337 = torch.prims.squeeze %334, %336 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_364 = torch.constant.int 2
    %338 = torch.prim.ListConstruct %int2_364 : (!torch.int) -> !torch.list<int>
    %339 = torch.prims.squeeze %337, %338 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_365 = torch.constant.int 3
    %340 = torch.prim.ListConstruct %int3_365 : (!torch.int) -> !torch.list<int>
    %341 = torch.prims.squeeze %335, %340 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_366 = torch.constant.int 2
    %342 = torch.prim.ListConstruct %int2_366 : (!torch.int) -> !torch.list<int>
    %343 = torch.prims.squeeze %341, %342 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %344 = torch.aten.detach %339 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %345 = torch.aten.detach %343 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %346 = torch.aten.silu %333 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %347 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16>
    %348 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_367 = torch.constant.int 1
    %int1_368 = torch.constant.int 1
    %349 = torch.prim.ListConstruct %int1_367, %int1_368 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_369 = torch.constant.int 1
    %int1_370 = torch.constant.int 1
    %350 = torch.prim.ListConstruct %int1_369, %int1_370 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_371 = torch.constant.int 1
    %int1_372 = torch.constant.int 1
    %351 = torch.prim.ListConstruct %int1_371, %int1_372 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_373 = torch.constant.bool false
    %int0_374 = torch.constant.int 0
    %int0_375 = torch.constant.int 0
    %352 = torch.prim.ListConstruct %int0_374, %int0_375 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_376 = torch.constant.int 1
    %353 = torch.aten.convolution %346, %347, %348, %349, %350, %351, %false_373, %352, %int1_376 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_377 = torch.constant.int 2
    %354 = torch.aten.clone %353, %int2_377 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_378 = torch.constant.int 1
    %int32_379 = torch.constant.int 32
    %int16_380 = torch.constant.int 16
    %int16384_381 = torch.constant.int 16384
    %355 = torch.prim.ListConstruct %int1_378, %int32_379, %int16_380, %int16384_381 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %356 = torch.aten.view %354, %355 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_382 = torch.constant.int 6
    %357 = torch.prims.convert_element_type %356, %int6_382 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_383 = torch.constant.int 2
    %int3_384 = torch.constant.int 3
    %358 = torch.prim.ListConstruct %int2_383, %int3_384 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_385 = torch.constant.int 0
    %true_386 = torch.constant.bool true
    %result0_387, %result1_388 = torch.aten.var_mean.correction %357, %358, %int0_385, %true_386 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_389 = torch.constant.float 9.9999999999999995E-7
    %int1_390 = torch.constant.int 1
    %359 = torch.aten.add.Scalar %result0_387, %float9.999990e-07_389, %int1_390 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %360 = torch.aten.rsqrt %359 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_391 = torch.constant.int 1
    %361 = torch.aten.sub.Tensor %356, %result1_388, %int1_391 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %362 = torch.aten.mul.Tensor %361, %360 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_392 = torch.constant.int 1
    %int512_393 = torch.constant.int 512
    %int128_394 = torch.constant.int 128
    %int128_395 = torch.constant.int 128
    %363 = torch.prim.ListConstruct %int1_392, %int512_393, %int128_394, %int128_395 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %364 = torch.aten.view %362, %363 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.0.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16>
    %365 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_396 = torch.constant.int 0
    %366 = torch.aten.unsqueeze %365, %int0_396 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_397 = torch.constant.int 2
    %367 = torch.aten.unsqueeze %366, %int2_397 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_398 = torch.constant.int 3
    %368 = torch.aten.unsqueeze %367, %int3_398 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16>
    %369 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_399 = torch.constant.int 0
    %370 = torch.aten.unsqueeze %369, %int0_399 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_400 = torch.constant.int 2
    %371 = torch.aten.unsqueeze %370, %int2_400 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_401 = torch.constant.int 3
    %372 = torch.aten.unsqueeze %371, %int3_401 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %373 = torch.aten.mul.Tensor %364, %372 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_402 = torch.constant.int 1
    %374 = torch.aten.add.Tensor %373, %368, %int1_402 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_403 = torch.constant.int 5
    %375 = torch.prims.convert_element_type %374, %int5_403 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_404 = torch.constant.int 5
    %376 = torch.prims.convert_element_type %result1_388, %int5_404 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_405 = torch.constant.int 5
    %377 = torch.prims.convert_element_type %360, %int5_405 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_406 = torch.constant.int 3
    %378 = torch.prim.ListConstruct %int3_406 : (!torch.int) -> !torch.list<int>
    %379 = torch.prims.squeeze %376, %378 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_407 = torch.constant.int 2
    %380 = torch.prim.ListConstruct %int2_407 : (!torch.int) -> !torch.list<int>
    %381 = torch.prims.squeeze %379, %380 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_408 = torch.constant.int 3
    %382 = torch.prim.ListConstruct %int3_408 : (!torch.int) -> !torch.list<int>
    %383 = torch.prims.squeeze %377, %382 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_409 = torch.constant.int 2
    %384 = torch.prim.ListConstruct %int2_409 : (!torch.int) -> !torch.list<int>
    %385 = torch.prims.squeeze %383, %384 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %386 = torch.aten.detach %381 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %387 = torch.aten.detach %385 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %388 = torch.aten.silu %375 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_410 = torch.constant.none
    %389 = torch.aten.clone %388, %none_410 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %390 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.0.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16>
    %391 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_411 = torch.constant.int 1
    %int1_412 = torch.constant.int 1
    %392 = torch.prim.ListConstruct %int1_411, %int1_412 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_413 = torch.constant.int 1
    %int1_414 = torch.constant.int 1
    %393 = torch.prim.ListConstruct %int1_413, %int1_414 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_415 = torch.constant.int 1
    %int1_416 = torch.constant.int 1
    %394 = torch.prim.ListConstruct %int1_415, %int1_416 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_417 = torch.constant.bool false
    %int0_418 = torch.constant.int 0
    %int0_419 = torch.constant.int 0
    %395 = torch.prim.ListConstruct %int0_418, %int0_419 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_420 = torch.constant.int 1
    %396 = torch.aten.convolution %389, %390, %391, %392, %393, %394, %false_417, %395, %int1_420 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_421 = torch.constant.int 1
    %397 = torch.aten.add.Tensor %311, %396, %int1_421 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %398 = torch.aten.div.Scalar %397, %float1.000000e00 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int2_422 = torch.constant.int 2
    %399 = torch.aten.clone %398, %int2_422 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_423 = torch.constant.int 1
    %int32_424 = torch.constant.int 32
    %int16_425 = torch.constant.int 16
    %int16384_426 = torch.constant.int 16384
    %400 = torch.prim.ListConstruct %int1_423, %int32_424, %int16_425, %int16384_426 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %401 = torch.aten.view %399, %400 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_427 = torch.constant.int 6
    %402 = torch.prims.convert_element_type %401, %int6_427 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_428 = torch.constant.int 2
    %int3_429 = torch.constant.int 3
    %403 = torch.prim.ListConstruct %int2_428, %int3_429 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_430 = torch.constant.int 0
    %true_431 = torch.constant.bool true
    %result0_432, %result1_433 = torch.aten.var_mean.correction %402, %403, %int0_430, %true_431 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_434 = torch.constant.float 9.9999999999999995E-7
    %int1_435 = torch.constant.int 1
    %404 = torch.aten.add.Scalar %result0_432, %float9.999990e-07_434, %int1_435 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %405 = torch.aten.rsqrt %404 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_436 = torch.constant.int 1
    %406 = torch.aten.sub.Tensor %401, %result1_433, %int1_436 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %407 = torch.aten.mul.Tensor %406, %405 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_437 = torch.constant.int 1
    %int512_438 = torch.constant.int 512
    %int128_439 = torch.constant.int 128
    %int128_440 = torch.constant.int 128
    %408 = torch.prim.ListConstruct %int1_437, %int512_438, %int128_439, %int128_440 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %409 = torch.aten.view %407, %408 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.1.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16>
    %410 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_441 = torch.constant.int 0
    %411 = torch.aten.unsqueeze %410, %int0_441 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_442 = torch.constant.int 2
    %412 = torch.aten.unsqueeze %411, %int2_442 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_443 = torch.constant.int 3
    %413 = torch.aten.unsqueeze %412, %int3_443 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16>
    %414 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_444 = torch.constant.int 0
    %415 = torch.aten.unsqueeze %414, %int0_444 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_445 = torch.constant.int 2
    %416 = torch.aten.unsqueeze %415, %int2_445 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_446 = torch.constant.int 3
    %417 = torch.aten.unsqueeze %416, %int3_446 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %418 = torch.aten.mul.Tensor %409, %417 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_447 = torch.constant.int 1
    %419 = torch.aten.add.Tensor %418, %413, %int1_447 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_448 = torch.constant.int 5
    %420 = torch.prims.convert_element_type %419, %int5_448 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_449 = torch.constant.int 5
    %421 = torch.prims.convert_element_type %result1_433, %int5_449 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_450 = torch.constant.int 5
    %422 = torch.prims.convert_element_type %405, %int5_450 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_451 = torch.constant.int 3
    %423 = torch.prim.ListConstruct %int3_451 : (!torch.int) -> !torch.list<int>
    %424 = torch.prims.squeeze %421, %423 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_452 = torch.constant.int 2
    %425 = torch.prim.ListConstruct %int2_452 : (!torch.int) -> !torch.list<int>
    %426 = torch.prims.squeeze %424, %425 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_453 = torch.constant.int 3
    %427 = torch.prim.ListConstruct %int3_453 : (!torch.int) -> !torch.list<int>
    %428 = torch.prims.squeeze %422, %427 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_454 = torch.constant.int 2
    %429 = torch.prim.ListConstruct %int2_454 : (!torch.int) -> !torch.list<int>
    %430 = torch.prims.squeeze %428, %429 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %431 = torch.aten.detach %426 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %432 = torch.aten.detach %430 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %433 = torch.aten.silu %420 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %434 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16>
    %435 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_455 = torch.constant.int 1
    %int1_456 = torch.constant.int 1
    %436 = torch.prim.ListConstruct %int1_455, %int1_456 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_457 = torch.constant.int 1
    %int1_458 = torch.constant.int 1
    %437 = torch.prim.ListConstruct %int1_457, %int1_458 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_459 = torch.constant.int 1
    %int1_460 = torch.constant.int 1
    %438 = torch.prim.ListConstruct %int1_459, %int1_460 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_461 = torch.constant.bool false
    %int0_462 = torch.constant.int 0
    %int0_463 = torch.constant.int 0
    %439 = torch.prim.ListConstruct %int0_462, %int0_463 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_464 = torch.constant.int 1
    %440 = torch.aten.convolution %433, %434, %435, %436, %437, %438, %false_461, %439, %int1_464 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_465 = torch.constant.int 2
    %441 = torch.aten.clone %440, %int2_465 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_466 = torch.constant.int 1
    %int32_467 = torch.constant.int 32
    %int16_468 = torch.constant.int 16
    %int16384_469 = torch.constant.int 16384
    %442 = torch.prim.ListConstruct %int1_466, %int32_467, %int16_468, %int16384_469 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %443 = torch.aten.view %441, %442 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_470 = torch.constant.int 6
    %444 = torch.prims.convert_element_type %443, %int6_470 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_471 = torch.constant.int 2
    %int3_472 = torch.constant.int 3
    %445 = torch.prim.ListConstruct %int2_471, %int3_472 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_473 = torch.constant.int 0
    %true_474 = torch.constant.bool true
    %result0_475, %result1_476 = torch.aten.var_mean.correction %444, %445, %int0_473, %true_474 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_477 = torch.constant.float 9.9999999999999995E-7
    %int1_478 = torch.constant.int 1
    %446 = torch.aten.add.Scalar %result0_475, %float9.999990e-07_477, %int1_478 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %447 = torch.aten.rsqrt %446 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_479 = torch.constant.int 1
    %448 = torch.aten.sub.Tensor %443, %result1_476, %int1_479 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %449 = torch.aten.mul.Tensor %448, %447 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_480 = torch.constant.int 1
    %int512_481 = torch.constant.int 512
    %int128_482 = torch.constant.int 128
    %int128_483 = torch.constant.int 128
    %450 = torch.prim.ListConstruct %int1_480, %int512_481, %int128_482, %int128_483 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %451 = torch.aten.view %449, %450 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.1.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16>
    %452 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_484 = torch.constant.int 0
    %453 = torch.aten.unsqueeze %452, %int0_484 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_485 = torch.constant.int 2
    %454 = torch.aten.unsqueeze %453, %int2_485 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_486 = torch.constant.int 3
    %455 = torch.aten.unsqueeze %454, %int3_486 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16>
    %456 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_487 = torch.constant.int 0
    %457 = torch.aten.unsqueeze %456, %int0_487 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_488 = torch.constant.int 2
    %458 = torch.aten.unsqueeze %457, %int2_488 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_489 = torch.constant.int 3
    %459 = torch.aten.unsqueeze %458, %int3_489 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %460 = torch.aten.mul.Tensor %451, %459 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_490 = torch.constant.int 1
    %461 = torch.aten.add.Tensor %460, %455, %int1_490 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_491 = torch.constant.int 5
    %462 = torch.prims.convert_element_type %461, %int5_491 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_492 = torch.constant.int 5
    %463 = torch.prims.convert_element_type %result1_476, %int5_492 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_493 = torch.constant.int 5
    %464 = torch.prims.convert_element_type %447, %int5_493 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_494 = torch.constant.int 3
    %465 = torch.prim.ListConstruct %int3_494 : (!torch.int) -> !torch.list<int>
    %466 = torch.prims.squeeze %463, %465 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_495 = torch.constant.int 2
    %467 = torch.prim.ListConstruct %int2_495 : (!torch.int) -> !torch.list<int>
    %468 = torch.prims.squeeze %466, %467 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_496 = torch.constant.int 3
    %469 = torch.prim.ListConstruct %int3_496 : (!torch.int) -> !torch.list<int>
    %470 = torch.prims.squeeze %464, %469 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_497 = torch.constant.int 2
    %471 = torch.prim.ListConstruct %int2_497 : (!torch.int) -> !torch.list<int>
    %472 = torch.prims.squeeze %470, %471 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %473 = torch.aten.detach %468 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %474 = torch.aten.detach %472 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %475 = torch.aten.silu %462 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_498 = torch.constant.none
    %476 = torch.aten.clone %475, %none_498 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %477 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.1.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16>
    %478 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_499 = torch.constant.int 1
    %int1_500 = torch.constant.int 1
    %479 = torch.prim.ListConstruct %int1_499, %int1_500 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_501 = torch.constant.int 1
    %int1_502 = torch.constant.int 1
    %480 = torch.prim.ListConstruct %int1_501, %int1_502 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_503 = torch.constant.int 1
    %int1_504 = torch.constant.int 1
    %481 = torch.prim.ListConstruct %int1_503, %int1_504 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_505 = torch.constant.bool false
    %int0_506 = torch.constant.int 0
    %int0_507 = torch.constant.int 0
    %482 = torch.prim.ListConstruct %int0_506, %int0_507 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_508 = torch.constant.int 1
    %483 = torch.aten.convolution %476, %477, %478, %479, %480, %481, %false_505, %482, %int1_508 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_509 = torch.constant.int 1
    %484 = torch.aten.add.Tensor %398, %483, %int1_509 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_510 = torch.constant.float 1.000000e+00
    %485 = torch.aten.div.Scalar %484, %float1.000000e00_510 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int2_511 = torch.constant.int 2
    %486 = torch.aten.clone %485, %int2_511 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_512 = torch.constant.int 1
    %int32_513 = torch.constant.int 32
    %int16_514 = torch.constant.int 16
    %int16384_515 = torch.constant.int 16384
    %487 = torch.prim.ListConstruct %int1_512, %int32_513, %int16_514, %int16384_515 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %488 = torch.aten.view %486, %487 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_516 = torch.constant.int 6
    %489 = torch.prims.convert_element_type %488, %int6_516 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_517 = torch.constant.int 2
    %int3_518 = torch.constant.int 3
    %490 = torch.prim.ListConstruct %int2_517, %int3_518 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_519 = torch.constant.int 0
    %true_520 = torch.constant.bool true
    %result0_521, %result1_522 = torch.aten.var_mean.correction %489, %490, %int0_519, %true_520 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_523 = torch.constant.float 9.9999999999999995E-7
    %int1_524 = torch.constant.int 1
    %491 = torch.aten.add.Scalar %result0_521, %float9.999990e-07_523, %int1_524 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %492 = torch.aten.rsqrt %491 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_525 = torch.constant.int 1
    %493 = torch.aten.sub.Tensor %488, %result1_522, %int1_525 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %494 = torch.aten.mul.Tensor %493, %492 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_526 = torch.constant.int 1
    %int512_527 = torch.constant.int 512
    %int128_528 = torch.constant.int 128
    %int128_529 = torch.constant.int 128
    %495 = torch.prim.ListConstruct %int1_526, %int512_527, %int128_528, %int128_529 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %496 = torch.aten.view %494, %495 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.2.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16>
    %497 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_530 = torch.constant.int 0
    %498 = torch.aten.unsqueeze %497, %int0_530 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_531 = torch.constant.int 2
    %499 = torch.aten.unsqueeze %498, %int2_531 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_532 = torch.constant.int 3
    %500 = torch.aten.unsqueeze %499, %int3_532 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16>
    %501 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_533 = torch.constant.int 0
    %502 = torch.aten.unsqueeze %501, %int0_533 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_534 = torch.constant.int 2
    %503 = torch.aten.unsqueeze %502, %int2_534 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_535 = torch.constant.int 3
    %504 = torch.aten.unsqueeze %503, %int3_535 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %505 = torch.aten.mul.Tensor %496, %504 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_536 = torch.constant.int 1
    %506 = torch.aten.add.Tensor %505, %500, %int1_536 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_537 = torch.constant.int 5
    %507 = torch.prims.convert_element_type %506, %int5_537 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_538 = torch.constant.int 5
    %508 = torch.prims.convert_element_type %result1_522, %int5_538 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_539 = torch.constant.int 5
    %509 = torch.prims.convert_element_type %492, %int5_539 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_540 = torch.constant.int 3
    %510 = torch.prim.ListConstruct %int3_540 : (!torch.int) -> !torch.list<int>
    %511 = torch.prims.squeeze %508, %510 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_541 = torch.constant.int 2
    %512 = torch.prim.ListConstruct %int2_541 : (!torch.int) -> !torch.list<int>
    %513 = torch.prims.squeeze %511, %512 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_542 = torch.constant.int 3
    %514 = torch.prim.ListConstruct %int3_542 : (!torch.int) -> !torch.list<int>
    %515 = torch.prims.squeeze %509, %514 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_543 = torch.constant.int 2
    %516 = torch.prim.ListConstruct %int2_543 : (!torch.int) -> !torch.list<int>
    %517 = torch.prims.squeeze %515, %516 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %518 = torch.aten.detach %513 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %519 = torch.aten.detach %517 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %520 = torch.aten.silu %507 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %521 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16>
    %522 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_544 = torch.constant.int 1
    %int1_545 = torch.constant.int 1
    %523 = torch.prim.ListConstruct %int1_544, %int1_545 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_546 = torch.constant.int 1
    %int1_547 = torch.constant.int 1
    %524 = torch.prim.ListConstruct %int1_546, %int1_547 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_548 = torch.constant.int 1
    %int1_549 = torch.constant.int 1
    %525 = torch.prim.ListConstruct %int1_548, %int1_549 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_550 = torch.constant.bool false
    %int0_551 = torch.constant.int 0
    %int0_552 = torch.constant.int 0
    %526 = torch.prim.ListConstruct %int0_551, %int0_552 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_553 = torch.constant.int 1
    %527 = torch.aten.convolution %520, %521, %522, %523, %524, %525, %false_550, %526, %int1_553 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int2_554 = torch.constant.int 2
    %528 = torch.aten.clone %527, %int2_554 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_555 = torch.constant.int 1
    %int32_556 = torch.constant.int 32
    %int16_557 = torch.constant.int 16
    %int16384_558 = torch.constant.int 16384
    %529 = torch.prim.ListConstruct %int1_555, %int32_556, %int16_557, %int16384_558 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %530 = torch.aten.view %528, %529 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_559 = torch.constant.int 6
    %531 = torch.prims.convert_element_type %530, %int6_559 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_560 = torch.constant.int 2
    %int3_561 = torch.constant.int 3
    %532 = torch.prim.ListConstruct %int2_560, %int3_561 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_562 = torch.constant.int 0
    %true_563 = torch.constant.bool true
    %result0_564, %result1_565 = torch.aten.var_mean.correction %531, %532, %int0_562, %true_563 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_566 = torch.constant.float 9.9999999999999995E-7
    %int1_567 = torch.constant.int 1
    %533 = torch.aten.add.Scalar %result0_564, %float9.999990e-07_566, %int1_567 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %534 = torch.aten.rsqrt %533 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_568 = torch.constant.int 1
    %535 = torch.aten.sub.Tensor %530, %result1_565, %int1_568 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %536 = torch.aten.mul.Tensor %535, %534 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_569 = torch.constant.int 1
    %int512_570 = torch.constant.int 512
    %int128_571 = torch.constant.int 128
    %int128_572 = torch.constant.int 128
    %537 = torch.prim.ListConstruct %int1_569, %int512_570, %int128_571, %int128_572 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %538 = torch.aten.view %536, %537 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %_params.vae.decoder.up_blocks.0.resnets.2.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16>
    %539 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_573 = torch.constant.int 0
    %540 = torch.aten.unsqueeze %539, %int0_573 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_574 = torch.constant.int 2
    %541 = torch.aten.unsqueeze %540, %int2_574 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_575 = torch.constant.int 3
    %542 = torch.aten.unsqueeze %541, %int3_575 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16>
    %543 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_576 = torch.constant.int 0
    %544 = torch.aten.unsqueeze %543, %int0_576 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_577 = torch.constant.int 2
    %545 = torch.aten.unsqueeze %544, %int2_577 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_578 = torch.constant.int 3
    %546 = torch.aten.unsqueeze %545, %int3_578 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %547 = torch.aten.mul.Tensor %538, %546 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_579 = torch.constant.int 1
    %548 = torch.aten.add.Tensor %547, %542, %int1_579 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_580 = torch.constant.int 5
    %549 = torch.prims.convert_element_type %548, %int5_580 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_581 = torch.constant.int 5
    %550 = torch.prims.convert_element_type %result1_565, %int5_581 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_582 = torch.constant.int 5
    %551 = torch.prims.convert_element_type %534, %int5_582 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_583 = torch.constant.int 3
    %552 = torch.prim.ListConstruct %int3_583 : (!torch.int) -> !torch.list<int>
    %553 = torch.prims.squeeze %550, %552 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_584 = torch.constant.int 2
    %554 = torch.prim.ListConstruct %int2_584 : (!torch.int) -> !torch.list<int>
    %555 = torch.prims.squeeze %553, %554 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_585 = torch.constant.int 3
    %556 = torch.prim.ListConstruct %int3_585 : (!torch.int) -> !torch.list<int>
    %557 = torch.prims.squeeze %551, %556 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_586 = torch.constant.int 2
    %558 = torch.prim.ListConstruct %int2_586 : (!torch.int) -> !torch.list<int>
    %559 = torch.prims.squeeze %557, %558 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %560 = torch.aten.detach %555 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %561 = torch.aten.detach %559 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %562 = torch.aten.silu %549 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_587 = torch.constant.none
    %563 = torch.aten.clone %562, %none_587 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %564 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.resnets.2.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16>
    %565 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_588 = torch.constant.int 1
    %int1_589 = torch.constant.int 1
    %566 = torch.prim.ListConstruct %int1_588, %int1_589 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_590 = torch.constant.int 1
    %int1_591 = torch.constant.int 1
    %567 = torch.prim.ListConstruct %int1_590, %int1_591 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_592 = torch.constant.int 1
    %int1_593 = torch.constant.int 1
    %568 = torch.prim.ListConstruct %int1_592, %int1_593 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_594 = torch.constant.bool false
    %int0_595 = torch.constant.int 0
    %int0_596 = torch.constant.int 0
    %569 = torch.prim.ListConstruct %int0_595, %int0_596 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_597 = torch.constant.int 1
    %570 = torch.aten.convolution %563, %564, %565, %566, %567, %568, %false_594, %569, %int1_597 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_598 = torch.constant.int 1
    %571 = torch.aten.add.Tensor %485, %570, %int1_598 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_599 = torch.constant.float 1.000000e+00
    %572 = torch.aten.div.Scalar %571, %float1.000000e00_599 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int6_600 = torch.constant.int 6
    %573 = torch.prims.convert_element_type %572, %int6_600 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int256 = torch.constant.int 256
    %int6_601 = torch.constant.int 6
    %none_602 = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_603 = torch.constant.bool false
    %574 = torch.aten.arange %int256, %int6_601, %none_602, %cpu, %false_603 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int1_604 = torch.constant.int 1
    %575 = torch.aten.add.Scalar %574, %float0.000000e00, %int1_604 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %576 = torch.aten.mul.Scalar %575, %float5.000000e-01 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4 = torch.constant.int 4
    %577 = torch.prims.convert_element_type %576, %int4 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %int-1_605 = torch.constant.int -1
    %578 = torch.aten.unsqueeze %577, %int-1_605 : !torch.vtensor<[256],si64>, !torch.int -> !torch.vtensor<[256,1],si64>
    %int256_606 = torch.constant.int 256
    %int6_607 = torch.constant.int 6
    %none_608 = torch.constant.none
    %cpu_609 = torch.constant.device "cpu"
    %false_610 = torch.constant.bool false
    %579 = torch.aten.arange %int256_606, %int6_607, %none_608, %cpu_609, %false_610 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00_611 = torch.constant.float 0.000000e+00
    %int1_612 = torch.constant.int 1
    %580 = torch.aten.add.Scalar %579, %float0.000000e00_611, %int1_612 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01_613 = torch.constant.float 5.000000e-01
    %581 = torch.aten.mul.Scalar %580, %float5.000000e-01_613 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4_614 = torch.constant.int 4
    %582 = torch.prims.convert_element_type %581, %int4_614 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %none_615 = torch.constant.none
    %none_616 = torch.constant.none
    %583 = torch.prim.ListConstruct %none_615, %none_616, %578, %582 : (!torch.none, !torch.none, !torch.vtensor<[256,1],si64>, !torch.vtensor<[256],si64>) -> !torch.list<optional<vtensor>>
    %584 = torch.aten.index.Tensor %573, %583 : !torch.vtensor<[1,512,128,128],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,256,256],f32>
    %int2_617 = torch.constant.int 2
    %585 = torch.aten.clone %584, %int2_617 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_618 = torch.constant.int 5
    %586 = torch.prims.convert_element_type %585, %int5_618 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.0.upsamplers.0.conv.weight = util.global.load @_params.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %587 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.0.upsamplers.0.conv.bias = util.global.load @_params.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16>
    %588 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_619 = torch.constant.int 1
    %int1_620 = torch.constant.int 1
    %589 = torch.prim.ListConstruct %int1_619, %int1_620 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_621 = torch.constant.int 1
    %int1_622 = torch.constant.int 1
    %590 = torch.prim.ListConstruct %int1_621, %int1_622 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_623 = torch.constant.int 1
    %int1_624 = torch.constant.int 1
    %591 = torch.prim.ListConstruct %int1_623, %int1_624 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_625 = torch.constant.bool false
    %int0_626 = torch.constant.int 0
    %int0_627 = torch.constant.int 0
    %592 = torch.prim.ListConstruct %int0_626, %int0_627 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_628 = torch.constant.int 1
    %593 = torch.aten.convolution %586, %587, %588, %589, %590, %591, %false_625, %592, %int1_628 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int2_629 = torch.constant.int 2
    %594 = torch.aten.clone %593, %int2_629 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_630 = torch.constant.int 1
    %int32_631 = torch.constant.int 32
    %int16_632 = torch.constant.int 16
    %int65536 = torch.constant.int 65536
    %595 = torch.prim.ListConstruct %int1_630, %int32_631, %int16_632, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %596 = torch.aten.view %594, %595 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_633 = torch.constant.int 6
    %597 = torch.prims.convert_element_type %596, %int6_633 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_634 = torch.constant.int 2
    %int3_635 = torch.constant.int 3
    %598 = torch.prim.ListConstruct %int2_634, %int3_635 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_636 = torch.constant.int 0
    %true_637 = torch.constant.bool true
    %result0_638, %result1_639 = torch.aten.var_mean.correction %597, %598, %int0_636, %true_637 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_640 = torch.constant.float 9.9999999999999995E-7
    %int1_641 = torch.constant.int 1
    %599 = torch.aten.add.Scalar %result0_638, %float9.999990e-07_640, %int1_641 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %600 = torch.aten.rsqrt %599 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_642 = torch.constant.int 1
    %601 = torch.aten.sub.Tensor %596, %result1_639, %int1_642 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %602 = torch.aten.mul.Tensor %601, %600 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_643 = torch.constant.int 1
    %int512_644 = torch.constant.int 512
    %int256_645 = torch.constant.int 256
    %int256_646 = torch.constant.int 256
    %603 = torch.prim.ListConstruct %int1_643, %int512_644, %int256_645, %int256_646 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %604 = torch.aten.view %602, %603 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.0.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16>
    %605 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_647 = torch.constant.int 0
    %606 = torch.aten.unsqueeze %605, %int0_647 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_648 = torch.constant.int 2
    %607 = torch.aten.unsqueeze %606, %int2_648 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_649 = torch.constant.int 3
    %608 = torch.aten.unsqueeze %607, %int3_649 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16>
    %609 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_650 = torch.constant.int 0
    %610 = torch.aten.unsqueeze %609, %int0_650 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_651 = torch.constant.int 2
    %611 = torch.aten.unsqueeze %610, %int2_651 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_652 = torch.constant.int 3
    %612 = torch.aten.unsqueeze %611, %int3_652 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %613 = torch.aten.mul.Tensor %604, %612 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_653 = torch.constant.int 1
    %614 = torch.aten.add.Tensor %613, %608, %int1_653 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_654 = torch.constant.int 5
    %615 = torch.prims.convert_element_type %614, %int5_654 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_655 = torch.constant.int 5
    %616 = torch.prims.convert_element_type %result1_639, %int5_655 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_656 = torch.constant.int 5
    %617 = torch.prims.convert_element_type %600, %int5_656 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_657 = torch.constant.int 3
    %618 = torch.prim.ListConstruct %int3_657 : (!torch.int) -> !torch.list<int>
    %619 = torch.prims.squeeze %616, %618 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_658 = torch.constant.int 2
    %620 = torch.prim.ListConstruct %int2_658 : (!torch.int) -> !torch.list<int>
    %621 = torch.prims.squeeze %619, %620 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_659 = torch.constant.int 3
    %622 = torch.prim.ListConstruct %int3_659 : (!torch.int) -> !torch.list<int>
    %623 = torch.prims.squeeze %617, %622 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_660 = torch.constant.int 2
    %624 = torch.prim.ListConstruct %int2_660 : (!torch.int) -> !torch.list<int>
    %625 = torch.prims.squeeze %623, %624 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %626 = torch.aten.detach %621 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %627 = torch.aten.detach %625 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %628 = torch.aten.silu %615 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %629 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16>
    %630 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_661 = torch.constant.int 1
    %int1_662 = torch.constant.int 1
    %631 = torch.prim.ListConstruct %int1_661, %int1_662 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_663 = torch.constant.int 1
    %int1_664 = torch.constant.int 1
    %632 = torch.prim.ListConstruct %int1_663, %int1_664 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_665 = torch.constant.int 1
    %int1_666 = torch.constant.int 1
    %633 = torch.prim.ListConstruct %int1_665, %int1_666 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_667 = torch.constant.bool false
    %int0_668 = torch.constant.int 0
    %int0_669 = torch.constant.int 0
    %634 = torch.prim.ListConstruct %int0_668, %int0_669 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_670 = torch.constant.int 1
    %635 = torch.aten.convolution %628, %629, %630, %631, %632, %633, %false_667, %634, %int1_670 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int2_671 = torch.constant.int 2
    %636 = torch.aten.clone %635, %int2_671 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_672 = torch.constant.int 1
    %int32_673 = torch.constant.int 32
    %int16_674 = torch.constant.int 16
    %int65536_675 = torch.constant.int 65536
    %637 = torch.prim.ListConstruct %int1_672, %int32_673, %int16_674, %int65536_675 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %638 = torch.aten.view %636, %637 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_676 = torch.constant.int 6
    %639 = torch.prims.convert_element_type %638, %int6_676 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_677 = torch.constant.int 2
    %int3_678 = torch.constant.int 3
    %640 = torch.prim.ListConstruct %int2_677, %int3_678 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_679 = torch.constant.int 0
    %true_680 = torch.constant.bool true
    %result0_681, %result1_682 = torch.aten.var_mean.correction %639, %640, %int0_679, %true_680 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_683 = torch.constant.float 9.9999999999999995E-7
    %int1_684 = torch.constant.int 1
    %641 = torch.aten.add.Scalar %result0_681, %float9.999990e-07_683, %int1_684 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %642 = torch.aten.rsqrt %641 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_685 = torch.constant.int 1
    %643 = torch.aten.sub.Tensor %638, %result1_682, %int1_685 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %644 = torch.aten.mul.Tensor %643, %642 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_686 = torch.constant.int 1
    %int512_687 = torch.constant.int 512
    %int256_688 = torch.constant.int 256
    %int256_689 = torch.constant.int 256
    %645 = torch.prim.ListConstruct %int1_686, %int512_687, %int256_688, %int256_689 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %646 = torch.aten.view %644, %645 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.0.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16>
    %647 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_690 = torch.constant.int 0
    %648 = torch.aten.unsqueeze %647, %int0_690 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_691 = torch.constant.int 2
    %649 = torch.aten.unsqueeze %648, %int2_691 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_692 = torch.constant.int 3
    %650 = torch.aten.unsqueeze %649, %int3_692 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16>
    %651 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_693 = torch.constant.int 0
    %652 = torch.aten.unsqueeze %651, %int0_693 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_694 = torch.constant.int 2
    %653 = torch.aten.unsqueeze %652, %int2_694 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_695 = torch.constant.int 3
    %654 = torch.aten.unsqueeze %653, %int3_695 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %655 = torch.aten.mul.Tensor %646, %654 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_696 = torch.constant.int 1
    %656 = torch.aten.add.Tensor %655, %650, %int1_696 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_697 = torch.constant.int 5
    %657 = torch.prims.convert_element_type %656, %int5_697 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_698 = torch.constant.int 5
    %658 = torch.prims.convert_element_type %result1_682, %int5_698 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_699 = torch.constant.int 5
    %659 = torch.prims.convert_element_type %642, %int5_699 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_700 = torch.constant.int 3
    %660 = torch.prim.ListConstruct %int3_700 : (!torch.int) -> !torch.list<int>
    %661 = torch.prims.squeeze %658, %660 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_701 = torch.constant.int 2
    %662 = torch.prim.ListConstruct %int2_701 : (!torch.int) -> !torch.list<int>
    %663 = torch.prims.squeeze %661, %662 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_702 = torch.constant.int 3
    %664 = torch.prim.ListConstruct %int3_702 : (!torch.int) -> !torch.list<int>
    %665 = torch.prims.squeeze %659, %664 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_703 = torch.constant.int 2
    %666 = torch.prim.ListConstruct %int2_703 : (!torch.int) -> !torch.list<int>
    %667 = torch.prims.squeeze %665, %666 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %668 = torch.aten.detach %663 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %669 = torch.aten.detach %667 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %670 = torch.aten.silu %657 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_704 = torch.constant.none
    %671 = torch.aten.clone %670, %none_704 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %672 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.0.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16>
    %673 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_705 = torch.constant.int 1
    %int1_706 = torch.constant.int 1
    %674 = torch.prim.ListConstruct %int1_705, %int1_706 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_707 = torch.constant.int 1
    %int1_708 = torch.constant.int 1
    %675 = torch.prim.ListConstruct %int1_707, %int1_708 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_709 = torch.constant.int 1
    %int1_710 = torch.constant.int 1
    %676 = torch.prim.ListConstruct %int1_709, %int1_710 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_711 = torch.constant.bool false
    %int0_712 = torch.constant.int 0
    %int0_713 = torch.constant.int 0
    %677 = torch.prim.ListConstruct %int0_712, %int0_713 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_714 = torch.constant.int 1
    %678 = torch.aten.convolution %671, %672, %673, %674, %675, %676, %false_711, %677, %int1_714 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_715 = torch.constant.int 1
    %679 = torch.aten.add.Tensor %593, %678, %int1_715 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_716 = torch.constant.float 1.000000e+00
    %680 = torch.aten.div.Scalar %679, %float1.000000e00_716 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int2_717 = torch.constant.int 2
    %681 = torch.aten.clone %680, %int2_717 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_718 = torch.constant.int 1
    %int32_719 = torch.constant.int 32
    %int16_720 = torch.constant.int 16
    %int65536_721 = torch.constant.int 65536
    %682 = torch.prim.ListConstruct %int1_718, %int32_719, %int16_720, %int65536_721 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %683 = torch.aten.view %681, %682 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_722 = torch.constant.int 6
    %684 = torch.prims.convert_element_type %683, %int6_722 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_723 = torch.constant.int 2
    %int3_724 = torch.constant.int 3
    %685 = torch.prim.ListConstruct %int2_723, %int3_724 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_725 = torch.constant.int 0
    %true_726 = torch.constant.bool true
    %result0_727, %result1_728 = torch.aten.var_mean.correction %684, %685, %int0_725, %true_726 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_729 = torch.constant.float 9.9999999999999995E-7
    %int1_730 = torch.constant.int 1
    %686 = torch.aten.add.Scalar %result0_727, %float9.999990e-07_729, %int1_730 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %687 = torch.aten.rsqrt %686 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_731 = torch.constant.int 1
    %688 = torch.aten.sub.Tensor %683, %result1_728, %int1_731 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %689 = torch.aten.mul.Tensor %688, %687 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_732 = torch.constant.int 1
    %int512_733 = torch.constant.int 512
    %int256_734 = torch.constant.int 256
    %int256_735 = torch.constant.int 256
    %690 = torch.prim.ListConstruct %int1_732, %int512_733, %int256_734, %int256_735 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %691 = torch.aten.view %689, %690 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.1.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16>
    %692 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_736 = torch.constant.int 0
    %693 = torch.aten.unsqueeze %692, %int0_736 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_737 = torch.constant.int 2
    %694 = torch.aten.unsqueeze %693, %int2_737 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_738 = torch.constant.int 3
    %695 = torch.aten.unsqueeze %694, %int3_738 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16>
    %696 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_739 = torch.constant.int 0
    %697 = torch.aten.unsqueeze %696, %int0_739 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_740 = torch.constant.int 2
    %698 = torch.aten.unsqueeze %697, %int2_740 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_741 = torch.constant.int 3
    %699 = torch.aten.unsqueeze %698, %int3_741 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %700 = torch.aten.mul.Tensor %691, %699 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_742 = torch.constant.int 1
    %701 = torch.aten.add.Tensor %700, %695, %int1_742 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_743 = torch.constant.int 5
    %702 = torch.prims.convert_element_type %701, %int5_743 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_744 = torch.constant.int 5
    %703 = torch.prims.convert_element_type %result1_728, %int5_744 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_745 = torch.constant.int 5
    %704 = torch.prims.convert_element_type %687, %int5_745 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_746 = torch.constant.int 3
    %705 = torch.prim.ListConstruct %int3_746 : (!torch.int) -> !torch.list<int>
    %706 = torch.prims.squeeze %703, %705 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_747 = torch.constant.int 2
    %707 = torch.prim.ListConstruct %int2_747 : (!torch.int) -> !torch.list<int>
    %708 = torch.prims.squeeze %706, %707 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_748 = torch.constant.int 3
    %709 = torch.prim.ListConstruct %int3_748 : (!torch.int) -> !torch.list<int>
    %710 = torch.prims.squeeze %704, %709 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_749 = torch.constant.int 2
    %711 = torch.prim.ListConstruct %int2_749 : (!torch.int) -> !torch.list<int>
    %712 = torch.prims.squeeze %710, %711 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %713 = torch.aten.detach %708 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %714 = torch.aten.detach %712 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %715 = torch.aten.silu %702 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %716 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16>
    %717 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_750 = torch.constant.int 1
    %int1_751 = torch.constant.int 1
    %718 = torch.prim.ListConstruct %int1_750, %int1_751 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_752 = torch.constant.int 1
    %int1_753 = torch.constant.int 1
    %719 = torch.prim.ListConstruct %int1_752, %int1_753 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_754 = torch.constant.int 1
    %int1_755 = torch.constant.int 1
    %720 = torch.prim.ListConstruct %int1_754, %int1_755 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_756 = torch.constant.bool false
    %int0_757 = torch.constant.int 0
    %int0_758 = torch.constant.int 0
    %721 = torch.prim.ListConstruct %int0_757, %int0_758 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_759 = torch.constant.int 1
    %722 = torch.aten.convolution %715, %716, %717, %718, %719, %720, %false_756, %721, %int1_759 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int2_760 = torch.constant.int 2
    %723 = torch.aten.clone %722, %int2_760 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_761 = torch.constant.int 1
    %int32_762 = torch.constant.int 32
    %int16_763 = torch.constant.int 16
    %int65536_764 = torch.constant.int 65536
    %724 = torch.prim.ListConstruct %int1_761, %int32_762, %int16_763, %int65536_764 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %725 = torch.aten.view %723, %724 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_765 = torch.constant.int 6
    %726 = torch.prims.convert_element_type %725, %int6_765 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_766 = torch.constant.int 2
    %int3_767 = torch.constant.int 3
    %727 = torch.prim.ListConstruct %int2_766, %int3_767 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_768 = torch.constant.int 0
    %true_769 = torch.constant.bool true
    %result0_770, %result1_771 = torch.aten.var_mean.correction %726, %727, %int0_768, %true_769 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_772 = torch.constant.float 9.9999999999999995E-7
    %int1_773 = torch.constant.int 1
    %728 = torch.aten.add.Scalar %result0_770, %float9.999990e-07_772, %int1_773 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %729 = torch.aten.rsqrt %728 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_774 = torch.constant.int 1
    %730 = torch.aten.sub.Tensor %725, %result1_771, %int1_774 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %731 = torch.aten.mul.Tensor %730, %729 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_775 = torch.constant.int 1
    %int512_776 = torch.constant.int 512
    %int256_777 = torch.constant.int 256
    %int256_778 = torch.constant.int 256
    %732 = torch.prim.ListConstruct %int1_775, %int512_776, %int256_777, %int256_778 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %733 = torch.aten.view %731, %732 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.1.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16>
    %734 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_779 = torch.constant.int 0
    %735 = torch.aten.unsqueeze %734, %int0_779 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_780 = torch.constant.int 2
    %736 = torch.aten.unsqueeze %735, %int2_780 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_781 = torch.constant.int 3
    %737 = torch.aten.unsqueeze %736, %int3_781 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16>
    %738 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_782 = torch.constant.int 0
    %739 = torch.aten.unsqueeze %738, %int0_782 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_783 = torch.constant.int 2
    %740 = torch.aten.unsqueeze %739, %int2_783 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_784 = torch.constant.int 3
    %741 = torch.aten.unsqueeze %740, %int3_784 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %742 = torch.aten.mul.Tensor %733, %741 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_785 = torch.constant.int 1
    %743 = torch.aten.add.Tensor %742, %737, %int1_785 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_786 = torch.constant.int 5
    %744 = torch.prims.convert_element_type %743, %int5_786 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_787 = torch.constant.int 5
    %745 = torch.prims.convert_element_type %result1_771, %int5_787 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_788 = torch.constant.int 5
    %746 = torch.prims.convert_element_type %729, %int5_788 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_789 = torch.constant.int 3
    %747 = torch.prim.ListConstruct %int3_789 : (!torch.int) -> !torch.list<int>
    %748 = torch.prims.squeeze %745, %747 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_790 = torch.constant.int 2
    %749 = torch.prim.ListConstruct %int2_790 : (!torch.int) -> !torch.list<int>
    %750 = torch.prims.squeeze %748, %749 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_791 = torch.constant.int 3
    %751 = torch.prim.ListConstruct %int3_791 : (!torch.int) -> !torch.list<int>
    %752 = torch.prims.squeeze %746, %751 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_792 = torch.constant.int 2
    %753 = torch.prim.ListConstruct %int2_792 : (!torch.int) -> !torch.list<int>
    %754 = torch.prims.squeeze %752, %753 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %755 = torch.aten.detach %750 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %756 = torch.aten.detach %754 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %757 = torch.aten.silu %744 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_793 = torch.constant.none
    %758 = torch.aten.clone %757, %none_793 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %759 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.1.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16>
    %760 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_794 = torch.constant.int 1
    %int1_795 = torch.constant.int 1
    %761 = torch.prim.ListConstruct %int1_794, %int1_795 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_796 = torch.constant.int 1
    %int1_797 = torch.constant.int 1
    %762 = torch.prim.ListConstruct %int1_796, %int1_797 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_798 = torch.constant.int 1
    %int1_799 = torch.constant.int 1
    %763 = torch.prim.ListConstruct %int1_798, %int1_799 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_800 = torch.constant.bool false
    %int0_801 = torch.constant.int 0
    %int0_802 = torch.constant.int 0
    %764 = torch.prim.ListConstruct %int0_801, %int0_802 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_803 = torch.constant.int 1
    %765 = torch.aten.convolution %758, %759, %760, %761, %762, %763, %false_800, %764, %int1_803 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_804 = torch.constant.int 1
    %766 = torch.aten.add.Tensor %680, %765, %int1_804 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_805 = torch.constant.float 1.000000e+00
    %767 = torch.aten.div.Scalar %766, %float1.000000e00_805 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int2_806 = torch.constant.int 2
    %768 = torch.aten.clone %767, %int2_806 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_807 = torch.constant.int 1
    %int32_808 = torch.constant.int 32
    %int16_809 = torch.constant.int 16
    %int65536_810 = torch.constant.int 65536
    %769 = torch.prim.ListConstruct %int1_807, %int32_808, %int16_809, %int65536_810 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %770 = torch.aten.view %768, %769 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_811 = torch.constant.int 6
    %771 = torch.prims.convert_element_type %770, %int6_811 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_812 = torch.constant.int 2
    %int3_813 = torch.constant.int 3
    %772 = torch.prim.ListConstruct %int2_812, %int3_813 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_814 = torch.constant.int 0
    %true_815 = torch.constant.bool true
    %result0_816, %result1_817 = torch.aten.var_mean.correction %771, %772, %int0_814, %true_815 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_818 = torch.constant.float 9.9999999999999995E-7
    %int1_819 = torch.constant.int 1
    %773 = torch.aten.add.Scalar %result0_816, %float9.999990e-07_818, %int1_819 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %774 = torch.aten.rsqrt %773 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_820 = torch.constant.int 1
    %775 = torch.aten.sub.Tensor %770, %result1_817, %int1_820 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %776 = torch.aten.mul.Tensor %775, %774 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_821 = torch.constant.int 1
    %int512_822 = torch.constant.int 512
    %int256_823 = torch.constant.int 256
    %int256_824 = torch.constant.int 256
    %777 = torch.prim.ListConstruct %int1_821, %int512_822, %int256_823, %int256_824 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %778 = torch.aten.view %776, %777 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.2.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16>
    %779 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_825 = torch.constant.int 0
    %780 = torch.aten.unsqueeze %779, %int0_825 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_826 = torch.constant.int 2
    %781 = torch.aten.unsqueeze %780, %int2_826 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_827 = torch.constant.int 3
    %782 = torch.aten.unsqueeze %781, %int3_827 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16>
    %783 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_828 = torch.constant.int 0
    %784 = torch.aten.unsqueeze %783, %int0_828 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_829 = torch.constant.int 2
    %785 = torch.aten.unsqueeze %784, %int2_829 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_830 = torch.constant.int 3
    %786 = torch.aten.unsqueeze %785, %int3_830 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %787 = torch.aten.mul.Tensor %778, %786 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_831 = torch.constant.int 1
    %788 = torch.aten.add.Tensor %787, %782, %int1_831 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_832 = torch.constant.int 5
    %789 = torch.prims.convert_element_type %788, %int5_832 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_833 = torch.constant.int 5
    %790 = torch.prims.convert_element_type %result1_817, %int5_833 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_834 = torch.constant.int 5
    %791 = torch.prims.convert_element_type %774, %int5_834 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_835 = torch.constant.int 3
    %792 = torch.prim.ListConstruct %int3_835 : (!torch.int) -> !torch.list<int>
    %793 = torch.prims.squeeze %790, %792 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_836 = torch.constant.int 2
    %794 = torch.prim.ListConstruct %int2_836 : (!torch.int) -> !torch.list<int>
    %795 = torch.prims.squeeze %793, %794 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_837 = torch.constant.int 3
    %796 = torch.prim.ListConstruct %int3_837 : (!torch.int) -> !torch.list<int>
    %797 = torch.prims.squeeze %791, %796 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_838 = torch.constant.int 2
    %798 = torch.prim.ListConstruct %int2_838 : (!torch.int) -> !torch.list<int>
    %799 = torch.prims.squeeze %797, %798 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %800 = torch.aten.detach %795 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %801 = torch.aten.detach %799 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %802 = torch.aten.silu %789 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %803 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16>
    %804 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_839 = torch.constant.int 1
    %int1_840 = torch.constant.int 1
    %805 = torch.prim.ListConstruct %int1_839, %int1_840 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_841 = torch.constant.int 1
    %int1_842 = torch.constant.int 1
    %806 = torch.prim.ListConstruct %int1_841, %int1_842 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_843 = torch.constant.int 1
    %int1_844 = torch.constant.int 1
    %807 = torch.prim.ListConstruct %int1_843, %int1_844 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_845 = torch.constant.bool false
    %int0_846 = torch.constant.int 0
    %int0_847 = torch.constant.int 0
    %808 = torch.prim.ListConstruct %int0_846, %int0_847 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_848 = torch.constant.int 1
    %809 = torch.aten.convolution %802, %803, %804, %805, %806, %807, %false_845, %808, %int1_848 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int2_849 = torch.constant.int 2
    %810 = torch.aten.clone %809, %int2_849 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_850 = torch.constant.int 1
    %int32_851 = torch.constant.int 32
    %int16_852 = torch.constant.int 16
    %int65536_853 = torch.constant.int 65536
    %811 = torch.prim.ListConstruct %int1_850, %int32_851, %int16_852, %int65536_853 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %812 = torch.aten.view %810, %811 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_854 = torch.constant.int 6
    %813 = torch.prims.convert_element_type %812, %int6_854 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_855 = torch.constant.int 2
    %int3_856 = torch.constant.int 3
    %814 = torch.prim.ListConstruct %int2_855, %int3_856 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_857 = torch.constant.int 0
    %true_858 = torch.constant.bool true
    %result0_859, %result1_860 = torch.aten.var_mean.correction %813, %814, %int0_857, %true_858 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_861 = torch.constant.float 9.9999999999999995E-7
    %int1_862 = torch.constant.int 1
    %815 = torch.aten.add.Scalar %result0_859, %float9.999990e-07_861, %int1_862 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %816 = torch.aten.rsqrt %815 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_863 = torch.constant.int 1
    %817 = torch.aten.sub.Tensor %812, %result1_860, %int1_863 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %818 = torch.aten.mul.Tensor %817, %816 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_864 = torch.constant.int 1
    %int512_865 = torch.constant.int 512
    %int256_866 = torch.constant.int 256
    %int256_867 = torch.constant.int 256
    %819 = torch.prim.ListConstruct %int1_864, %int512_865, %int256_866, %int256_867 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %820 = torch.aten.view %818, %819 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %_params.vae.decoder.up_blocks.1.resnets.2.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16>
    %821 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_868 = torch.constant.int 0
    %822 = torch.aten.unsqueeze %821, %int0_868 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_869 = torch.constant.int 2
    %823 = torch.aten.unsqueeze %822, %int2_869 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_870 = torch.constant.int 3
    %824 = torch.aten.unsqueeze %823, %int3_870 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16>
    %825 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_871 = torch.constant.int 0
    %826 = torch.aten.unsqueeze %825, %int0_871 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_872 = torch.constant.int 2
    %827 = torch.aten.unsqueeze %826, %int2_872 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_873 = torch.constant.int 3
    %828 = torch.aten.unsqueeze %827, %int3_873 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %829 = torch.aten.mul.Tensor %820, %828 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_874 = torch.constant.int 1
    %830 = torch.aten.add.Tensor %829, %824, %int1_874 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_875 = torch.constant.int 5
    %831 = torch.prims.convert_element_type %830, %int5_875 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int5_876 = torch.constant.int 5
    %832 = torch.prims.convert_element_type %result1_860, %int5_876 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_877 = torch.constant.int 5
    %833 = torch.prims.convert_element_type %816, %int5_877 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_878 = torch.constant.int 3
    %834 = torch.prim.ListConstruct %int3_878 : (!torch.int) -> !torch.list<int>
    %835 = torch.prims.squeeze %832, %834 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_879 = torch.constant.int 2
    %836 = torch.prim.ListConstruct %int2_879 : (!torch.int) -> !torch.list<int>
    %837 = torch.prims.squeeze %835, %836 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_880 = torch.constant.int 3
    %838 = torch.prim.ListConstruct %int3_880 : (!torch.int) -> !torch.list<int>
    %839 = torch.prims.squeeze %833, %838 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_881 = torch.constant.int 2
    %840 = torch.prim.ListConstruct %int2_881 : (!torch.int) -> !torch.list<int>
    %841 = torch.prims.squeeze %839, %840 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %842 = torch.aten.detach %837 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %843 = torch.aten.detach %841 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %844 = torch.aten.silu %831 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_882 = torch.constant.none
    %845 = torch.aten.clone %844, %none_882 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %846 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.resnets.2.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16>
    %847 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_883 = torch.constant.int 1
    %int1_884 = torch.constant.int 1
    %848 = torch.prim.ListConstruct %int1_883, %int1_884 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_885 = torch.constant.int 1
    %int1_886 = torch.constant.int 1
    %849 = torch.prim.ListConstruct %int1_885, %int1_886 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_887 = torch.constant.int 1
    %int1_888 = torch.constant.int 1
    %850 = torch.prim.ListConstruct %int1_887, %int1_888 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_889 = torch.constant.bool false
    %int0_890 = torch.constant.int 0
    %int0_891 = torch.constant.int 0
    %851 = torch.prim.ListConstruct %int0_890, %int0_891 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_892 = torch.constant.int 1
    %852 = torch.aten.convolution %845, %846, %847, %848, %849, %850, %false_889, %851, %int1_892 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_893 = torch.constant.int 1
    %853 = torch.aten.add.Tensor %767, %852, %int1_893 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_894 = torch.constant.float 1.000000e+00
    %854 = torch.aten.div.Scalar %853, %float1.000000e00_894 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int6_895 = torch.constant.int 6
    %855 = torch.prims.convert_element_type %854, %int6_895 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int512_896 = torch.constant.int 512
    %int6_897 = torch.constant.int 6
    %none_898 = torch.constant.none
    %cpu_899 = torch.constant.device "cpu"
    %false_900 = torch.constant.bool false
    %856 = torch.aten.arange %int512_896, %int6_897, %none_898, %cpu_899, %false_900 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_901 = torch.constant.float 0.000000e+00
    %int1_902 = torch.constant.int 1
    %857 = torch.aten.add.Scalar %856, %float0.000000e00_901, %int1_902 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_903 = torch.constant.float 5.000000e-01
    %858 = torch.aten.mul.Scalar %857, %float5.000000e-01_903 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_904 = torch.constant.int 4
    %859 = torch.prims.convert_element_type %858, %int4_904 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %int-1_905 = torch.constant.int -1
    %860 = torch.aten.unsqueeze %859, %int-1_905 : !torch.vtensor<[512],si64>, !torch.int -> !torch.vtensor<[512,1],si64>
    %int512_906 = torch.constant.int 512
    %int6_907 = torch.constant.int 6
    %none_908 = torch.constant.none
    %cpu_909 = torch.constant.device "cpu"
    %false_910 = torch.constant.bool false
    %861 = torch.aten.arange %int512_906, %int6_907, %none_908, %cpu_909, %false_910 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_911 = torch.constant.float 0.000000e+00
    %int1_912 = torch.constant.int 1
    %862 = torch.aten.add.Scalar %861, %float0.000000e00_911, %int1_912 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_913 = torch.constant.float 5.000000e-01
    %863 = torch.aten.mul.Scalar %862, %float5.000000e-01_913 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_914 = torch.constant.int 4
    %864 = torch.prims.convert_element_type %863, %int4_914 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %none_915 = torch.constant.none
    %none_916 = torch.constant.none
    %865 = torch.prim.ListConstruct %none_915, %none_916, %860, %864 : (!torch.none, !torch.none, !torch.vtensor<[512,1],si64>, !torch.vtensor<[512],si64>) -> !torch.list<optional<vtensor>>
    %866 = torch.aten.index.Tensor %855, %865 : !torch.vtensor<[1,512,256,256],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,512,512],f32>
    %int2_917 = torch.constant.int 2
    %867 = torch.aten.clone %866, %int2_917 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_918 = torch.constant.int 5
    %868 = torch.prims.convert_element_type %867, %int5_918 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %_params.vae.decoder.up_blocks.1.upsamplers.0.conv.weight = util.global.load @_params.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %869 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %_params.vae.decoder.up_blocks.1.upsamplers.0.conv.bias = util.global.load @_params.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16>
    %870 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_919 = torch.constant.int 1
    %int1_920 = torch.constant.int 1
    %871 = torch.prim.ListConstruct %int1_919, %int1_920 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_921 = torch.constant.int 1
    %int1_922 = torch.constant.int 1
    %872 = torch.prim.ListConstruct %int1_921, %int1_922 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_923 = torch.constant.int 1
    %int1_924 = torch.constant.int 1
    %873 = torch.prim.ListConstruct %int1_923, %int1_924 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_925 = torch.constant.bool false
    %int0_926 = torch.constant.int 0
    %int0_927 = torch.constant.int 0
    %874 = torch.prim.ListConstruct %int0_926, %int0_927 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_928 = torch.constant.int 1
    %875 = torch.aten.convolution %868, %869, %870, %871, %872, %873, %false_925, %874, %int1_928 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %int2_929 = torch.constant.int 2
    %876 = torch.aten.clone %875, %int2_929 : !torch.vtensor<[1,512,512,512],f16>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %int1_930 = torch.constant.int 1
    %int32_931 = torch.constant.int 32
    %int16_932 = torch.constant.int 16
    %int262144 = torch.constant.int 262144
    %877 = torch.prim.ListConstruct %int1_930, %int32_931, %int16_932, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %878 = torch.aten.view %876, %877 : !torch.vtensor<[1,512,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,262144],f16>
    %int6_933 = torch.constant.int 6
    %879 = torch.prims.convert_element_type %878, %int6_933 : !torch.vtensor<[1,32,16,262144],f16>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %int2_934 = torch.constant.int 2
    %int3_935 = torch.constant.int 3
    %880 = torch.prim.ListConstruct %int2_934, %int3_935 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_936 = torch.constant.int 0
    %true_937 = torch.constant.bool true
    %result0_938, %result1_939 = torch.aten.var_mean.correction %879, %880, %int0_936, %true_937 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_940 = torch.constant.float 9.9999999999999995E-7
    %int1_941 = torch.constant.int 1
    %881 = torch.aten.add.Scalar %result0_938, %float9.999990e-07_940, %int1_941 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %882 = torch.aten.rsqrt %881 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_942 = torch.constant.int 1
    %883 = torch.aten.sub.Tensor %878, %result1_939, %int1_942 : !torch.vtensor<[1,32,16,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %884 = torch.aten.mul.Tensor %883, %882 : !torch.vtensor<[1,32,16,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,262144],f32>
    %int1_943 = torch.constant.int 1
    %int512_944 = torch.constant.int 512
    %int512_945 = torch.constant.int 512
    %int512_946 = torch.constant.int 512
    %885 = torch.prim.ListConstruct %int1_943, %int512_944, %int512_945, %int512_946 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %886 = torch.aten.view %884, %885 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,512,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.0.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16>
    %887 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_947 = torch.constant.int 0
    %888 = torch.aten.unsqueeze %887, %int0_947 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_948 = torch.constant.int 2
    %889 = torch.aten.unsqueeze %888, %int2_948 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_949 = torch.constant.int 3
    %890 = torch.aten.unsqueeze %889, %int3_949 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16>
    %891 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_950 = torch.constant.int 0
    %892 = torch.aten.unsqueeze %891, %int0_950 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_951 = torch.constant.int 2
    %893 = torch.aten.unsqueeze %892, %int2_951 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_952 = torch.constant.int 3
    %894 = torch.aten.unsqueeze %893, %int3_952 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %895 = torch.aten.mul.Tensor %886, %894 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,512,512],f32>
    %int1_953 = torch.constant.int 1
    %896 = torch.aten.add.Tensor %895, %890, %int1_953 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_954 = torch.constant.int 5
    %897 = torch.prims.convert_element_type %896, %int5_954 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %int5_955 = torch.constant.int 5
    %898 = torch.prims.convert_element_type %result1_939, %int5_955 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_956 = torch.constant.int 5
    %899 = torch.prims.convert_element_type %882, %int5_956 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_957 = torch.constant.int 3
    %900 = torch.prim.ListConstruct %int3_957 : (!torch.int) -> !torch.list<int>
    %901 = torch.prims.squeeze %898, %900 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_958 = torch.constant.int 2
    %902 = torch.prim.ListConstruct %int2_958 : (!torch.int) -> !torch.list<int>
    %903 = torch.prims.squeeze %901, %902 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_959 = torch.constant.int 3
    %904 = torch.prim.ListConstruct %int3_959 : (!torch.int) -> !torch.list<int>
    %905 = torch.prims.squeeze %899, %904 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_960 = torch.constant.int 2
    %906 = torch.prim.ListConstruct %int2_960 : (!torch.int) -> !torch.list<int>
    %907 = torch.prims.squeeze %905, %906 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %908 = torch.aten.detach %903 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %909 = torch.aten.detach %907 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %910 = torch.aten.silu %897 : !torch.vtensor<[1,512,512,512],f16> -> !torch.vtensor<[1,512,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16>
    %911 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16> -> !torch.vtensor<[256,512,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16>
    %912 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_961 = torch.constant.int 1
    %int1_962 = torch.constant.int 1
    %913 = torch.prim.ListConstruct %int1_961, %int1_962 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_963 = torch.constant.int 1
    %int1_964 = torch.constant.int 1
    %914 = torch.prim.ListConstruct %int1_963, %int1_964 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_965 = torch.constant.int 1
    %int1_966 = torch.constant.int 1
    %915 = torch.prim.ListConstruct %int1_965, %int1_966 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_967 = torch.constant.bool false
    %int0_968 = torch.constant.int 0
    %int0_969 = torch.constant.int 0
    %916 = torch.prim.ListConstruct %int0_968, %int0_969 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_970 = torch.constant.int 1
    %917 = torch.aten.convolution %910, %911, %912, %913, %914, %915, %false_967, %916, %int1_970 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int2_971 = torch.constant.int 2
    %918 = torch.aten.clone %917, %int2_971 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_972 = torch.constant.int 1
    %int32_973 = torch.constant.int 32
    %int8 = torch.constant.int 8
    %int262144_974 = torch.constant.int 262144
    %919 = torch.prim.ListConstruct %int1_972, %int32_973, %int8, %int262144_974 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %920 = torch.aten.view %918, %919 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_975 = torch.constant.int 6
    %921 = torch.prims.convert_element_type %920, %int6_975 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_976 = torch.constant.int 2
    %int3_977 = torch.constant.int 3
    %922 = torch.prim.ListConstruct %int2_976, %int3_977 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_978 = torch.constant.int 0
    %true_979 = torch.constant.bool true
    %result0_980, %result1_981 = torch.aten.var_mean.correction %921, %922, %int0_978, %true_979 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_982 = torch.constant.float 9.9999999999999995E-7
    %int1_983 = torch.constant.int 1
    %923 = torch.aten.add.Scalar %result0_980, %float9.999990e-07_982, %int1_983 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %924 = torch.aten.rsqrt %923 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_984 = torch.constant.int 1
    %925 = torch.aten.sub.Tensor %920, %result1_981, %int1_984 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %926 = torch.aten.mul.Tensor %925, %924 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_985 = torch.constant.int 1
    %int256_986 = torch.constant.int 256
    %int512_987 = torch.constant.int 512
    %int512_988 = torch.constant.int 512
    %927 = torch.prim.ListConstruct %int1_985, %int256_986, %int512_987, %int512_988 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %928 = torch.aten.view %926, %927 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.0.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16>
    %929 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_989 = torch.constant.int 0
    %930 = torch.aten.unsqueeze %929, %int0_989 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_990 = torch.constant.int 2
    %931 = torch.aten.unsqueeze %930, %int2_990 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_991 = torch.constant.int 3
    %932 = torch.aten.unsqueeze %931, %int3_991 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16>
    %933 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_992 = torch.constant.int 0
    %934 = torch.aten.unsqueeze %933, %int0_992 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_993 = torch.constant.int 2
    %935 = torch.aten.unsqueeze %934, %int2_993 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_994 = torch.constant.int 3
    %936 = torch.aten.unsqueeze %935, %int3_994 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %937 = torch.aten.mul.Tensor %928, %936 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_995 = torch.constant.int 1
    %938 = torch.aten.add.Tensor %937, %932, %int1_995 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_996 = torch.constant.int 5
    %939 = torch.prims.convert_element_type %938, %int5_996 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int5_997 = torch.constant.int 5
    %940 = torch.prims.convert_element_type %result1_981, %int5_997 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_998 = torch.constant.int 5
    %941 = torch.prims.convert_element_type %924, %int5_998 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_999 = torch.constant.int 3
    %942 = torch.prim.ListConstruct %int3_999 : (!torch.int) -> !torch.list<int>
    %943 = torch.prims.squeeze %940, %942 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1000 = torch.constant.int 2
    %944 = torch.prim.ListConstruct %int2_1000 : (!torch.int) -> !torch.list<int>
    %945 = torch.prims.squeeze %943, %944 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1001 = torch.constant.int 3
    %946 = torch.prim.ListConstruct %int3_1001 : (!torch.int) -> !torch.list<int>
    %947 = torch.prims.squeeze %941, %946 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1002 = torch.constant.int 2
    %948 = torch.prim.ListConstruct %int2_1002 : (!torch.int) -> !torch.list<int>
    %949 = torch.prims.squeeze %947, %948 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %950 = torch.aten.detach %945 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %951 = torch.aten.detach %949 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %952 = torch.aten.silu %939 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_1003 = torch.constant.none
    %953 = torch.aten.clone %952, %none_1003 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %954 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16>
    %955 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1004 = torch.constant.int 1
    %int1_1005 = torch.constant.int 1
    %956 = torch.prim.ListConstruct %int1_1004, %int1_1005 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1006 = torch.constant.int 1
    %int1_1007 = torch.constant.int 1
    %957 = torch.prim.ListConstruct %int1_1006, %int1_1007 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1008 = torch.constant.int 1
    %int1_1009 = torch.constant.int 1
    %958 = torch.prim.ListConstruct %int1_1008, %int1_1009 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1010 = torch.constant.bool false
    %int0_1011 = torch.constant.int 0
    %int0_1012 = torch.constant.int 0
    %959 = torch.prim.ListConstruct %int0_1011, %int0_1012 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1013 = torch.constant.int 1
    %960 = torch.aten.convolution %953, %954, %955, %956, %957, %958, %false_1010, %959, %int1_1013 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16>
    %961 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16> -> !torch.vtensor<[256,512,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %962 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1014 = torch.constant.int 1
    %int1_1015 = torch.constant.int 1
    %963 = torch.prim.ListConstruct %int1_1014, %int1_1015 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1016 = torch.constant.int 0
    %int0_1017 = torch.constant.int 0
    %964 = torch.prim.ListConstruct %int0_1016, %int0_1017 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1018 = torch.constant.int 1
    %int1_1019 = torch.constant.int 1
    %965 = torch.prim.ListConstruct %int1_1018, %int1_1019 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1020 = torch.constant.bool false
    %int0_1021 = torch.constant.int 0
    %int0_1022 = torch.constant.int 0
    %966 = torch.prim.ListConstruct %int0_1021, %int0_1022 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1023 = torch.constant.int 1
    %967 = torch.aten.convolution %875, %961, %962, %963, %964, %965, %false_1020, %966, %int1_1023 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1024 = torch.constant.int 1
    %968 = torch.aten.add.Tensor %967, %960, %int1_1024 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_1025 = torch.constant.float 1.000000e+00
    %969 = torch.aten.div.Scalar %968, %float1.000000e00_1025 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int2_1026 = torch.constant.int 2
    %970 = torch.aten.clone %969, %int2_1026 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1027 = torch.constant.int 1
    %int32_1028 = torch.constant.int 32
    %int8_1029 = torch.constant.int 8
    %int262144_1030 = torch.constant.int 262144
    %971 = torch.prim.ListConstruct %int1_1027, %int32_1028, %int8_1029, %int262144_1030 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %972 = torch.aten.view %970, %971 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1031 = torch.constant.int 6
    %973 = torch.prims.convert_element_type %972, %int6_1031 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1032 = torch.constant.int 2
    %int3_1033 = torch.constant.int 3
    %974 = torch.prim.ListConstruct %int2_1032, %int3_1033 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1034 = torch.constant.int 0
    %true_1035 = torch.constant.bool true
    %result0_1036, %result1_1037 = torch.aten.var_mean.correction %973, %974, %int0_1034, %true_1035 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1038 = torch.constant.float 9.9999999999999995E-7
    %int1_1039 = torch.constant.int 1
    %975 = torch.aten.add.Scalar %result0_1036, %float9.999990e-07_1038, %int1_1039 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %976 = torch.aten.rsqrt %975 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1040 = torch.constant.int 1
    %977 = torch.aten.sub.Tensor %972, %result1_1037, %int1_1040 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %978 = torch.aten.mul.Tensor %977, %976 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1041 = torch.constant.int 1
    %int256_1042 = torch.constant.int 256
    %int512_1043 = torch.constant.int 512
    %int512_1044 = torch.constant.int 512
    %979 = torch.prim.ListConstruct %int1_1041, %int256_1042, %int512_1043, %int512_1044 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %980 = torch.aten.view %978, %979 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.1.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16>
    %981 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1045 = torch.constant.int 0
    %982 = torch.aten.unsqueeze %981, %int0_1045 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1046 = torch.constant.int 2
    %983 = torch.aten.unsqueeze %982, %int2_1046 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1047 = torch.constant.int 3
    %984 = torch.aten.unsqueeze %983, %int3_1047 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16>
    %985 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1048 = torch.constant.int 0
    %986 = torch.aten.unsqueeze %985, %int0_1048 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1049 = torch.constant.int 2
    %987 = torch.aten.unsqueeze %986, %int2_1049 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1050 = torch.constant.int 3
    %988 = torch.aten.unsqueeze %987, %int3_1050 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %989 = torch.aten.mul.Tensor %980, %988 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1051 = torch.constant.int 1
    %990 = torch.aten.add.Tensor %989, %984, %int1_1051 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1052 = torch.constant.int 5
    %991 = torch.prims.convert_element_type %990, %int5_1052 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int5_1053 = torch.constant.int 5
    %992 = torch.prims.convert_element_type %result1_1037, %int5_1053 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1054 = torch.constant.int 5
    %993 = torch.prims.convert_element_type %976, %int5_1054 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1055 = torch.constant.int 3
    %994 = torch.prim.ListConstruct %int3_1055 : (!torch.int) -> !torch.list<int>
    %995 = torch.prims.squeeze %992, %994 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1056 = torch.constant.int 2
    %996 = torch.prim.ListConstruct %int2_1056 : (!torch.int) -> !torch.list<int>
    %997 = torch.prims.squeeze %995, %996 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1057 = torch.constant.int 3
    %998 = torch.prim.ListConstruct %int3_1057 : (!torch.int) -> !torch.list<int>
    %999 = torch.prims.squeeze %993, %998 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1058 = torch.constant.int 2
    %1000 = torch.prim.ListConstruct %int2_1058 : (!torch.int) -> !torch.list<int>
    %1001 = torch.prims.squeeze %999, %1000 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1002 = torch.aten.detach %997 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1003 = torch.aten.detach %1001 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1004 = torch.aten.silu %991 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %1005 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16>
    %1006 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1059 = torch.constant.int 1
    %int1_1060 = torch.constant.int 1
    %1007 = torch.prim.ListConstruct %int1_1059, %int1_1060 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1061 = torch.constant.int 1
    %int1_1062 = torch.constant.int 1
    %1008 = torch.prim.ListConstruct %int1_1061, %int1_1062 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1063 = torch.constant.int 1
    %int1_1064 = torch.constant.int 1
    %1009 = torch.prim.ListConstruct %int1_1063, %int1_1064 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1065 = torch.constant.bool false
    %int0_1066 = torch.constant.int 0
    %int0_1067 = torch.constant.int 0
    %1010 = torch.prim.ListConstruct %int0_1066, %int0_1067 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1068 = torch.constant.int 1
    %1011 = torch.aten.convolution %1004, %1005, %1006, %1007, %1008, %1009, %false_1065, %1010, %int1_1068 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int2_1069 = torch.constant.int 2
    %1012 = torch.aten.clone %1011, %int2_1069 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1070 = torch.constant.int 1
    %int32_1071 = torch.constant.int 32
    %int8_1072 = torch.constant.int 8
    %int262144_1073 = torch.constant.int 262144
    %1013 = torch.prim.ListConstruct %int1_1070, %int32_1071, %int8_1072, %int262144_1073 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1014 = torch.aten.view %1012, %1013 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1074 = torch.constant.int 6
    %1015 = torch.prims.convert_element_type %1014, %int6_1074 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1075 = torch.constant.int 2
    %int3_1076 = torch.constant.int 3
    %1016 = torch.prim.ListConstruct %int2_1075, %int3_1076 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1077 = torch.constant.int 0
    %true_1078 = torch.constant.bool true
    %result0_1079, %result1_1080 = torch.aten.var_mean.correction %1015, %1016, %int0_1077, %true_1078 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1081 = torch.constant.float 9.9999999999999995E-7
    %int1_1082 = torch.constant.int 1
    %1017 = torch.aten.add.Scalar %result0_1079, %float9.999990e-07_1081, %int1_1082 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1018 = torch.aten.rsqrt %1017 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1083 = torch.constant.int 1
    %1019 = torch.aten.sub.Tensor %1014, %result1_1080, %int1_1083 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %1020 = torch.aten.mul.Tensor %1019, %1018 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1084 = torch.constant.int 1
    %int256_1085 = torch.constant.int 256
    %int512_1086 = torch.constant.int 512
    %int512_1087 = torch.constant.int 512
    %1021 = torch.prim.ListConstruct %int1_1084, %int256_1085, %int512_1086, %int512_1087 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1022 = torch.aten.view %1020, %1021 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.1.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16>
    %1023 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1088 = torch.constant.int 0
    %1024 = torch.aten.unsqueeze %1023, %int0_1088 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1089 = torch.constant.int 2
    %1025 = torch.aten.unsqueeze %1024, %int2_1089 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1090 = torch.constant.int 3
    %1026 = torch.aten.unsqueeze %1025, %int3_1090 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16>
    %1027 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1091 = torch.constant.int 0
    %1028 = torch.aten.unsqueeze %1027, %int0_1091 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1092 = torch.constant.int 2
    %1029 = torch.aten.unsqueeze %1028, %int2_1092 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1093 = torch.constant.int 3
    %1030 = torch.aten.unsqueeze %1029, %int3_1093 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %1031 = torch.aten.mul.Tensor %1022, %1030 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1094 = torch.constant.int 1
    %1032 = torch.aten.add.Tensor %1031, %1026, %int1_1094 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1095 = torch.constant.int 5
    %1033 = torch.prims.convert_element_type %1032, %int5_1095 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int5_1096 = torch.constant.int 5
    %1034 = torch.prims.convert_element_type %result1_1080, %int5_1096 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1097 = torch.constant.int 5
    %1035 = torch.prims.convert_element_type %1018, %int5_1097 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1098 = torch.constant.int 3
    %1036 = torch.prim.ListConstruct %int3_1098 : (!torch.int) -> !torch.list<int>
    %1037 = torch.prims.squeeze %1034, %1036 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1099 = torch.constant.int 2
    %1038 = torch.prim.ListConstruct %int2_1099 : (!torch.int) -> !torch.list<int>
    %1039 = torch.prims.squeeze %1037, %1038 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1100 = torch.constant.int 3
    %1040 = torch.prim.ListConstruct %int3_1100 : (!torch.int) -> !torch.list<int>
    %1041 = torch.prims.squeeze %1035, %1040 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1101 = torch.constant.int 2
    %1042 = torch.prim.ListConstruct %int2_1101 : (!torch.int) -> !torch.list<int>
    %1043 = torch.prims.squeeze %1041, %1042 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1044 = torch.aten.detach %1039 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1045 = torch.aten.detach %1043 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1046 = torch.aten.silu %1033 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_1102 = torch.constant.none
    %1047 = torch.aten.clone %1046, %none_1102 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %1048 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.1.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16>
    %1049 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1103 = torch.constant.int 1
    %int1_1104 = torch.constant.int 1
    %1050 = torch.prim.ListConstruct %int1_1103, %int1_1104 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1105 = torch.constant.int 1
    %int1_1106 = torch.constant.int 1
    %1051 = torch.prim.ListConstruct %int1_1105, %int1_1106 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1107 = torch.constant.int 1
    %int1_1108 = torch.constant.int 1
    %1052 = torch.prim.ListConstruct %int1_1107, %int1_1108 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1109 = torch.constant.bool false
    %int0_1110 = torch.constant.int 0
    %int0_1111 = torch.constant.int 0
    %1053 = torch.prim.ListConstruct %int0_1110, %int0_1111 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1112 = torch.constant.int 1
    %1054 = torch.aten.convolution %1047, %1048, %1049, %1050, %1051, %1052, %false_1109, %1053, %int1_1112 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1113 = torch.constant.int 1
    %1055 = torch.aten.add.Tensor %969, %1054, %int1_1113 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_1114 = torch.constant.float 1.000000e+00
    %1056 = torch.aten.div.Scalar %1055, %float1.000000e00_1114 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int2_1115 = torch.constant.int 2
    %1057 = torch.aten.clone %1056, %int2_1115 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1116 = torch.constant.int 1
    %int32_1117 = torch.constant.int 32
    %int8_1118 = torch.constant.int 8
    %int262144_1119 = torch.constant.int 262144
    %1058 = torch.prim.ListConstruct %int1_1116, %int32_1117, %int8_1118, %int262144_1119 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1059 = torch.aten.view %1057, %1058 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1120 = torch.constant.int 6
    %1060 = torch.prims.convert_element_type %1059, %int6_1120 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1121 = torch.constant.int 2
    %int3_1122 = torch.constant.int 3
    %1061 = torch.prim.ListConstruct %int2_1121, %int3_1122 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1123 = torch.constant.int 0
    %true_1124 = torch.constant.bool true
    %result0_1125, %result1_1126 = torch.aten.var_mean.correction %1060, %1061, %int0_1123, %true_1124 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1127 = torch.constant.float 9.9999999999999995E-7
    %int1_1128 = torch.constant.int 1
    %1062 = torch.aten.add.Scalar %result0_1125, %float9.999990e-07_1127, %int1_1128 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1063 = torch.aten.rsqrt %1062 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1129 = torch.constant.int 1
    %1064 = torch.aten.sub.Tensor %1059, %result1_1126, %int1_1129 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %1065 = torch.aten.mul.Tensor %1064, %1063 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1130 = torch.constant.int 1
    %int256_1131 = torch.constant.int 256
    %int512_1132 = torch.constant.int 512
    %int512_1133 = torch.constant.int 512
    %1066 = torch.prim.ListConstruct %int1_1130, %int256_1131, %int512_1132, %int512_1133 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1067 = torch.aten.view %1065, %1066 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.2.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16>
    %1068 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1134 = torch.constant.int 0
    %1069 = torch.aten.unsqueeze %1068, %int0_1134 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1135 = torch.constant.int 2
    %1070 = torch.aten.unsqueeze %1069, %int2_1135 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1136 = torch.constant.int 3
    %1071 = torch.aten.unsqueeze %1070, %int3_1136 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16>
    %1072 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1137 = torch.constant.int 0
    %1073 = torch.aten.unsqueeze %1072, %int0_1137 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1138 = torch.constant.int 2
    %1074 = torch.aten.unsqueeze %1073, %int2_1138 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1139 = torch.constant.int 3
    %1075 = torch.aten.unsqueeze %1074, %int3_1139 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %1076 = torch.aten.mul.Tensor %1067, %1075 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1140 = torch.constant.int 1
    %1077 = torch.aten.add.Tensor %1076, %1071, %int1_1140 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1141 = torch.constant.int 5
    %1078 = torch.prims.convert_element_type %1077, %int5_1141 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int5_1142 = torch.constant.int 5
    %1079 = torch.prims.convert_element_type %result1_1126, %int5_1142 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1143 = torch.constant.int 5
    %1080 = torch.prims.convert_element_type %1063, %int5_1143 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1144 = torch.constant.int 3
    %1081 = torch.prim.ListConstruct %int3_1144 : (!torch.int) -> !torch.list<int>
    %1082 = torch.prims.squeeze %1079, %1081 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1145 = torch.constant.int 2
    %1083 = torch.prim.ListConstruct %int2_1145 : (!torch.int) -> !torch.list<int>
    %1084 = torch.prims.squeeze %1082, %1083 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1146 = torch.constant.int 3
    %1085 = torch.prim.ListConstruct %int3_1146 : (!torch.int) -> !torch.list<int>
    %1086 = torch.prims.squeeze %1080, %1085 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1147 = torch.constant.int 2
    %1087 = torch.prim.ListConstruct %int2_1147 : (!torch.int) -> !torch.list<int>
    %1088 = torch.prims.squeeze %1086, %1087 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1089 = torch.aten.detach %1084 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1090 = torch.aten.detach %1088 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1091 = torch.aten.silu %1078 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16>
    %1092 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16>
    %1093 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1148 = torch.constant.int 1
    %int1_1149 = torch.constant.int 1
    %1094 = torch.prim.ListConstruct %int1_1148, %int1_1149 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1150 = torch.constant.int 1
    %int1_1151 = torch.constant.int 1
    %1095 = torch.prim.ListConstruct %int1_1150, %int1_1151 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1152 = torch.constant.int 1
    %int1_1153 = torch.constant.int 1
    %1096 = torch.prim.ListConstruct %int1_1152, %int1_1153 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1154 = torch.constant.bool false
    %int0_1155 = torch.constant.int 0
    %int0_1156 = torch.constant.int 0
    %1097 = torch.prim.ListConstruct %int0_1155, %int0_1156 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1157 = torch.constant.int 1
    %1098 = torch.aten.convolution %1091, %1092, %1093, %1094, %1095, %1096, %false_1154, %1097, %int1_1157 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int2_1158 = torch.constant.int 2
    %1099 = torch.aten.clone %1098, %int2_1158 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1159 = torch.constant.int 1
    %int32_1160 = torch.constant.int 32
    %int8_1161 = torch.constant.int 8
    %int262144_1162 = torch.constant.int 262144
    %1100 = torch.prim.ListConstruct %int1_1159, %int32_1160, %int8_1161, %int262144_1162 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1101 = torch.aten.view %1099, %1100 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1163 = torch.constant.int 6
    %1102 = torch.prims.convert_element_type %1101, %int6_1163 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1164 = torch.constant.int 2
    %int3_1165 = torch.constant.int 3
    %1103 = torch.prim.ListConstruct %int2_1164, %int3_1165 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1166 = torch.constant.int 0
    %true_1167 = torch.constant.bool true
    %result0_1168, %result1_1169 = torch.aten.var_mean.correction %1102, %1103, %int0_1166, %true_1167 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1170 = torch.constant.float 9.9999999999999995E-7
    %int1_1171 = torch.constant.int 1
    %1104 = torch.aten.add.Scalar %result0_1168, %float9.999990e-07_1170, %int1_1171 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1105 = torch.aten.rsqrt %1104 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1172 = torch.constant.int 1
    %1106 = torch.aten.sub.Tensor %1101, %result1_1169, %int1_1172 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %1107 = torch.aten.mul.Tensor %1106, %1105 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1173 = torch.constant.int 1
    %int256_1174 = torch.constant.int 256
    %int512_1175 = torch.constant.int 512
    %int512_1176 = torch.constant.int 512
    %1108 = torch.prim.ListConstruct %int1_1173, %int256_1174, %int512_1175, %int512_1176 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1109 = torch.aten.view %1107, %1108 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %_params.vae.decoder.up_blocks.2.resnets.2.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16>
    %1110 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1177 = torch.constant.int 0
    %1111 = torch.aten.unsqueeze %1110, %int0_1177 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1178 = torch.constant.int 2
    %1112 = torch.aten.unsqueeze %1111, %int2_1178 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1179 = torch.constant.int 3
    %1113 = torch.aten.unsqueeze %1112, %int3_1179 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16>
    %1114 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1180 = torch.constant.int 0
    %1115 = torch.aten.unsqueeze %1114, %int0_1180 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1181 = torch.constant.int 2
    %1116 = torch.aten.unsqueeze %1115, %int2_1181 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1182 = torch.constant.int 3
    %1117 = torch.aten.unsqueeze %1116, %int3_1182 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %1118 = torch.aten.mul.Tensor %1109, %1117 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1183 = torch.constant.int 1
    %1119 = torch.aten.add.Tensor %1118, %1113, %int1_1183 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1184 = torch.constant.int 5
    %1120 = torch.prims.convert_element_type %1119, %int5_1184 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int5_1185 = torch.constant.int 5
    %1121 = torch.prims.convert_element_type %result1_1169, %int5_1185 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1186 = torch.constant.int 5
    %1122 = torch.prims.convert_element_type %1105, %int5_1186 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1187 = torch.constant.int 3
    %1123 = torch.prim.ListConstruct %int3_1187 : (!torch.int) -> !torch.list<int>
    %1124 = torch.prims.squeeze %1121, %1123 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1188 = torch.constant.int 2
    %1125 = torch.prim.ListConstruct %int2_1188 : (!torch.int) -> !torch.list<int>
    %1126 = torch.prims.squeeze %1124, %1125 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1189 = torch.constant.int 3
    %1127 = torch.prim.ListConstruct %int3_1189 : (!torch.int) -> !torch.list<int>
    %1128 = torch.prims.squeeze %1122, %1127 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1190 = torch.constant.int 2
    %1129 = torch.prim.ListConstruct %int2_1190 : (!torch.int) -> !torch.list<int>
    %1130 = torch.prims.squeeze %1128, %1129 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1131 = torch.aten.detach %1126 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1132 = torch.aten.detach %1130 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1133 = torch.aten.silu %1120 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_1191 = torch.constant.none
    %1134 = torch.aten.clone %1133, %none_1191 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16>
    %1135 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.resnets.2.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16>
    %1136 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1192 = torch.constant.int 1
    %int1_1193 = torch.constant.int 1
    %1137 = torch.prim.ListConstruct %int1_1192, %int1_1193 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1194 = torch.constant.int 1
    %int1_1195 = torch.constant.int 1
    %1138 = torch.prim.ListConstruct %int1_1194, %int1_1195 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1196 = torch.constant.int 1
    %int1_1197 = torch.constant.int 1
    %1139 = torch.prim.ListConstruct %int1_1196, %int1_1197 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1198 = torch.constant.bool false
    %int0_1199 = torch.constant.int 0
    %int0_1200 = torch.constant.int 0
    %1140 = torch.prim.ListConstruct %int0_1199, %int0_1200 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1201 = torch.constant.int 1
    %1141 = torch.aten.convolution %1134, %1135, %1136, %1137, %1138, %1139, %false_1198, %1140, %int1_1201 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1202 = torch.constant.int 1
    %1142 = torch.aten.add.Tensor %1056, %1141, %int1_1202 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_1203 = torch.constant.float 1.000000e+00
    %1143 = torch.aten.div.Scalar %1142, %float1.000000e00_1203 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int6_1204 = torch.constant.int 6
    %1144 = torch.prims.convert_element_type %1143, %int6_1204 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int1024 = torch.constant.int 1024
    %int6_1205 = torch.constant.int 6
    %none_1206 = torch.constant.none
    %cpu_1207 = torch.constant.device "cpu"
    %false_1208 = torch.constant.bool false
    %1145 = torch.aten.arange %int1024, %int6_1205, %none_1206, %cpu_1207, %false_1208 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1209 = torch.constant.float 0.000000e+00
    %int1_1210 = torch.constant.int 1
    %1146 = torch.aten.add.Scalar %1145, %float0.000000e00_1209, %int1_1210 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1211 = torch.constant.float 5.000000e-01
    %1147 = torch.aten.mul.Scalar %1146, %float5.000000e-01_1211 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1212 = torch.constant.int 4
    %1148 = torch.prims.convert_element_type %1147, %int4_1212 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %int-1_1213 = torch.constant.int -1
    %1149 = torch.aten.unsqueeze %1148, %int-1_1213 : !torch.vtensor<[1024],si64>, !torch.int -> !torch.vtensor<[1024,1],si64>
    %int1024_1214 = torch.constant.int 1024
    %int6_1215 = torch.constant.int 6
    %none_1216 = torch.constant.none
    %cpu_1217 = torch.constant.device "cpu"
    %false_1218 = torch.constant.bool false
    %1150 = torch.aten.arange %int1024_1214, %int6_1215, %none_1216, %cpu_1217, %false_1218 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1219 = torch.constant.float 0.000000e+00
    %int1_1220 = torch.constant.int 1
    %1151 = torch.aten.add.Scalar %1150, %float0.000000e00_1219, %int1_1220 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1221 = torch.constant.float 5.000000e-01
    %1152 = torch.aten.mul.Scalar %1151, %float5.000000e-01_1221 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1222 = torch.constant.int 4
    %1153 = torch.prims.convert_element_type %1152, %int4_1222 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %none_1223 = torch.constant.none
    %none_1224 = torch.constant.none
    %1154 = torch.prim.ListConstruct %none_1223, %none_1224, %1149, %1153 : (!torch.none, !torch.none, !torch.vtensor<[1024,1],si64>, !torch.vtensor<[1024],si64>) -> !torch.list<optional<vtensor>>
    %1155 = torch.aten.index.Tensor %1144, %1154 : !torch.vtensor<[1,256,512,512],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int2_1225 = torch.constant.int 2
    %1156 = torch.aten.clone %1155, %int2_1225 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1226 = torch.constant.int 5
    %1157 = torch.prims.convert_element_type %1156, %int5_1226 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %_params.vae.decoder.up_blocks.2.upsamplers.0.conv.weight = util.global.load @_params.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %1158 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %_params.vae.decoder.up_blocks.2.upsamplers.0.conv.bias = util.global.load @_params.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16>
    %1159 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1227 = torch.constant.int 1
    %int1_1228 = torch.constant.int 1
    %1160 = torch.prim.ListConstruct %int1_1227, %int1_1228 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1229 = torch.constant.int 1
    %int1_1230 = torch.constant.int 1
    %1161 = torch.prim.ListConstruct %int1_1229, %int1_1230 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1231 = torch.constant.int 1
    %int1_1232 = torch.constant.int 1
    %1162 = torch.prim.ListConstruct %int1_1231, %int1_1232 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1233 = torch.constant.bool false
    %int0_1234 = torch.constant.int 0
    %int0_1235 = torch.constant.int 0
    %1163 = torch.prim.ListConstruct %int0_1234, %int0_1235 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1236 = torch.constant.int 1
    %1164 = torch.aten.convolution %1157, %1158, %1159, %1160, %1161, %1162, %false_1233, %1163, %int1_1236 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %int2_1237 = torch.constant.int 2
    %1165 = torch.aten.clone %1164, %int2_1237 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %int1_1238 = torch.constant.int 1
    %int32_1239 = torch.constant.int 32
    %int8_1240 = torch.constant.int 8
    %int1048576 = torch.constant.int 1048576
    %1166 = torch.prim.ListConstruct %int1_1238, %int32_1239, %int8_1240, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1167 = torch.aten.view %1165, %1166 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,1048576],f16>
    %int6_1241 = torch.constant.int 6
    %1168 = torch.prims.convert_element_type %1167, %int6_1241 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %int2_1242 = torch.constant.int 2
    %int3_1243 = torch.constant.int 3
    %1169 = torch.prim.ListConstruct %int2_1242, %int3_1243 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1244 = torch.constant.int 0
    %true_1245 = torch.constant.bool true
    %result0_1246, %result1_1247 = torch.aten.var_mean.correction %1168, %1169, %int0_1244, %true_1245 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1248 = torch.constant.float 9.9999999999999995E-7
    %int1_1249 = torch.constant.int 1
    %1170 = torch.aten.add.Scalar %result0_1246, %float9.999990e-07_1248, %int1_1249 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1171 = torch.aten.rsqrt %1170 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1250 = torch.constant.int 1
    %1172 = torch.aten.sub.Tensor %1167, %result1_1247, %int1_1250 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %1173 = torch.aten.mul.Tensor %1172, %1171 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,1048576],f32>
    %int1_1251 = torch.constant.int 1
    %int256_1252 = torch.constant.int 256
    %int1024_1253 = torch.constant.int 1024
    %int1024_1254 = torch.constant.int 1024
    %1174 = torch.prim.ListConstruct %int1_1251, %int256_1252, %int1024_1253, %int1024_1254 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1175 = torch.aten.view %1173, %1174 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,256,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.0.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16>
    %1176 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1255 = torch.constant.int 0
    %1177 = torch.aten.unsqueeze %1176, %int0_1255 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1256 = torch.constant.int 2
    %1178 = torch.aten.unsqueeze %1177, %int2_1256 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1257 = torch.constant.int 3
    %1179 = torch.aten.unsqueeze %1178, %int3_1257 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16>
    %1180 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1258 = torch.constant.int 0
    %1181 = torch.aten.unsqueeze %1180, %int0_1258 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1259 = torch.constant.int 2
    %1182 = torch.aten.unsqueeze %1181, %int2_1259 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1260 = torch.constant.int 3
    %1183 = torch.aten.unsqueeze %1182, %int3_1260 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %1184 = torch.aten.mul.Tensor %1175, %1183 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int1_1261 = torch.constant.int 1
    %1185 = torch.aten.add.Tensor %1184, %1179, %int1_1261 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1262 = torch.constant.int 5
    %1186 = torch.prims.convert_element_type %1185, %int5_1262 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %int5_1263 = torch.constant.int 5
    %1187 = torch.prims.convert_element_type %result1_1247, %int5_1263 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1264 = torch.constant.int 5
    %1188 = torch.prims.convert_element_type %1171, %int5_1264 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1265 = torch.constant.int 3
    %1189 = torch.prim.ListConstruct %int3_1265 : (!torch.int) -> !torch.list<int>
    %1190 = torch.prims.squeeze %1187, %1189 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1266 = torch.constant.int 2
    %1191 = torch.prim.ListConstruct %int2_1266 : (!torch.int) -> !torch.list<int>
    %1192 = torch.prims.squeeze %1190, %1191 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1267 = torch.constant.int 3
    %1193 = torch.prim.ListConstruct %int3_1267 : (!torch.int) -> !torch.list<int>
    %1194 = torch.prims.squeeze %1188, %1193 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1268 = torch.constant.int 2
    %1195 = torch.prim.ListConstruct %int2_1268 : (!torch.int) -> !torch.list<int>
    %1196 = torch.prims.squeeze %1194, %1195 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1197 = torch.aten.detach %1192 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1198 = torch.aten.detach %1196 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1199 = torch.aten.silu %1186 : !torch.vtensor<[1,256,1024,1024],f16> -> !torch.vtensor<[1,256,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16>
    %1200 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16> -> !torch.vtensor<[128,256,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16>
    %1201 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1269 = torch.constant.int 1
    %int1_1270 = torch.constant.int 1
    %1202 = torch.prim.ListConstruct %int1_1269, %int1_1270 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1271 = torch.constant.int 1
    %int1_1272 = torch.constant.int 1
    %1203 = torch.prim.ListConstruct %int1_1271, %int1_1272 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1273 = torch.constant.int 1
    %int1_1274 = torch.constant.int 1
    %1204 = torch.prim.ListConstruct %int1_1273, %int1_1274 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1275 = torch.constant.bool false
    %int0_1276 = torch.constant.int 0
    %int0_1277 = torch.constant.int 0
    %1205 = torch.prim.ListConstruct %int0_1276, %int0_1277 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1278 = torch.constant.int 1
    %1206 = torch.aten.convolution %1199, %1200, %1201, %1202, %1203, %1204, %false_1275, %1205, %int1_1278 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1279 = torch.constant.int 2
    %1207 = torch.aten.clone %1206, %int2_1279 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1280 = torch.constant.int 1
    %int32_1281 = torch.constant.int 32
    %int4_1282 = torch.constant.int 4
    %int1048576_1283 = torch.constant.int 1048576
    %1208 = torch.prim.ListConstruct %int1_1280, %int32_1281, %int4_1282, %int1048576_1283 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1209 = torch.aten.view %1207, %1208 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1284 = torch.constant.int 6
    %1210 = torch.prims.convert_element_type %1209, %int6_1284 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1285 = torch.constant.int 2
    %int3_1286 = torch.constant.int 3
    %1211 = torch.prim.ListConstruct %int2_1285, %int3_1286 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1287 = torch.constant.int 0
    %true_1288 = torch.constant.bool true
    %result0_1289, %result1_1290 = torch.aten.var_mean.correction %1210, %1211, %int0_1287, %true_1288 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1291 = torch.constant.float 9.9999999999999995E-7
    %int1_1292 = torch.constant.int 1
    %1212 = torch.aten.add.Scalar %result0_1289, %float9.999990e-07_1291, %int1_1292 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1213 = torch.aten.rsqrt %1212 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1293 = torch.constant.int 1
    %1214 = torch.aten.sub.Tensor %1209, %result1_1290, %int1_1293 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1215 = torch.aten.mul.Tensor %1214, %1213 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1294 = torch.constant.int 1
    %int128_1295 = torch.constant.int 128
    %int1024_1296 = torch.constant.int 1024
    %int1024_1297 = torch.constant.int 1024
    %1216 = torch.prim.ListConstruct %int1_1294, %int128_1295, %int1024_1296, %int1024_1297 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1217 = torch.aten.view %1215, %1216 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.0.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16>
    %1218 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1298 = torch.constant.int 0
    %1219 = torch.aten.unsqueeze %1218, %int0_1298 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1299 = torch.constant.int 2
    %1220 = torch.aten.unsqueeze %1219, %int2_1299 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1300 = torch.constant.int 3
    %1221 = torch.aten.unsqueeze %1220, %int3_1300 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16>
    %1222 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1301 = torch.constant.int 0
    %1223 = torch.aten.unsqueeze %1222, %int0_1301 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1302 = torch.constant.int 2
    %1224 = torch.aten.unsqueeze %1223, %int2_1302 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1303 = torch.constant.int 3
    %1225 = torch.aten.unsqueeze %1224, %int3_1303 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1226 = torch.aten.mul.Tensor %1217, %1225 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1304 = torch.constant.int 1
    %1227 = torch.aten.add.Tensor %1226, %1221, %int1_1304 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1305 = torch.constant.int 5
    %1228 = torch.prims.convert_element_type %1227, %int5_1305 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1306 = torch.constant.int 5
    %1229 = torch.prims.convert_element_type %result1_1290, %int5_1306 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1307 = torch.constant.int 5
    %1230 = torch.prims.convert_element_type %1213, %int5_1307 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1308 = torch.constant.int 3
    %1231 = torch.prim.ListConstruct %int3_1308 : (!torch.int) -> !torch.list<int>
    %1232 = torch.prims.squeeze %1229, %1231 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1309 = torch.constant.int 2
    %1233 = torch.prim.ListConstruct %int2_1309 : (!torch.int) -> !torch.list<int>
    %1234 = torch.prims.squeeze %1232, %1233 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1310 = torch.constant.int 3
    %1235 = torch.prim.ListConstruct %int3_1310 : (!torch.int) -> !torch.list<int>
    %1236 = torch.prims.squeeze %1230, %1235 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1311 = torch.constant.int 2
    %1237 = torch.prim.ListConstruct %int2_1311 : (!torch.int) -> !torch.list<int>
    %1238 = torch.prims.squeeze %1236, %1237 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1239 = torch.aten.detach %1234 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1240 = torch.aten.detach %1238 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1241 = torch.aten.silu %1228 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1312 = torch.constant.none
    %1242 = torch.aten.clone %1241, %none_1312 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %1243 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16>
    %1244 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1313 = torch.constant.int 1
    %int1_1314 = torch.constant.int 1
    %1245 = torch.prim.ListConstruct %int1_1313, %int1_1314 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1315 = torch.constant.int 1
    %int1_1316 = torch.constant.int 1
    %1246 = torch.prim.ListConstruct %int1_1315, %int1_1316 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1317 = torch.constant.int 1
    %int1_1318 = torch.constant.int 1
    %1247 = torch.prim.ListConstruct %int1_1317, %int1_1318 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1319 = torch.constant.bool false
    %int0_1320 = torch.constant.int 0
    %int0_1321 = torch.constant.int 0
    %1248 = torch.prim.ListConstruct %int0_1320, %int0_1321 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1322 = torch.constant.int 1
    %1249 = torch.aten.convolution %1242, %1243, %1244, %1245, %1246, %1247, %false_1319, %1248, %int1_1322 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16>
    %1250 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16> -> !torch.vtensor<[128,256,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16>
    %1251 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1323 = torch.constant.int 1
    %int1_1324 = torch.constant.int 1
    %1252 = torch.prim.ListConstruct %int1_1323, %int1_1324 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1325 = torch.constant.int 0
    %int0_1326 = torch.constant.int 0
    %1253 = torch.prim.ListConstruct %int0_1325, %int0_1326 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1327 = torch.constant.int 1
    %int1_1328 = torch.constant.int 1
    %1254 = torch.prim.ListConstruct %int1_1327, %int1_1328 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1329 = torch.constant.bool false
    %int0_1330 = torch.constant.int 0
    %int0_1331 = torch.constant.int 0
    %1255 = torch.prim.ListConstruct %int0_1330, %int0_1331 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1332 = torch.constant.int 1
    %1256 = torch.aten.convolution %1164, %1250, %1251, %1252, %1253, %1254, %false_1329, %1255, %int1_1332 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,1,1],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1333 = torch.constant.int 1
    %1257 = torch.aten.add.Tensor %1256, %1249, %int1_1333 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1334 = torch.constant.float 1.000000e+00
    %1258 = torch.aten.div.Scalar %1257, %float1.000000e00_1334 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1335 = torch.constant.int 2
    %1259 = torch.aten.clone %1258, %int2_1335 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1336 = torch.constant.int 1
    %int32_1337 = torch.constant.int 32
    %int4_1338 = torch.constant.int 4
    %int1048576_1339 = torch.constant.int 1048576
    %1260 = torch.prim.ListConstruct %int1_1336, %int32_1337, %int4_1338, %int1048576_1339 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1261 = torch.aten.view %1259, %1260 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1340 = torch.constant.int 6
    %1262 = torch.prims.convert_element_type %1261, %int6_1340 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1341 = torch.constant.int 2
    %int3_1342 = torch.constant.int 3
    %1263 = torch.prim.ListConstruct %int2_1341, %int3_1342 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1343 = torch.constant.int 0
    %true_1344 = torch.constant.bool true
    %result0_1345, %result1_1346 = torch.aten.var_mean.correction %1262, %1263, %int0_1343, %true_1344 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1347 = torch.constant.float 9.9999999999999995E-7
    %int1_1348 = torch.constant.int 1
    %1264 = torch.aten.add.Scalar %result0_1345, %float9.999990e-07_1347, %int1_1348 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1265 = torch.aten.rsqrt %1264 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1349 = torch.constant.int 1
    %1266 = torch.aten.sub.Tensor %1261, %result1_1346, %int1_1349 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1267 = torch.aten.mul.Tensor %1266, %1265 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1350 = torch.constant.int 1
    %int128_1351 = torch.constant.int 128
    %int1024_1352 = torch.constant.int 1024
    %int1024_1353 = torch.constant.int 1024
    %1268 = torch.prim.ListConstruct %int1_1350, %int128_1351, %int1024_1352, %int1024_1353 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1269 = torch.aten.view %1267, %1268 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.1.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16>
    %1270 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1354 = torch.constant.int 0
    %1271 = torch.aten.unsqueeze %1270, %int0_1354 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1355 = torch.constant.int 2
    %1272 = torch.aten.unsqueeze %1271, %int2_1355 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1356 = torch.constant.int 3
    %1273 = torch.aten.unsqueeze %1272, %int3_1356 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16>
    %1274 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1357 = torch.constant.int 0
    %1275 = torch.aten.unsqueeze %1274, %int0_1357 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1358 = torch.constant.int 2
    %1276 = torch.aten.unsqueeze %1275, %int2_1358 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1359 = torch.constant.int 3
    %1277 = torch.aten.unsqueeze %1276, %int3_1359 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1278 = torch.aten.mul.Tensor %1269, %1277 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1360 = torch.constant.int 1
    %1279 = torch.aten.add.Tensor %1278, %1273, %int1_1360 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1361 = torch.constant.int 5
    %1280 = torch.prims.convert_element_type %1279, %int5_1361 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1362 = torch.constant.int 5
    %1281 = torch.prims.convert_element_type %result1_1346, %int5_1362 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1363 = torch.constant.int 5
    %1282 = torch.prims.convert_element_type %1265, %int5_1363 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1364 = torch.constant.int 3
    %1283 = torch.prim.ListConstruct %int3_1364 : (!torch.int) -> !torch.list<int>
    %1284 = torch.prims.squeeze %1281, %1283 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1365 = torch.constant.int 2
    %1285 = torch.prim.ListConstruct %int2_1365 : (!torch.int) -> !torch.list<int>
    %1286 = torch.prims.squeeze %1284, %1285 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1366 = torch.constant.int 3
    %1287 = torch.prim.ListConstruct %int3_1366 : (!torch.int) -> !torch.list<int>
    %1288 = torch.prims.squeeze %1282, %1287 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1367 = torch.constant.int 2
    %1289 = torch.prim.ListConstruct %int2_1367 : (!torch.int) -> !torch.list<int>
    %1290 = torch.prims.squeeze %1288, %1289 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1291 = torch.aten.detach %1286 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1292 = torch.aten.detach %1290 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1293 = torch.aten.silu %1280 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %1294 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16>
    %1295 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1368 = torch.constant.int 1
    %int1_1369 = torch.constant.int 1
    %1296 = torch.prim.ListConstruct %int1_1368, %int1_1369 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1370 = torch.constant.int 1
    %int1_1371 = torch.constant.int 1
    %1297 = torch.prim.ListConstruct %int1_1370, %int1_1371 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1372 = torch.constant.int 1
    %int1_1373 = torch.constant.int 1
    %1298 = torch.prim.ListConstruct %int1_1372, %int1_1373 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1374 = torch.constant.bool false
    %int0_1375 = torch.constant.int 0
    %int0_1376 = torch.constant.int 0
    %1299 = torch.prim.ListConstruct %int0_1375, %int0_1376 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1377 = torch.constant.int 1
    %1300 = torch.aten.convolution %1293, %1294, %1295, %1296, %1297, %1298, %false_1374, %1299, %int1_1377 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1378 = torch.constant.int 2
    %1301 = torch.aten.clone %1300, %int2_1378 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1379 = torch.constant.int 1
    %int32_1380 = torch.constant.int 32
    %int4_1381 = torch.constant.int 4
    %int1048576_1382 = torch.constant.int 1048576
    %1302 = torch.prim.ListConstruct %int1_1379, %int32_1380, %int4_1381, %int1048576_1382 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1303 = torch.aten.view %1301, %1302 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1383 = torch.constant.int 6
    %1304 = torch.prims.convert_element_type %1303, %int6_1383 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1384 = torch.constant.int 2
    %int3_1385 = torch.constant.int 3
    %1305 = torch.prim.ListConstruct %int2_1384, %int3_1385 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1386 = torch.constant.int 0
    %true_1387 = torch.constant.bool true
    %result0_1388, %result1_1389 = torch.aten.var_mean.correction %1304, %1305, %int0_1386, %true_1387 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1390 = torch.constant.float 9.9999999999999995E-7
    %int1_1391 = torch.constant.int 1
    %1306 = torch.aten.add.Scalar %result0_1388, %float9.999990e-07_1390, %int1_1391 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1307 = torch.aten.rsqrt %1306 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1392 = torch.constant.int 1
    %1308 = torch.aten.sub.Tensor %1303, %result1_1389, %int1_1392 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1309 = torch.aten.mul.Tensor %1308, %1307 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1393 = torch.constant.int 1
    %int128_1394 = torch.constant.int 128
    %int1024_1395 = torch.constant.int 1024
    %int1024_1396 = torch.constant.int 1024
    %1310 = torch.prim.ListConstruct %int1_1393, %int128_1394, %int1024_1395, %int1024_1396 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1311 = torch.aten.view %1309, %1310 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.1.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16>
    %1312 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1397 = torch.constant.int 0
    %1313 = torch.aten.unsqueeze %1312, %int0_1397 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1398 = torch.constant.int 2
    %1314 = torch.aten.unsqueeze %1313, %int2_1398 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1399 = torch.constant.int 3
    %1315 = torch.aten.unsqueeze %1314, %int3_1399 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16>
    %1316 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1400 = torch.constant.int 0
    %1317 = torch.aten.unsqueeze %1316, %int0_1400 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1401 = torch.constant.int 2
    %1318 = torch.aten.unsqueeze %1317, %int2_1401 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1402 = torch.constant.int 3
    %1319 = torch.aten.unsqueeze %1318, %int3_1402 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1320 = torch.aten.mul.Tensor %1311, %1319 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1403 = torch.constant.int 1
    %1321 = torch.aten.add.Tensor %1320, %1315, %int1_1403 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1404 = torch.constant.int 5
    %1322 = torch.prims.convert_element_type %1321, %int5_1404 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1405 = torch.constant.int 5
    %1323 = torch.prims.convert_element_type %result1_1389, %int5_1405 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1406 = torch.constant.int 5
    %1324 = torch.prims.convert_element_type %1307, %int5_1406 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1407 = torch.constant.int 3
    %1325 = torch.prim.ListConstruct %int3_1407 : (!torch.int) -> !torch.list<int>
    %1326 = torch.prims.squeeze %1323, %1325 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1408 = torch.constant.int 2
    %1327 = torch.prim.ListConstruct %int2_1408 : (!torch.int) -> !torch.list<int>
    %1328 = torch.prims.squeeze %1326, %1327 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1409 = torch.constant.int 3
    %1329 = torch.prim.ListConstruct %int3_1409 : (!torch.int) -> !torch.list<int>
    %1330 = torch.prims.squeeze %1324, %1329 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1410 = torch.constant.int 2
    %1331 = torch.prim.ListConstruct %int2_1410 : (!torch.int) -> !torch.list<int>
    %1332 = torch.prims.squeeze %1330, %1331 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1333 = torch.aten.detach %1328 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1334 = torch.aten.detach %1332 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1335 = torch.aten.silu %1322 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1411 = torch.constant.none
    %1336 = torch.aten.clone %1335, %none_1411 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %1337 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.1.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16>
    %1338 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1412 = torch.constant.int 1
    %int1_1413 = torch.constant.int 1
    %1339 = torch.prim.ListConstruct %int1_1412, %int1_1413 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1414 = torch.constant.int 1
    %int1_1415 = torch.constant.int 1
    %1340 = torch.prim.ListConstruct %int1_1414, %int1_1415 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1416 = torch.constant.int 1
    %int1_1417 = torch.constant.int 1
    %1341 = torch.prim.ListConstruct %int1_1416, %int1_1417 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1418 = torch.constant.bool false
    %int0_1419 = torch.constant.int 0
    %int0_1420 = torch.constant.int 0
    %1342 = torch.prim.ListConstruct %int0_1419, %int0_1420 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1421 = torch.constant.int 1
    %1343 = torch.aten.convolution %1336, %1337, %1338, %1339, %1340, %1341, %false_1418, %1342, %int1_1421 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1422 = torch.constant.int 1
    %1344 = torch.aten.add.Tensor %1258, %1343, %int1_1422 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1423 = torch.constant.float 1.000000e+00
    %1345 = torch.aten.div.Scalar %1344, %float1.000000e00_1423 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1424 = torch.constant.int 2
    %1346 = torch.aten.clone %1345, %int2_1424 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1425 = torch.constant.int 1
    %int32_1426 = torch.constant.int 32
    %int4_1427 = torch.constant.int 4
    %int1048576_1428 = torch.constant.int 1048576
    %1347 = torch.prim.ListConstruct %int1_1425, %int32_1426, %int4_1427, %int1048576_1428 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1348 = torch.aten.view %1346, %1347 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1429 = torch.constant.int 6
    %1349 = torch.prims.convert_element_type %1348, %int6_1429 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1430 = torch.constant.int 2
    %int3_1431 = torch.constant.int 3
    %1350 = torch.prim.ListConstruct %int2_1430, %int3_1431 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1432 = torch.constant.int 0
    %true_1433 = torch.constant.bool true
    %result0_1434, %result1_1435 = torch.aten.var_mean.correction %1349, %1350, %int0_1432, %true_1433 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1436 = torch.constant.float 9.9999999999999995E-7
    %int1_1437 = torch.constant.int 1
    %1351 = torch.aten.add.Scalar %result0_1434, %float9.999990e-07_1436, %int1_1437 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1352 = torch.aten.rsqrt %1351 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1438 = torch.constant.int 1
    %1353 = torch.aten.sub.Tensor %1348, %result1_1435, %int1_1438 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1354 = torch.aten.mul.Tensor %1353, %1352 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1439 = torch.constant.int 1
    %int128_1440 = torch.constant.int 128
    %int1024_1441 = torch.constant.int 1024
    %int1024_1442 = torch.constant.int 1024
    %1355 = torch.prim.ListConstruct %int1_1439, %int128_1440, %int1024_1441, %int1024_1442 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1356 = torch.aten.view %1354, %1355 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.2.norm1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16>
    %1357 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1443 = torch.constant.int 0
    %1358 = torch.aten.unsqueeze %1357, %int0_1443 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1444 = torch.constant.int 2
    %1359 = torch.aten.unsqueeze %1358, %int2_1444 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1445 = torch.constant.int 3
    %1360 = torch.aten.unsqueeze %1359, %int3_1445 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.norm1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16>
    %1361 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1446 = torch.constant.int 0
    %1362 = torch.aten.unsqueeze %1361, %int0_1446 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1447 = torch.constant.int 2
    %1363 = torch.aten.unsqueeze %1362, %int2_1447 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1448 = torch.constant.int 3
    %1364 = torch.aten.unsqueeze %1363, %int3_1448 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1365 = torch.aten.mul.Tensor %1356, %1364 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1449 = torch.constant.int 1
    %1366 = torch.aten.add.Tensor %1365, %1360, %int1_1449 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1450 = torch.constant.int 5
    %1367 = torch.prims.convert_element_type %1366, %int5_1450 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1451 = torch.constant.int 5
    %1368 = torch.prims.convert_element_type %result1_1435, %int5_1451 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1452 = torch.constant.int 5
    %1369 = torch.prims.convert_element_type %1352, %int5_1452 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1453 = torch.constant.int 3
    %1370 = torch.prim.ListConstruct %int3_1453 : (!torch.int) -> !torch.list<int>
    %1371 = torch.prims.squeeze %1368, %1370 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1454 = torch.constant.int 2
    %1372 = torch.prim.ListConstruct %int2_1454 : (!torch.int) -> !torch.list<int>
    %1373 = torch.prims.squeeze %1371, %1372 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1455 = torch.constant.int 3
    %1374 = torch.prim.ListConstruct %int3_1455 : (!torch.int) -> !torch.list<int>
    %1375 = torch.prims.squeeze %1369, %1374 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1456 = torch.constant.int 2
    %1376 = torch.prim.ListConstruct %int2_1456 : (!torch.int) -> !torch.list<int>
    %1377 = torch.prims.squeeze %1375, %1376 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1378 = torch.aten.detach %1373 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1379 = torch.aten.detach %1377 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1380 = torch.aten.silu %1367 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.conv1.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16>
    %1381 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.conv1.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16>
    %1382 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1457 = torch.constant.int 1
    %int1_1458 = torch.constant.int 1
    %1383 = torch.prim.ListConstruct %int1_1457, %int1_1458 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1459 = torch.constant.int 1
    %int1_1460 = torch.constant.int 1
    %1384 = torch.prim.ListConstruct %int1_1459, %int1_1460 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1461 = torch.constant.int 1
    %int1_1462 = torch.constant.int 1
    %1385 = torch.prim.ListConstruct %int1_1461, %int1_1462 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1463 = torch.constant.bool false
    %int0_1464 = torch.constant.int 0
    %int0_1465 = torch.constant.int 0
    %1386 = torch.prim.ListConstruct %int0_1464, %int0_1465 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1466 = torch.constant.int 1
    %1387 = torch.aten.convolution %1380, %1381, %1382, %1383, %1384, %1385, %false_1463, %1386, %int1_1466 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1467 = torch.constant.int 2
    %1388 = torch.aten.clone %1387, %int2_1467 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1468 = torch.constant.int 1
    %int32_1469 = torch.constant.int 32
    %int4_1470 = torch.constant.int 4
    %int1048576_1471 = torch.constant.int 1048576
    %1389 = torch.prim.ListConstruct %int1_1468, %int32_1469, %int4_1470, %int1048576_1471 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1390 = torch.aten.view %1388, %1389 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1472 = torch.constant.int 6
    %1391 = torch.prims.convert_element_type %1390, %int6_1472 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1473 = torch.constant.int 2
    %int3_1474 = torch.constant.int 3
    %1392 = torch.prim.ListConstruct %int2_1473, %int3_1474 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1475 = torch.constant.int 0
    %true_1476 = torch.constant.bool true
    %result0_1477, %result1_1478 = torch.aten.var_mean.correction %1391, %1392, %int0_1475, %true_1476 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1479 = torch.constant.float 9.9999999999999995E-7
    %int1_1480 = torch.constant.int 1
    %1393 = torch.aten.add.Scalar %result0_1477, %float9.999990e-07_1479, %int1_1480 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1394 = torch.aten.rsqrt %1393 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1481 = torch.constant.int 1
    %1395 = torch.aten.sub.Tensor %1390, %result1_1478, %int1_1481 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1396 = torch.aten.mul.Tensor %1395, %1394 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1482 = torch.constant.int 1
    %int128_1483 = torch.constant.int 128
    %int1024_1484 = torch.constant.int 1024
    %int1024_1485 = torch.constant.int 1024
    %1397 = torch.prim.ListConstruct %int1_1482, %int128_1483, %int1024_1484, %int1024_1485 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1398 = torch.aten.view %1396, %1397 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.up_blocks.3.resnets.2.norm2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16>
    %1399 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1486 = torch.constant.int 0
    %1400 = torch.aten.unsqueeze %1399, %int0_1486 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1487 = torch.constant.int 2
    %1401 = torch.aten.unsqueeze %1400, %int2_1487 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1488 = torch.constant.int 3
    %1402 = torch.aten.unsqueeze %1401, %int3_1488 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.norm2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16>
    %1403 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1489 = torch.constant.int 0
    %1404 = torch.aten.unsqueeze %1403, %int0_1489 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1490 = torch.constant.int 2
    %1405 = torch.aten.unsqueeze %1404, %int2_1490 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1491 = torch.constant.int 3
    %1406 = torch.aten.unsqueeze %1405, %int3_1491 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1407 = torch.aten.mul.Tensor %1398, %1406 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1492 = torch.constant.int 1
    %1408 = torch.aten.add.Tensor %1407, %1402, %int1_1492 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1493 = torch.constant.int 5
    %1409 = torch.prims.convert_element_type %1408, %int5_1493 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1494 = torch.constant.int 5
    %1410 = torch.prims.convert_element_type %result1_1478, %int5_1494 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1495 = torch.constant.int 5
    %1411 = torch.prims.convert_element_type %1394, %int5_1495 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1496 = torch.constant.int 3
    %1412 = torch.prim.ListConstruct %int3_1496 : (!torch.int) -> !torch.list<int>
    %1413 = torch.prims.squeeze %1410, %1412 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1497 = torch.constant.int 2
    %1414 = torch.prim.ListConstruct %int2_1497 : (!torch.int) -> !torch.list<int>
    %1415 = torch.prims.squeeze %1413, %1414 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1498 = torch.constant.int 3
    %1416 = torch.prim.ListConstruct %int3_1498 : (!torch.int) -> !torch.list<int>
    %1417 = torch.prims.squeeze %1411, %1416 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1499 = torch.constant.int 2
    %1418 = torch.prim.ListConstruct %int2_1499 : (!torch.int) -> !torch.list<int>
    %1419 = torch.prims.squeeze %1417, %1418 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1420 = torch.aten.detach %1415 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1421 = torch.aten.detach %1419 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1422 = torch.aten.silu %1409 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1500 = torch.constant.none
    %1423 = torch.aten.clone %1422, %none_1500 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.conv2.weight = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16>
    %1424 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %_params.vae.decoder.up_blocks.3.resnets.2.conv2.bias = util.global.load @_params.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16>
    %1425 = torch_c.from_builtin_tensor %_params.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1501 = torch.constant.int 1
    %int1_1502 = torch.constant.int 1
    %1426 = torch.prim.ListConstruct %int1_1501, %int1_1502 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1503 = torch.constant.int 1
    %int1_1504 = torch.constant.int 1
    %1427 = torch.prim.ListConstruct %int1_1503, %int1_1504 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1505 = torch.constant.int 1
    %int1_1506 = torch.constant.int 1
    %1428 = torch.prim.ListConstruct %int1_1505, %int1_1506 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1507 = torch.constant.bool false
    %int0_1508 = torch.constant.int 0
    %int0_1509 = torch.constant.int 0
    %1429 = torch.prim.ListConstruct %int0_1508, %int0_1509 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1510 = torch.constant.int 1
    %1430 = torch.aten.convolution %1423, %1424, %1425, %1426, %1427, %1428, %false_1507, %1429, %int1_1510 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1511 = torch.constant.int 1
    %1431 = torch.aten.add.Tensor %1345, %1430, %int1_1511 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1512 = torch.constant.float 1.000000e+00
    %1432 = torch.aten.div.Scalar %1431, %float1.000000e00_1512 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int2_1513 = torch.constant.int 2
    %1433 = torch.aten.clone %1432, %int2_1513 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1514 = torch.constant.int 1
    %int32_1515 = torch.constant.int 32
    %int4_1516 = torch.constant.int 4
    %int1048576_1517 = torch.constant.int 1048576
    %1434 = torch.prim.ListConstruct %int1_1514, %int32_1515, %int4_1516, %int1048576_1517 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1435 = torch.aten.view %1433, %1434 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1518 = torch.constant.int 6
    %1436 = torch.prims.convert_element_type %1435, %int6_1518 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1519 = torch.constant.int 2
    %int3_1520 = torch.constant.int 3
    %1437 = torch.prim.ListConstruct %int2_1519, %int3_1520 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1521 = torch.constant.int 0
    %true_1522 = torch.constant.bool true
    %result0_1523, %result1_1524 = torch.aten.var_mean.correction %1436, %1437, %int0_1521, %true_1522 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1525 = torch.constant.float 9.9999999999999995E-7
    %int1_1526 = torch.constant.int 1
    %1438 = torch.aten.add.Scalar %result0_1523, %float9.999990e-07_1525, %int1_1526 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1439 = torch.aten.rsqrt %1438 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1527 = torch.constant.int 1
    %1440 = torch.aten.sub.Tensor %1435, %result1_1524, %int1_1527 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1441 = torch.aten.mul.Tensor %1440, %1439 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1528 = torch.constant.int 1
    %int128_1529 = torch.constant.int 128
    %int1024_1530 = torch.constant.int 1024
    %int1024_1531 = torch.constant.int 1024
    %1442 = torch.prim.ListConstruct %int1_1528, %int128_1529, %int1024_1530, %int1024_1531 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1443 = torch.aten.view %1441, %1442 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %_params.vae.decoder.conv_norm_out.bias = util.global.load @_params.vae.decoder.conv_norm_out.bias : tensor<128xf16>
    %1444 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_norm_out.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1532 = torch.constant.int 0
    %1445 = torch.aten.unsqueeze %1444, %int0_1532 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1533 = torch.constant.int 2
    %1446 = torch.aten.unsqueeze %1445, %int2_1533 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1534 = torch.constant.int 3
    %1447 = torch.aten.unsqueeze %1446, %int3_1534 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %_params.vae.decoder.conv_norm_out.weight = util.global.load @_params.vae.decoder.conv_norm_out.weight : tensor<128xf16>
    %1448 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_norm_out.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1535 = torch.constant.int 0
    %1449 = torch.aten.unsqueeze %1448, %int0_1535 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1536 = torch.constant.int 2
    %1450 = torch.aten.unsqueeze %1449, %int2_1536 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1537 = torch.constant.int 3
    %1451 = torch.aten.unsqueeze %1450, %int3_1537 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1452 = torch.aten.mul.Tensor %1443, %1451 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1538 = torch.constant.int 1
    %1453 = torch.aten.add.Tensor %1452, %1447, %int1_1538 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1539 = torch.constant.int 5
    %1454 = torch.prims.convert_element_type %1453, %int5_1539 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int5_1540 = torch.constant.int 5
    %1455 = torch.prims.convert_element_type %result1_1524, %int5_1540 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int5_1541 = torch.constant.int 5
    %1456 = torch.prims.convert_element_type %1439, %int5_1541 : !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,1,1],f16>
    %int3_1542 = torch.constant.int 3
    %1457 = torch.prim.ListConstruct %int3_1542 : (!torch.int) -> !torch.list<int>
    %1458 = torch.prims.squeeze %1455, %1457 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1543 = torch.constant.int 2
    %1459 = torch.prim.ListConstruct %int2_1543 : (!torch.int) -> !torch.list<int>
    %1460 = torch.prims.squeeze %1458, %1459 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %int3_1544 = torch.constant.int 3
    %1461 = torch.prim.ListConstruct %int3_1544 : (!torch.int) -> !torch.list<int>
    %1462 = torch.prims.squeeze %1456, %1461 : !torch.vtensor<[1,32,1,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32,1],f16>
    %int2_1545 = torch.constant.int 2
    %1463 = torch.prim.ListConstruct %int2_1545 : (!torch.int) -> !torch.list<int>
    %1464 = torch.prims.squeeze %1462, %1463 : !torch.vtensor<[1,32,1],f16>, !torch.list<int> -> !torch.vtensor<[1,32],f16>
    %1465 = torch.aten.detach %1460 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1466 = torch.aten.detach %1464 : !torch.vtensor<[1,32],f16> -> !torch.vtensor<[1,32],f16>
    %1467 = torch.aten.silu %1454 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %_params.vae.decoder.conv_out.weight = util.global.load @_params.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16>
    %1468 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16> -> !torch.vtensor<[3,128,3,3],f16>
    %_params.vae.decoder.conv_out.bias = util.global.load @_params.vae.decoder.conv_out.bias : tensor<3xf16>
    %1469 = torch_c.from_builtin_tensor %_params.vae.decoder.conv_out.bias : tensor<3xf16> -> !torch.vtensor<[3],f16>
    %int1_1546 = torch.constant.int 1
    %int1_1547 = torch.constant.int 1
    %1470 = torch.prim.ListConstruct %int1_1546, %int1_1547 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1548 = torch.constant.int 1
    %int1_1549 = torch.constant.int 1
    %1471 = torch.prim.ListConstruct %int1_1548, %int1_1549 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1550 = torch.constant.int 1
    %int1_1551 = torch.constant.int 1
    %1472 = torch.prim.ListConstruct %int1_1550, %int1_1551 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1552 = torch.constant.bool false
    %int0_1553 = torch.constant.int 0
    %int0_1554 = torch.constant.int 0
    %1473 = torch.prim.ListConstruct %int0_1553, %int0_1554 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1555 = torch.constant.int 1
    %1474 = torch.aten.convolution %1467, %1468, %1469, %1470, %1471, %1472, %false_1552, %1473, %int1_1555 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[3,128,3,3],f16>, !torch.vtensor<[3],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int2_1556 = torch.constant.int 2
    %1475 = torch.aten.div.Scalar %1474, %int2_1556 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %float5.000000e-01_1557 = torch.constant.float 5.000000e-01
    %int1_1558 = torch.constant.int 1
    %1476 = torch.aten.add.Scalar %1475, %float5.000000e-01_1557, %int1_1558 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.float, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int0_1559 = torch.constant.int 0
    %int1_1560 = torch.constant.int 1
    %1477 = torch.aten.clamp %1476, %int0_1559, %int1_1560 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    return %1477 : !torch.vtensor<[1,3,1024,1024],f16>
  }
}
